<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Extended Introduction to Geometric Numerical Integration</title>
<style>
body { font-family: serif; line-height: 1.5; margin: 2em; }
h1, h2, h3, h4 { font-family: Georgia, serif; }
code { background: #eee; padding: 2px 4px; }
.task { color: #777; font-style: italic; }
</style>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<h1>Geometric Numerical Integration — Rigorous Extended Introduction</h1>
<h2>Based on Blanes & Casas (2026), with Expanded Exposition</h2>

<hr/>

<h1>0. Purpose and Roadmap</h1>

<p>
This document provides a rigorous, self-contained introduction to 
<strong>Geometric Numerical Integration (GNI)</strong>, following and expanding the 
structure of <em>A Concise Introduction to Geometric Numerical Integration</em> 
(Blanes & Casas, 2nd ed., 2026). 

The aim is to:
<ul>
  <li>Start from elementary but precise principles</li>
  <li>Build toward graduate-level understanding</li>
  <li>Unify the geometric, algebraic, and analytic perspectives</li>
  <li>Present the material using structured numbering for iterative filling</li>
  <li>Expand coverage of new 2nd-edition topics</li>
</ul>
</p>

<p class="task">Task-list mode: Each numbered section is an independent module you can request for completion.</p>

<hr/>

<h1>1. Foundations of Geometric Numerical Integration</h1>

<h2>1.1 What is Geometric Numerical Integration?</h2>
<ul>
  <li>Definition of geometric properties of differential equations</li>
  <li>Why structure-preservation matters</li>
  <li>Global vs local error; qualitative vs quantitative accuracy</li>
  <li>Historical perspective: from symplectic methods to modern GNI</li>
</ul>

<h2>1.2 Fundamental Objects in Differential Equations</h2>
<ul>
  <li>Flows of ODEs: definition, group properties, Lie structure</li>
  <li>Autonomous vs non-autonomous vector fields</li>
  <li>Preservation laws: invariants, symmetries, first integrals</li>
  <li>Geometric structures: symplectic, Poisson, volume-preserving, Lie-group actions</li>
</ul>

<h2>1.3 The Geometry of Flows</h2>
<ul>
  <li>Phase-space manifolds, tangent bundles</li>
  <li>Lie derivative, pullbacks, pushforwards</li>
  <li>Time-ordered exponentials and Magnus expansions (preview)</li>
</ul>

<hr/>

<h1>2. Symplectic Geometry and Hamiltonian Dynamics</h1>

<h2>2.1 Symplectic Manifolds</h2>
<ul>
  <li>Symplectic forms, non-degeneracy</li>
  <li>Canonical coordinates (Darboux theorem)</li>
</ul>

<h2>2.2 Hamiltonian Vector Fields</h2>
<ul>
  <li>Hamilton’s equations from geometric first principles</li>
  <li>Poisson brackets, integrability, action-angle variables</li>
  <li>Examples: Kepler, harmonic oscillator, rigid body</li>
</ul>

<h2>2.3 Symmetries and Noether Theory</h2>
<ul>
  <li>Symmetry groups, momentum maps</li>
  <li>Conservation laws and structure preservation</li>
</ul>

<hr/>

<h1>3. Symplectic Integrators for Hamiltonian Systems</h1>

<h2>3.1 Why Symplectic Integrators?</h2>
<ul>
  <li>Geometric long-time stability</li>
  <li>Energy behaviour: oscillatory error vs drift</li>
</ul>

<h2>3.2 Symplectic Euler and Leapfrog</h2>
<ul>
  <li>Construction and proof of symplecticity</li>
  <li>Störmer-Verlet, velocity Verlet</li>
  <li>Backward error analysis preview</li>
</ul>

<h2>3.3 Variational Integrators</h2>
<ul>
  <li>Discrete Lagrangians</li>
  <li>Discrete Euler–Lagrange equations</li>
  <li>Connection to symplecticity</li>
</ul>

<hr/>

<h1>4. Splitting and Composition Methods</h1>

<h2>4.1 Basic Theory</h2>
<ul>
  <li>Lie–Trotter and Strang splittings</li>
  <li>Error analysis via commutators</li>
  <li>Lie algebra structure of compositions</li>
</ul>

<h2>4.2 High-Order Composition Methods</h2>
<ul>
  <li>Yoshida’s method</li>
  <li>Order conditions and rooted trees</li>
</ul>

<h2>4.3 Complex Coefficient Splittings (NEW)</h2>
<ul>
  <li>Motivation from 2nd edition</li>
  <li>Avoiding order barriers with complex timesteps</li>
  <li>Non-trivial constraints: positive-real-part conditions</li>
  <li>Applications to PDEs and stiff problems</li>
</ul>

<hr/>

<h1>5. Exponential Integrators and Magnus Expansions</h1>

<h2>5.1 The Exponential Map of Vector Fields</h2>
<ul>
  <li>Flows as exponentials of differential operators</li>
  <li>Lie series and formal analysis</li>
</ul>

<h2>5.2 Magnus Expansion for Linear Non-Autonomous Systems</h2>
<ul>
  <li>Definition and derivation</li>
  <li>Truncations and commutator structure</li>
  <li>Convergence theory</li>
</ul>

<h2>5.3 Efficient Magnus Integrators</h2>
<ul>
  <li>Gauss–Legendre quadrature strategies</li>
  <li>Commutator-free Magnus methods</li>
</ul>

<hr/>

<h1>6. Backward Error Analysis (BEA)</h1>

<h2>6.1 Modified Equations</h2>
<ul>
  <li>Formal series expansion</li>
  <li>Geometric interpretation: perturbed Hamiltonians</li>
</ul>

<h2>6.2 Long-Time Near-Conservation</h2>
<ul>
  <li>Energy behaviour of symplectic schemes</li>
  <li>Resonances and metastable dynamics</li>
</ul>

<hr/>

<h1>7. Geometric Integrators for Non-Autonomous Systems (NEW)</h1>

<h2>7.1 Extended Phase Space</h2>
<ul>
  <li>Time as a dynamical variable</li>
  <li>Local vs global invariants</li>
</ul>

<h2>7.2 Non-Autonomous Hamiltonian Systems</h2>
<ul>
  <li>Magnus expansion vs time-dependent symplectic flows</li>
  <li>Splittings for variable-coefficient operators</li>
</ul>

<h2>7.3 Applications</h2>
<ul>
  <li>Driven oscillators</li>
  <li>Chemical dynamics with time-dependent fields</li>
</ul>

<hr/>

<h1>8. Lie-Group Methods and Manifold Integrators</h1>

<h2>8.1 Differential Equations on Lie Groups</h2>
<ul>
  <li>Matrix groups, Lie algebras</li>
  <li>Left-invariant and right-invariant vector fields</li>
</ul>

<h2>8.2 Runge–Kutta–Munthe-Kaas (RKMK) methods</h2>
<ul>
  <li>Use of exponential and BCH formula</li>
  <li>Order conditions</li>
</ul>

<h2>8.3 Applications</h2>
<ul>
  <li>Rigid-body dynamics (SO(3))</li>
  <li>Quantum spin systems (SU(2))</li>
</ul>

<hr/>

<h1>9. Geometric Methods for PDEs (EXPANDED in 2nd Edition)</h1>

<h2>9.1 Semi-Discretisation and Method of Lines</h2>
<ul>
  <li>Hamiltonian PDEs: NLS, KdV, wave equation</li>
  <li>Poisson structures in infinite dimensions</li>
</ul>

<h2>9.2 Splitting for PDEs</h2>
<ul>
  <li>Linear–nonlinear decompositions</li>
  <li>FFT-based implementations</li>
</ul>

<h2>9.3 Volume-Preserving and Energy-Preserving PDE Integrators</h2>
<ul>
  <li>Discrete gradients</li>
  <li>Average vector field (AVF) methods</li>
</ul>

<hr/>

<h1>10. Applications Highlighted in 2nd Edition</h1>

<h2>10.1 Hamiltonian Monte Carlo (HMC)</h2>
<ul>
  <li>Leapfrog as a symplectic integrator for probabilistic inference</li>
  <li>Volume preservation and detailed balance</li>
</ul>

<h2>10.2 Quantum Computing</h2>
<ul>
  <li>Trotterisation and Suzuki decompositions</li>
  <li>Quantum simulation of Hamiltonian systems</li>
  <li>Error vs depth trade-offs</li>
</ul>

<h2>10.3 Celestial Mechanics and N-Body Problems</h2>
<ul>
  <li>Wisdom–Holman splitting</li>
  <li>Symplectic correctors</li>
</ul>

<hr/>

<h1>11. Advanced Topics and Research Directions</h1>

<h2>11.1 Arbitrary-Order Commutator-Free Schemes</h2>
<h2>11.2 Symmetry-Preserving Integrators</h2>
<h2>11.3 Structure-Preserving Neural ODEs and Machine Learning</h2>

<hr/>

<h1>12. Appendix: Mathematical Tools</h1>

<h2>12.1 Lie Algebras and BCH Formula</h2>
<h2>12.2 Rooted Tree Analysis</h2>
<h2>12.3 Algebraic Structure of Modified Equations</h2>

</body>

<section id="sec-1-1">
  <h2>1.1 What is Geometric Numerical Integration?</h2>

  <p>
    <strong>Geometric Numerical Integration (GNI)</strong> is the study and design of numerical
    methods for differential equations that preserve the underlying
    <em>geometric structures</em> of the exact flow: symplectic forms, invariants, symmetries,
    constraints, and manifold structure. Rather than focusing solely on minimizing local
    truncation error at a fixed time, GNI asks:
  </p>

  <blockquote>
    <em>Can a numerical method approximate not only the solution values, but the
    qualitative, structural behaviour of the continuous dynamical system, especially
    over long times?</em>
  </blockquote>

  <p>
    This viewpoint is synthesized in the monograph by Hairer, Lubich, and Wanner
    <span class="citation">[HLW06]</span>, and is presented concisely in Blanes &amp; Casas
    <span class="citation">[BC26]</span>, on which this companion is based.  [oai_citation:0‡Université Paris 13](https://www.math.univ-paris13.fr/~cuvelier/docs/Enseignements/Energetique/AnaNumII/12-13/TP1/G3/Geometric_Numerical_Integration_-_Hairer_Chap1.pdf?utm_source=chatgpt.com)
  </p>

  <p>
    To motivate the subject, we begin from first principles: flows of ordinary
    differential equations, their geometric properties, and the limitations of
    traditional error-centric numerical analysis.
  </p>

  <hr/>

  <h3 id="sec-1-1-1">1.1.1 Differential Equations and Flows</h3>

  <p>
    Consider an autonomous system of ordinary differential equations (ODEs)
  </p>

  <p class="math">
    \[
      \dot{y}(t) = f(y(t)), \qquad y(t) \in \mathbb{R}^d, \quad f : \mathbb{R}^d \to \mathbb{R}^d.
    \]
  </p>

  <p>
    Under standard assumptions (e.g. locally Lipschitz \(f\)), for any initial
    state \(y_0 \in \mathbb{R}^d\) and time \(t\) in some interval containing \(0\),
    there exists a unique solution \(y(t; y_0)\). The mapping
  </p>

  <p class="math">
    \[
      \varphi^t : \mathbb{R}^d \to \mathbb{R}^d, 
      \qquad \varphi^t(y_0) := y(t; y_0)
    \]
  </p>

  <p>
    is called the <strong>flow</strong> of the ODE at time \(t\). For an autonomous system,
    the family \(\{\varphi^t\}_{t\in I}\) satisfies the <em>flow (group) properties</em>:
  </p>

  <ul>
    <li><strong>Identity:</strong> \(\varphi^0 = \mathrm{id}\).</li>
    <li><strong>Composition (group law):</strong> \(\varphi^{t+s} = \varphi^t \circ \varphi^s\) whenever both sides are defined.</li>
    <li><strong>Invertibility:</strong> For each fixed \(t\), \(\varphi^t\) is a diffeomorphism (under suitable smoothness assumptions), with inverse \(\varphi^{-t}\).</li>
  </ul>

  <p>
    At this level, numerical methods are approximations of the one-step map
    \(\varphi^h\) for some timestep \(h\):
  </p>

  <p class="math">
    \[
      y_{n+1} = \Phi_h(y_n) \approx \varphi^h(y_n).
    \]
  </p>

  <p>
    The key idea in GNI is to treat \(\Phi_h\) itself as a <em>discrete dynamical system</em>
    and to study how well it reproduces the geometric and qualitative properties of
    \(\varphi^t\), especially for long-time integration.
  </p>

  <h4>Geometric viewpoint: phase space and invariants</h4>

  <p>
    The phase space \(\mathbb{R}^d\) is often endowed with additional structure:
  </p>

  <ul>
    <li>
      A <strong>symplectic form</strong> \(\omega\) (for Hamiltonian systems),
      making \((\mathbb{R}^{2m}, \omega)\) a symplectic manifold.
    </li>
    <li>
      A <strong>Riemannian metric</strong> \(g\) (for gradient flows).
    </li>
    <li>
      A <strong>constraint manifold</strong> \(M \subseteq \mathbb{R}^d\) (e.g. motion on a sphere).
    </li>
    <li>
      A <strong>volume form</strong> (e.g. divergence-free flows).
    </li>
  </ul>

  <p>
    The exact flow \(\varphi^t\) typically preserves some or all of these structures:
  </p>

  <ul>
    <li>
      <em>First integrals</em> (invariants):
      <span class="math">\(\;I : \mathbb{R}^d \to \mathbb{R}\; \)</span> such that
      <span class="math">\(\;I(\varphi^t(y_0)) = I(y_0)\; \forall t\).</span>
    </li>
    <li>
      <em>Symplecticity:</em> \((\varphi^t)^*\omega = \omega\), i.e. the pullback of the symplectic form is itself.
    </li>
    <li>
      <em>Reversibility:</em> for some involution \(R\) (with \(R^2 = \mathrm{id}\)),
      we may have \(R\circ \varphi^t \circ R = \varphi^{-t}\).
    </li>
    <li>
      <em>Volume preservation:</em> \(\det D\varphi^t(y) = 1\) (Liouville’s theorem for Hamiltonian flows).
    </li>
  </ul>

  <p>
    Geometric integrators are numerical methods \(\Phi_h\) that <em>exactly</em> preserve
    some of these properties for the discrete dynamics \(y_{n+1} = \Phi_h(y_n)\),
    regardless of step-size (within stability limits).
  </p>

  <hr/>

  <h3 id="sec-1-1-2">1.1.2 Traditional vs Geometric Numerical Analysis</h3>

  <p>
    Classical numerical analysis for ODEs emphasizes:
  </p>

  <ul>
    <li><strong>Local truncation error</strong> and <strong>global error</strong> at a fixed final time \(T\).</li>
    <li><strong>Order of accuracy</strong> \(p\), meaning global error \(O(h^p)\) as \(h\to0\).</li>
    <li><strong>Stability</strong> in the sense of Dahlquist (e.g. A-stability, L-stability) for linear test problems.</li>
  </ul>

  <p>
    For many applications this is sufficient. However, in problems such as:
  </p>

  <ul>
    <li>Hamiltonian mechanics (celestial mechanics, molecular dynamics),</li>
    <li>charged particle dynamics in electromagnetic fields,</li>
    <li>wave propagation and long-time asymptotics,</li>
  </ul>

  <p>
    the <em>long-time qualitative behaviour</em> is crucial: boundedness of energy,
    correct qualitative phase portraits, existence of quasi-periodic tori, etc.
    Standard high-order methods can reproduce short-time trajectories very
    accurately yet fail dramatically over long times by slowly but steadily
    destroying invariants.
  </p>

  <p>
    Geometric numerical analysis shifts the emphasis:
  </p>

  <ul>
    <li>
      <strong>Preserve structure exactly, accept small controlled distortion
      elsewhere.</strong> For instance, symplectic integrators for Hamiltonian systems
      do not exactly conserve energy, but they nearly do so over exponentially long
      times by following the flow of a <em>modified</em> Hamiltonian; see backward error
      analysis in later chapters and in <span class="citation">[HLW06, Ch. IX]</span>.  [oai_citation:1‡Université Paris 13](https://www.math.univ-paris13.fr/~cuvelier/docs/Enseignements/Energetique/AnaNumII/12-13/TP1/G3/Geometric_Numerical_Integration_-_Hairer_Chap1.pdf?utm_source=chatgpt.com)
    </li>
    <li>
      <strong>View methods as geometric maps.</strong> Numerical integrators are treated as
      diffeomorphisms \(\Phi_h\) on phase space with specific properties
      (symplectic, volume-preserving, reversible, etc.).
    </li>
    <li>
      <strong>Focus on long-time dynamics.</strong> Instead of asking “What is the error
      at \(T\)?”, we ask “How does the numerical phase portrait compare with the
      true one for large \(n\)?”.
    </li>
  </ul>

  <p>
    The outcome is a theory that explains why relatively low-order geometric
    methods can dramatically outperform higher-order non-geometric methods in
    long-time simulations of structured systems.
  </p>

  <hr/>

  <h3 id="sec-1-1-3">1.1.3 Example: Harmonic Oscillator and Energy Drift</h3>

  <p>
    A canonical example is the one-dimensional harmonic oscillator:
  </p>

  <p class="math">
    \[
      \dot{q} = p, \qquad \dot{p} = -q,
    \]
  </p>

  <p>
    with Hamiltonian
  </p>

  <p class="math">
    \[
      H(q,p) = \frac{1}{2}(p^2 + q^2).
    \]
  </p>

  <p>
    The exact flow preserves energy exactly: \(H(q(t),p(t)) = H(q_0,p_0)\) for all \(t\).
  </p>

  <h4>Explicit Euler</h4>

  <p>
    The explicit Euler method for this system is
  </p>

  <p class="math">
    \[
      \begin{aligned}
        q_{n+1} &= q_n + h p_n,\\
        p_{n+1} &= p_n - h q_n.
      \end{aligned}
    \]
  </p>

  <p>
    This map is <em>not</em> symplectic, not volume-preserving, and the discrete energy
    \(H(q_n,p_n)\) typically grows (for small \(h\)), causing a spiralling-out
    numerical trajectory in phase space.
  </p>

  <h4>Symplectic Euler</h4>

  <p>
    One variant of the symplectic Euler method (sometimes called “implicit in \(p\)”)
    is
  </p>

  <p class="math">
    \[
      \begin{aligned}
        p_{n+1} &= p_n - h q_n,\\
        q_{n+1} &= q_n + h p_{n+1}.
      \end{aligned}
    \]
  </p>

  <p>
    This method is <em>symplectic</em>: its Jacobian matrix \(D\Phi_h(q,p)\) satisfies
    \(J^\top \Omega J = \Omega\) with the standard symplectic matrix
    <span class="math">\(\Omega = \begin{pmatrix}0 & 1\\ -1 & 0\end{pmatrix}\)</span>.
    Although it does not conserve the original energy exactly,
    backward error analysis shows that it nearly conserves a nearby (modified)
    Hamiltonian over very long times.
  </p>

  <p>
    Qualitatively, instead of a spiralling trajectory, we obtain a nearly closed
    invariant curve, and the numerical energy oscillates within a small band.
  </p>

  <figure id="fig-1-1" style="text-align:center;">
    <canvas id="oscillatorCanvas" width="600" height="260"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 1.1</strong> – Numerical energy \(H(q_n,p_n)\) vs time for the
      harmonic oscillator with step-size \(h=0.1\), comparing explicit Euler
      (growing energy) and symplectic Euler (bounded oscillatory energy).
    </figcaption>
  </figure>

  <script>
    // Simple demo: energy of harmonic oscillator with Euler vs symplectic Euler.
    (function() {
      const canvas = document.getElementById('oscillatorCanvas');
      if (!canvas || !canvas.getContext) return;
      const ctx = canvas.getContext('2d');

      // Parameters
      const h = 0.1;
      const steps = 400;
      const q0 = 1.0, p0 = 0.0;

      // Storage
      const energyEuler = [];
      const energySymp = [];
      const tvals = [];

      // Explicit Euler
      let q = q0, p = p0;
      for (let n = 0; n <= steps; ++n) {
        const t = n * h;
        tvals.push(t);
        const H = 0.5 * (p*p + q*q);
        energyEuler.push(H);
        // Step
        const q_new = q + h * p;
        const p_new = p - h * q;
        q = q_new; p = p_new;
      }

      // Symplectic Euler (p first, then q)
      q = q0; p = p0;
      for (let n = 0; n <= steps; ++n) {
        const H = 0.5 * (p*p + q*q);
        energySymp.push(H);
        // Step
        const p_new = p - h * q;
        const q_new = q + h * p_new;
        q = q_new; p = p_new;
      }

      // Determine ranges
      const Eall = energyEuler.concat(energySymp);
      const Emin = Math.min.apply(null, Eall);
      const Emax = Math.max.apply(null, Eall);

      // Padding
      const padLeft = 40, padRight = 10, padTop = 10, padBottom = 30;
      const w = canvas.width, hC = canvas.height;

      // Helper: convert (t,E) to canvas coords
      function xScale(t) {
        const tmin = 0, tmax = tvals[tvals.length - 1];
        return padLeft + (t - tmin) * (w - padLeft - padRight) / (tmax - tmin);
      }
      function yScale(E) {
        return hC - padBottom - (E - Emin) * (hC - padTop - padBottom) / (Emax - Emin);
      }

      // Clear
      ctx.clearRect(0, 0, w, hC);
      ctx.font = "12px sans-serif";

      // Axes
      ctx.beginPath();
      ctx.moveTo(padLeft, padTop);
      ctx.lineTo(padLeft, hC - padBottom);
      ctx.lineTo(w - padRight, hC - padBottom);
      ctx.strokeStyle = "#000";
      ctx.stroke();

      // Labels
      ctx.fillText("t", w - padRight - 10, hC - padBottom + 20);
      ctx.fillText("H", padLeft - 20, padTop + 10);

      // Plot Euler (red-ish)
      ctx.beginPath();
      for (let n = 0; n < tvals.length; ++n) {
        const x = xScale(tvals[n]);
        const y = yScale(energyEuler[n]);
        if (n === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
      }
      ctx.strokeStyle = "#c00";
      ctx.stroke();

      // Plot Symplectic Euler (blue-ish)
      ctx.beginPath();
      for (let n = 0; n < tvals.length; ++n) {
        const x = xScale(tvals[n]);
        const y = yScale(energySymp[n]);
        if (n === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
      }
      ctx.strokeStyle = "#006";
      ctx.stroke();

      // Legend
      ctx.fillStyle = "#c00";
      ctx.fillRect(padLeft + 10, padTop + 5, 10, 3);
      ctx.fillStyle = "#000";
      ctx.fillText("Explicit Euler", padLeft + 25, padTop + 10);

      ctx.fillStyle = "#006";
      ctx.fillRect(padLeft + 10, padTop + 20, 10, 3);
      ctx.fillStyle = "#000";
      ctx.fillText("Symplectic Euler", padLeft + 25, padTop + 25);
    })();
  </script>

  <p class="task">
    Task marker: in later sections we can formalize the proof of symplecticity for
    symplectic Euler and perform a rigorous backward error analysis for the oscillator.
  </p>

  <hr/>

  <h3 id="sec-1-1-4">1.1.4 Geometric Structures and Corresponding Integrators</h3>

  <p>
    Many important classes of differential equations are characterized by particular
    geometric structures. Table 1.1 summarizes a few, along with typical geometric
    integrator families designed for them.
  </p>

  <figure id="tab-1-1">
    <table border="1" cellpadding="4" cellspacing="0" style="border-collapse:collapse; width:100%;">
      <thead>
        <tr>
          <th>Class of system</th>
          <th>Geometric structure preserved by flow</th>
          <th>Typical geometric integrators</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Hamiltonian ODEs</td>
          <td>Symplectic form, volume, (approx.) Hamiltonian</td>
          <td>Symplectic Runge–Kutta, splitting/composition methods, variational integrators</td>
        </tr>
        <tr>
          <td>Reversible systems</td>
          <td>Reversing symmetry \(R\) with \(R^2 = \mathrm{id}\)</td>
          <td>Symmetric compositions, time-reversible integrators</td>
        </tr>
        <tr>
          <td>ODEs on manifolds / Lie groups</td>
          <td>Manifold constraint, group structure</td>
          <td>Lie-group integrators (RKMK, Crouch–Grossman, Munthe-Kaas methods)</td>
        </tr>
        <tr>
          <td>Gradient systems</td>
          <td>Lyapunov functional decreasing along flow</td>
          <td>Energy-diminishing / contractive methods, discrete gradient methods</td>
        </tr>
        <tr>
          <td>Volume-preserving systems</td>
          <td>Volume form</td>
          <td>Volume-preserving integrators (e.g. splitting methods on divergence-free fields)</td>
        </tr>
        <tr>
          <td>Highly oscillatory Hamiltonian systems</td>
          <td>Adiabatic invariants, actions</td>
          <td>Modulated Fourier integrators, tailored splitting schemes</td>
        </tr>
      </tbody>
    </table>
    <figcaption>
      <strong>Table 1.1</strong> – Examples of geometric structures preserved by exact flows
      and corresponding families of geometric integrators. See <span class="citation">[HLW06, BC26]</span>
      for details.  [oai_citation:2‡Université Paris 13](https://www.math.univ-paris13.fr/~cuvelier/docs/Enseignements/Energetique/AnaNumII/12-13/TP1/G3/Geometric_Numerical_Integration_-_Hairer_Chap1.pdf?utm_source=chatgpt.com)
    </figcaption>
  </figure>

  <hr/>

  <h3 id="sec-1-1-5">1.1.5 Where This Book Sits in the Literature</h3>

  <p>
    The modern theory of geometric numerical integration is primarily developed in:
  </p>

  <ul>
    <li>
      E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>,
      2nd ed., Springer, 2006. <span class="citation">[HLW06]</span>  [oai_citation:3‡Google Books](https://books.google.com/books/about/Geometric_Numerical_Integration.html?id=T1TaNRLmZv8C&utm_source=chatgpt.com)
    </li>
    <li>
      S. Blanes, F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      Chapman &amp; Hall/CRC, 2026. <span class="citation">[BC26]</span>  [oai_citation:4‡Taylor & Francis](https://www.taylorfrancis.com/books/mono/10.1201/9781003527626/concise-introduction-geometric-numerical-integration-sergio-blanes-fernando-casas?utm_source=chatgpt.com)
    </li>
  </ul>

  <p>
    The present document follows the structure of <span class="citation">[BC26]</span> and aims to
    provide a more expansive, first-principles exposition that:
  </p>

  <ol>
    <li>Builds up the geometric language (symplectic forms, flows on manifolds, Lie groups).</li>
    <li>Explains how standard numerical methods can be viewed as maps on phase space.</li>
    <li>Shows how structure-preserving maps are constructed (splitting, composition, variational, Lie-group, exponential and Magnus methods).</li>
    <li>Introduces key tools such as backward error analysis and B-series.</li>
    <li>Connects to new topics emphasized in the 2nd edition: non-autonomous systems, PDEs, Hamiltonian Monte Carlo, and quantum computing.  [oai_citation:5‡Taylor & Francis](https://www.taylorfrancis.com/books/mono/10.1201/9781003527626/concise-introduction-geometric-numerical-integration-sergio-blanes-fernando-casas?utm_source=chatgpt.com)</li>
  </ol>

  <p class="task">
    Task marker: Section 1.2 will formalize flows, invariants, and symmetries using
    differential geometric tools (Lie derivatives, pullbacks, pushforwards), and
    will set up the precise definition of symplectic and other geometric structures.
  </p>

  <hr/>

  <h3 id="sec-1-1-6">1.1.6 References for Section 1.1</h3>

  <ol>
    <li id="ref-HLW06">
      <strong>[HLW06]</strong> E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>,
      2nd ed., Springer, 2006.  [oai_citation:6‡Google Books](https://books.google.com/books/about/Geometric_Numerical_Integration.html?id=T1TaNRLmZv8C&utm_source=chatgpt.com)
    </li>
    <li id="ref-BC26">
      <strong>[BC26]</strong> S. Blanes, F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      Chapman &amp; Hall/CRC, 2026.  [oai_citation:7‡Taylor & Francis](https://www.taylorfrancis.com/books/mono/10.1201/9781003527626/concise-introduction-geometric-numerical-integration-sergio-blanes-fernando-casas?utm_source=chatgpt.com)
    </li>
    <li id="ref-HairerNotes">
      <strong>[Hai99]</strong> E. Hairer,
      “Numerical Geometric Integration,”
      <em>Lecture notes</em>, 1998–1999 (available online).  [oai_citation:8‡Math McGill](https://www.math.mcgill.ca/gantumur/docs/down/Hairer9899.pdf?utm_source=chatgpt.com)
    </li>
  </ol>

</section>

<section id="sec-1-2">
  <h2>1.2 Fundamental Objects in Differential Equations</h2>

  <p>
    In Section 1.1, we introduced the notion of a <em>flow</em> of an ODE and motivated
    the idea of preserving geometric properties in numerical integration. We now
    formalize these concepts using basic differential geometric language. Our goal
    is to define:
  </p>

  <ol>
    <li>Flows and their infinitesimal generators (vector fields),</li>
    <li>Invariants and first integrals,</li>
    <li>Symmetries and reversible systems,</li>
    <li>Geometric structures (symplectic, volume-preserving, etc.) that will be central for geometric integrators.</li>
  </ol>

  <p>
    Throughout, we work primarily on \( \mathbb{R}^d \) for simplicity, but the
    concepts extend naturally to smooth manifolds; see e.g. <span class="citation">[AM78]</span>.  
  </p>

  <hr/>

  <h3 id="sec-1-2-1">1.2.1 Vector Fields and Flows</h3>

  <p>
    Let \(M\) be a smooth manifold (for most of this section you may take \(M =
    \mathbb{R}^d\)). A <strong>vector field</strong> on \(M\) is a smooth assignment
    that to each point \(x \in M\) associates a tangent vector \(f(x) \in T_x M\).
    We write:
  </p>

  <p class="math">
    \[
      f : M \to TM, \qquad x \mapsto f(x) \in T_x M,
    \]
  </p>

  <p>
    and in a global coordinate chart on \(\mathbb{R}^d\) we simply view
    \(f(x)\) as a function \(f : \mathbb{R}^d \to \mathbb{R}^d\).
  </p>

  <h4>Integral curves and flows</h4>

  <p>
    A smooth curve \(\gamma: I \to M\) is called an <strong>integral curve</strong> of a
    vector field \(f\) if it satisfies the ODE:
  </p>

  <p class="math">
    \[
      \dot{\gamma}(t) = f(\gamma(t)), \qquad t \in I \subset \mathbb{R}.
    \]
  </p>

  <p>
    Under standard existence and uniqueness conditions (e.g. \(f\) locally Lipschitz),
    for every point \(x \in M\) there is a maximal interval \(I_x\) and a unique integral
    curve \(\gamma_x : I_x \to M\) with \(\gamma_x(0) = x\). The <strong>flow</strong> of
    \(f\) is then the mapping
  </p>

  <p class="math">
    \[
      \varphi : D \subset \mathbb{R} \times M \to M, \qquad
      \varphi(t,x) := \gamma_x(t),
    \]
  </p>

  <p>
    defined on an open domain \(D\) such that \((0,x) \in D\) for all \(x\).
    For each fixed \(t\) such that \(\{t\} \times M \subset D\), we write
    \(\varphi^t : M \to M\), \(\varphi^t(x) = \varphi(t,x)\).
  </p>

  <p>
    The flow satisfies the <strong>group property</strong>:
  </p>

  <p class="math">
    \[
      \varphi^0 = \mathrm{id}_M, \qquad
      \varphi^{t+s} = \varphi^t \circ \varphi^s,
    \]
  </p>

  <p>
    whenever the compositions are defined. Conversely, a one-parameter group
    of diffeomorphisms \(\{\varphi^t\}_{t}\) with \(\varphi^0 = \mathrm{id}\)
    arises from a unique (time-independent) vector field \(f\) given by the
    <strong>infinitesimal generator</strong>:
  </p>

  <p class="math">
    \[
      f(x) = \left.\frac{d}{dt}\right|_{t=0} \varphi^t(x).
    \]
  </p>

  <h4>Autonomous vs non-autonomous systems</h4>

  <p>
    An <strong>autonomous</strong> ODE on \(M\) has the form
  </p>

  <p class="math">
    \[
      \dot{y} = f(y),
    \]
  </p>

  <p>
    with \(f\) independent of time. Its flow satisfies the group property above.
    By contrast, a <strong>non-autonomous</strong> ODE has the form
  </p>

  <p class="math">
    \[
      \dot{y} = f(t, y),
    \]
  </p>

  <p>
    and its evolution operator \(\Phi^{t,s}\) mapping \(y(s)\) to \(y(t)\) generally
    satisfies a two-parameter semigroup property:
  </p>

  <p class="math">
    \[
      \Phi^{t,s} \circ \Phi^{s,r} = \Phi^{t,r}, \qquad \Phi^{s,s} = \mathrm{id}.
    \]
  </p>

  <p>
    A common trick, central in geometric integration for non-autonomous systems,
    is to convert the system into an autonomous one on an extended phase space
    \(M \times \mathbb{R}\); we return to this in Section 7.
  </p>

  <figure id="fig-1-2">
    <svg id="flowFieldSVG" width="520" height="260" style="border:1px solid #ccc;">
      <!-- The JS below will populate arrows and trajectories -->
      Sorry, your browser does not support inline SVG.
    </svg>
    <figcaption>
      <strong>Figure 1.2</strong> – Vector field and approximate flow lines for a planar
      system. The arrows depict the vector field \(f(x)\), and the curves show
      integral curves (numerically approximated). An autonomous system corresponds
      to time-invariant arrows; non-autonomous systems would have time-dependent
      vector fields. This figure is generated interactively with JavaScript.
    </figcaption>
  </figure>

  <script>
    // Simple SVG visualization of a 2D vector field and its flows.
    (function() {
      const svg = document.getElementById("flowFieldSVG");
      if (!svg) return;

      const width = svg.viewBox.baseVal.width || svg.clientWidth || 520;
      const height = svg.viewBox.baseVal.height || svg.clientHeight || 260;

      // Coordinate ranges in phase space
      const xmin = -2.0, xmax = 2.0;
      const ymin = -1.0, ymax = 3.0;

      function xToSvg(x) {
        return (x - xmin) / (xmax - xmin) * width;
      }
      function yToSvg(y) {
        return height - (y - ymin) / (ymax - ymin) * height;
      }

      // Example vector field: a simple nonlinear system
      //   q' = p
      //   p' = -q - 0.2 q^3
      function f(q, p) {
        return { dq: p, dp: -q - 0.2*q*q*q };
      }

      // Draw vector field arrows on a coarse grid
      const gridQ = 11, gridP = 11;
      for (let i = 0; i < gridQ; ++i) {
        for (let j = 0; j < gridP; ++j) {
          const q = xmin + (xmax - xmin) * i / (gridQ - 1);
          const p = ymin + (ymax - ymin) * j / (gridP - 1);
          const v = f(q, p);
          const norm = Math.sqrt(v.dq*v.dq + v.dp*v.dp) || 1e-6;
          const scale = 0.2; // arrow length scale in phase coords
          const dq = (v.dq / norm) * scale;
          const dp = (v.dp / norm) * scale;

          const x1 = xToSvg(q - 0.5*dq);
          const y1 = yToSvg(p - 0.5*dp);
          const x2 = xToSvg(q + 0.5*dq);
          const y2 = yToSvg(p + 0.5*dp);

          const line = document.createElementNS("http://www.w3.org/2000/svg", "line");
          line.setAttribute("x1", x1);
          line.setAttribute("y1", y1);
          line.setAttribute("x2", x2);
          line.setAttribute("y2", y2);
          line.setAttribute("stroke", "#999");
          line.setAttribute("stroke-width", "1");
          svg.appendChild(line);
        }
      }

      // Draw several integral curves via a simple numerical integrator (RK2)
      const initialConditions = [
        {q: -1.5, p: 0.0},
        {q: 0.0,  p: 1.0},
        {q: 1.2,  p: 1.0},
        {q: -0.5, p: 2.0}
      ];

      const h = 0.05, steps = 200;
      initialConditions.forEach((ic) => {
        let q = ic.q, p = ic.p;

        const path = document.createElementNS("http://www.w3.org/2000/svg", "path");
        let d = "";
        for (let n = 0; n < steps; ++n) {
          const x = xToSvg(q);
          const y = yToSvg(p);
          d += (n === 0 ? "M " : " L ") + x + " " + y;

          // RK2 (midpoint) step
          const k1 = f(q, p);
          const qMid = q + 0.5*h*k1.dq;
          const pMid = p + 0.5*h*k1.dp;
          const k2 = f(qMid, pMid);
          q += h * k2.dq;
          p += h * k2.dp;
        }
        path.setAttribute("d", d);
        path.setAttribute("fill", "none");
        path.setAttribute("stroke", "#006");
        path.setAttribute("stroke-width", "1.5");
        svg.appendChild(path);
      });
    })();
  </script>

  <p class="task">
    Task marker: later sections will replace the ad-hoc RK2 integrator used for plotting
    with structure-preserving methods and compare phase portraits.
  </p>

  <hr/>

  <h3 id="sec-1-2-2">1.2.2 Invariants and First Integrals</h3>

  <p>
    An important qualitative feature of many dynamical systems is the existence of
    quantities that do not change along solutions.
  </p>

  <p><strong>Definition 1.1 (First integral).</strong>
    Let \(f\) be a vector field on \(M\) with flow \(\varphi^t\). A smooth function
    \(I : M \to \mathbb{R}\) is called a <em>first integral</em> or <em>invariant</em> if
  </p>

  <p class="math">
    \[
      I(\varphi^t(x)) = I(x) \quad \text{for all } x \in M \text{ and all } t \text{ in the domain of the flow}.
    \]
  </p>

  <p>
    Equivalently, the derivative of \(I\) along integral curves vanishes:
  </p>

  <p class="math">
    \[
      \frac{d}{dt} I(\gamma(t)) = 0
      \quad \text{whenever} \quad \dot{\gamma}(t) = f(\gamma(t)).
    \]
  </p>

  <p>
    In local coordinates, this is expressed using the gradient:
  </p>

  <p class="math">
    \[
      \frac{d}{dt} I(y(t))
      = \nabla I(y(t)) \cdot \dot{y}(t)
      = \nabla I(y(t)) \cdot f(y(t)) = 0.
    \]
  </p>

  <p>
    The differential-geometric formulation uses the <em>Lie derivative</em> of a function
    with respect to a vector field:
  </p>

  <p class="math">
    \[
      \mathcal{L}_f I = f[I] := dI(f) = \nabla I \cdot f.
    \]
  </p>

  <p>
    Then \(I\) is a first integral if and only if
  </p>

  <p class="math">
    \[
      \mathcal{L}_f I = 0.
    \]
  </p>

  <h4>Examples</h4>

  <ol>
    <li>
      <strong>Energy of the harmonic oscillator.</strong>
      For the system \(\dot{q} = p\), \(\dot{p} = -q\), the Hamiltonian
      \(H(q,p) = \frac{1}{2}(p^2 + q^2)\) satisfies
      \(\nabla H = (q, p)\), and
      \(\nabla H \cdot (p, -q) = q p + p(-q) = 0\), so \(H\) is invariant.
    </li>
    <li>
      <strong>Angular momentum in central forces.</strong>
      For a particle in \(\mathbb{R}^3\) with \(\dot{x} = v\), \(\dot{v} = F(x)\)
      and \(F(x) = f(|x|) x\) central, the angular momentum
      \(L = x \times v\) is invariant. This is linked to rotational symmetry
      and Noether’s theorem.
    </li>
  </ol>

  <p>
    For geometric integrators, the question is: <em>can we construct numerical
    methods that preserve such invariants exactly?</em> For quadratic invariants,
    special Runge–Kutta and projection methods can achieve this; see
    <span class="citation">[HLW06, Ch. 3]</span>.  
  </p>

  <hr/>

  <h3 id="sec-1-2-3">1.2.3 Symmetries and Reversibility</h3>

  <p>
    The behaviour of a dynamical system is often constrained by its symmetries.
    These symmetries are crucial in geometric integration because numerical methods
    can be designed to respect them.
  </p>

  <h4>Symmetry under a diffeomorphism</h4>

  <p><strong>Definition 1.2 (Symmetry of a vector field).</strong>
    Let \(G\) be a Lie group acting smoothly on \(M\) via \(\Phi : G \times M \to M\),
    \((g,x) \mapsto \Phi(g,x)\).
    An element \(g \in G\) is a <em>symmetry</em> of the vector field \(f\) if
  </p>

  <p class="math">
    \[
      T_x \Phi(g, \cdot) \, f(x) = f(\Phi(g,x))
      \qquad \text{for all } x \in M,
    \]
  </p>

  <p>
    i.e. the pushforward of \(f\) under the group action equals \(f\) at the
    transformed point. This implies that the flow commutes with the group action:
  </p>

  <p class="math">
    \[
      \Phi(g,\varphi^t(x)) = \varphi^t(\Phi(g,x)).
    \]
  </p>

  <p>
    Symmetries give rise to conserved quantities via Noether’s theorem when the
    system derives from a variational principle; see <span class="citation">[AM78]</span>.
  </p>

  <h4>Reversible systems</h4>

  <p>
    A particularly important type of symmetry is <em>time-reversal</em>.
  </p>

  <p><strong>Definition 1.3 (Reversible system).</strong>
    Let \(R : M \to M\) be an involution, i.e. \(R^2 = \mathrm{id}_M\).
    An autonomous system \(\dot{y} = f(y)\) is called <em>reversible</em> with respect
    to \(R\) if
  </p>

  <p class="math">
    \[
      f(Ry) = - T_y R \, f(y).
    \]
  </p>

  <p>
    This implies the <strong>reversing symmetry</strong> relation for the flow:
  </p>

  <p class="math">
    \[
      R \circ \varphi^t \circ R = \varphi^{-t}.
    \]
  </p>

  <p>
    For example, Hamiltonian systems with standard symplectic structure are reversible
    under the involution \(R(q,p) = (q,-p)\), when the Hamiltonian satisfies appropriate
    conditions. Reversibility implies the existence of symmetric orbits and constrains
    the long-time behaviour.
  </p>

  <p>
    Geometric integrators can be constructed to be <em>self-adjoint</em> (time-symmetric),
    which is the discrete analogue of reversibility and plays a key role in achieving
    good long-time behaviour; see <span class="citation">[HLW06, Ch. 2, 3]</span>.
  </p>

  <hr/>

  <h3 id="sec-1-2-4">1.2.4 Pullbacks, Pushforwards, and Lie Derivatives</h3>

  <p>
    To formalize the preservation of geometric quantities by flows (and later by
    numerical methods), we briefly recall the notions of pullback, pushforward, and
    Lie derivative.
  </p>

  <h4>Pushforward of a vector field</h4>

  <p>
    Let \(\psi : M \to N\) be a smooth map between manifolds. Its <strong>differential</strong>
    at \(x\) is the linear map
  </p>

  <p class="math">
    \[
      T_x \psi : T_x M \to T_{\psi(x)} N,
    \]
  </p>

  <p>
    called the <em>pushforward</em>. If \(f\) is a vector field on \(M\), we define the
    pushforward vector field \(\psi_* f\) on \(\psi(M)\) (when \(\psi\) is a diffeomorphism)
    by
  </p>

  <p class="math">
    \[
      (\psi_* f)(\psi(x)) = T_x \psi \, f(x).
    \]
  </p>

  <h4>Pullback of functions and forms</h4>

  <p>
    For a smooth function \(g: N \to \mathbb{R}\), the <strong>pullback</strong> by \(\psi\)
    is simply composition:
  </p>

  <p class="math">
    \[
      (\psi^* g)(x) := g(\psi(x)).
    \]
  </p>

  <p>
    More generally, if \(\alpha\) is a differential 1-form (or higher-rank form) on \(N\),
    the pullback \(\psi^*\alpha\) is a form on \(M\) defined so that it “undoes” the
    effect of the pushforward; see <span class="citation">[AM78]</span> for the standard construction.
  </p>

  <h4>Lie derivative of a function and of a form</h4>

  <p>
    Let \(f\) be a vector field with flow \(\varphi^t\). For a smooth function
    \(I : M \to \mathbb{R}\), the Lie derivative of \(I\) along \(f\) is defined by
  </p>

  <p class="math">
    \[
      (\mathcal{L}_f I)(x)
      = \left.\frac{d}{dt}\right|_{t=0} I(\varphi^t(x))
      = \nabla I(x)\cdot f(x).
    \]
  </p>

  <p>
    For a differential form \(\alpha\), the Lie derivative is defined by
  </p>

  <p class="math">
    \[
      (\mathcal{L}_f \alpha)_x
      = \left.\frac{d}{dt}\right|_{t=0} (\varphi^t)^* \alpha_{\varphi^t(x)}.
    \]
  </p>

  <p>
    A form \(\alpha\) is preserved by the flow if and only if
    \((\mathcal{L}_f \alpha) = 0\), which in turn is equivalent to
    \((\varphi^t)^*\alpha = \alpha\) for all \(t\).
  </p>

  <p>
    These notions are fundamental in defining symplectic and volume-preserving
    structures and in proving their invariance under flows and numerical methods.
  </p>

  <hr/>

  <h3 id="sec-1-2-5">1.2.5 Symplectic and Volume-Preserving Flows</h3>

  <p>
    Two particularly important geometric structures in GNI are:
  </p>

  <ol>
    <li>Symplectic structures (for Hamiltonian systems),</li>
    <li>Volume forms (for divergence-free or Hamiltonian flows).</li>
  </ol>

  <h4>Symplectic forms and Hamiltonian vector fields</h4>

  <p>
    A <strong>symplectic form</strong> on a manifold \(M\) is a closed, nondegenerate
    2-form \(\omega\), that is:
  </p>

  <ul>
    <li>\(\omega\) is a smooth bilinear, skew-symmetric form on each tangent space;</li>
    <li>\(d\omega = 0\) (closed);</li>
    <li>For each \(x\), the map \(T_xM \to T_x^*M\), \(v \mapsto \omega_x(v, \cdot)\), is an isomorphism (nondegenerate).</li>
  </ul>

  <p>
    On \(M = \mathbb{R}^{2m}\) with coordinates \(z=(q,p)\), the standard symplectic
    form is
  </p>

  <p class="math">
    \[
      \omega = \sum_{i=1}^m dq_i \wedge dp_i,
    \]
  </p>

  <p>
    or in matrix form, \(\omega(u,v) = u^\top \Omega v\) with the canonical symplectic
    matrix \(\Omega = \begin{pmatrix} 0 & I \\ -I & 0\end{pmatrix}\).
  </p>

  <p>
    Given a smooth function \(H : M \to \mathbb{R}\) called the <strong>Hamiltonian</strong>,
    the associated <strong>Hamiltonian vector field</strong> \(X_H\) is uniquely defined
    by
  </p>

  <p class="math">
    \[
      i_{X_H}\omega = dH,
    \]
  </p>

  <p>
    i.e. \(\omega(X_H, \cdot) = dH\). In canonical coordinates this yields Hamilton’s
    equations:
  </p>

  <p class="math">
    \[
      \dot{q} = \frac{\partial H}{\partial p}, \qquad
      \dot{p} = - \frac{\partial H}{\partial q}.
    \]
  </p>

  <p>
    The flow \(\varphi^t\) of a Hamiltonian vector field is <em>symplectic</em>,
    meaning
  </p>

  <p class="math">
    \[
      (\varphi^t)^* \omega = \omega,
    \]
  </p>

  <p>
    or in coordinates
    \(\,(D\varphi^t(z))^\top \Omega\, D\varphi^t(z) = \Omega\).
    This symplecticity implies conservation of phase-space volume (Liouville’s
    theorem) and many other qualitative properties; see <span class="citation">[HLW06, Ch. 1]</span>.
  </p>

  <h4>Volume-preserving flows</h4>

  <p>
    On \(M = \mathbb{R}^d\), the standard volume form is
    \(\mathrm{d}V = dx_1 \wedge \cdots \wedge dx_d\). A diffeomorphism
    \(\psi : M \to M\) is volume-preserving if
  </p>

  <p class="math">
    \[
      \psi^*(\mathrm{d}V) = \mathrm{d}V
      \quad \Longleftrightarrow \quad
      \det D\psi(x) = 1 \quad \forall x.
    \]
  </p>

  <p>
    For a vector field \(f\), the Lie derivative condition
    \(\mathcal{L}_f(\mathrm{d}V) = 0\) is equivalent to \(\nabla \cdot f = 0\):
    a <strong>divergence-free</strong> vector field generates a volume-preserving flow.
  </p>

  <p>
    Hamiltonian vector fields are divergence-free with respect to the canonical
    volume form, hence Hamiltonian flows are volume-preserving. There exist
    other classes of volume-preserving flows that are not symplectic, and GNI
    has developed specialized integrators for them; see <span class="citation">[HLW06, Ch. VI]</span>.
  </p>

  <figure id="tab-1-2">
    <table border="1" cellpadding="4" cellspacing="0" style="border-collapse:collapse; width:100%;">
      <thead>
        <tr>
          <th>Structure</th>
          <th>Defining property</th>
          <th>Flow condition</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Symplectic</td>
          <td>Closed, nondegenerate 2-form \(\omega\)</td>
          <td>\((\varphi^t)^*\omega = \omega\)</td>
        </tr>
        <tr>
          <td>Volume-preserving</td>
          <td>Volume form \(\mathrm{d}V\)</td>
          <td>\((\varphi^t)^*\mathrm{d}V = \mathrm{d}V\)</td>
        </tr>
        <tr>
          <td>Reversible</td>
          <td>Involution \(R : M \to M\)</td>
          <td>\(R \circ \varphi^t \circ R = \varphi^{-t}\)</td>
        </tr>
        <tr>
          <td>Invariant function</td>
          <td>First integral \(I : M \to \mathbb{R}\)</td>
          <td>\(I \circ \varphi^t = I\)</td>
        </tr>
      </tbody>
    </table>
    <figcaption>
      <strong>Table 1.2</strong> – Examples of geometric structures viewed as preserved
      objects under a flow \(\varphi^t\).
    </figcaption>
  </figure>

  <p class="task">
    Task marker: later chapters will introduce symplectic integrators whose discrete maps
    \(\Phi_h\) satisfy the same algebraic symplectic condition, and volume-preserving
    schemes with \(\det D\Phi_h = 1\).
  </p>

  <hr/>

  <h3 id="sec-1-2-6">1.2.6 Summary and Outlook</h3>

  <p>
    In this section we have:
  </p>

  <ul>
    <li>Defined vector fields and flows on manifolds,</li>
    <li>Formalized invariants as functions with zero Lie derivative,</li>
    <li>Introduced symmetries, reversibility, and the role of group actions,</li>
    <li>Used pullbacks, pushforwards, and Lie derivatives to express structure preservation,</li>
    <li>Characterized symplectic and volume-preserving flows as central geometric structures.</li>
  </ul>

  <p>
    Geometric numerical integrators are, in essence, numerical maps \(\Phi_h\) that
    attempt to mimic these preservation properties at the discrete level. In the
    next sections, we focus specifically on Hamiltonian systems and symplectic
    geometry (Chapter 2) and then on symplectic integrators (Chapter 3), following
    and expanding the treatment in <span class="citation">[BC26, HLW06]</span>.
  </p>

  <hr/>

  <h3 id="sec-1-2-7">1.2.7 References for Section 1.2</h3>

  <ol>
    <li id="ref-AM78">
      <strong>[AM78]</strong> R. Abraham, J.E. Marsden,
      <em>Foundations of Mechanics</em>, 2nd ed., Addison–Wesley, 1978.
      (Standard reference for differential geometry, symplectic forms, and Hamiltonian systems.)
    </li>
    <li id="ref-HLW06">
      <strong>[HLW06]</strong> E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>,
      2nd ed., Springer, 2006. (See especially Chapters I–III for flows, invariants, and symplecticity.)
    </li>
    <li id="ref-BC26">
      <strong>[BC26]</strong> S. Blanes, F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      Chapman &amp; Hall/CRC, 2026. (Introductory material on geometric structures and integrators.)
    </li>
  </ol>

</section>

<section id="sec-1-3">
  <h2>1.3 The Geometry of Flows</h2>

  <p>
    The purpose of this section is to explain how flows of ODEs can be understood
    geometrically: as one-parameter groups of diffeomorphisms generated by vector
    fields, acting on functions, forms, and structures on phase space.
  </p>

  <p>
    This viewpoint is essential in geometric numerical integration because it allows us
    to interpret a numerical method not merely as a recursion formula, but as a
    <em>discrete flow map</em> whose geometric properties can be studied, compared,
    and preserved. Our objective is to formalize the following ideas:
  </p>

  <ol>
    <li>The flow as a one-parameter group of diffeomorphisms,</li>
    <li>The infinitesimal generator as a derivation (Lie derivative),</li>
    <li>The exponential map linking vector fields and flows,</li>
    <li>The Baker–Campbell–Hausdorff (BCH) structure underlying splitting methods,</li>
    <li>Time-ordered exponentials for non-autonomous systems and their Magnus expansion.</li>
  </ol>

  <hr/>

  <!-- 1.3.1 -->
  <h3 id="sec-1-3-1">1.3.1 Flows as One-Parameter Groups of Diffeomorphisms</h3>

  <p>
    Let \(M\) be a smooth manifold and \(f\) a smooth vector field on \(M\).
    As previously defined, the flow of \(f\) is a smooth mapping
  </p>

  <p class="math">\[
      \varphi : D \subset \mathbb{R} \times M \to M, \qquad
      (t,x) \mapsto \varphi(t,x),
  \]</p>

  <p>
    where \(D\) is an open neighbourhood of \(\{0\}\times M\) and \(\varphi(0,x)=x\).
    For each fixed \(t\), define the <em>time-\(t\) map</em> \(\varphi^t(x):=\varphi(t,x)\).
  </p>

  <p>
    When the system is autonomous, the collection
    \(\{\varphi^t\}_{t\in\mathbb{R}}\) satisfies the <strong>group property</strong>:
  </p>

  <p class="math">\[
      \varphi^{t+s} = \varphi^t \circ \varphi^s,  \qquad  \varphi^0 = \mathrm{id}_M.
  \]</p>

  <p>
    Thus each \(\varphi^t\) is a diffeomorphism and the flow is a one-parameter
    subgroup of \(\mathrm{Diff}(M)\), the infinite-dimensional Lie group of
    diffeomorphisms of \(M\).  
    See Abraham–Marsden <span class="citation">[AM78]</span> for classical foundations.
  </p>

  <h4>Linearisation and tangent dynamics</h4>

  <p>
    Differentiating the flow map with respect to initial conditions yields the
    <strong>variational equation</strong>:
  </p>

  <p class="math">\[
      \frac{d}{dt}\Big(D\varphi^t(x)\Big)
      = Df(\varphi^t(x)) \, D\varphi^t(x).
  \]</p>

  <p>
    This governs the evolution of small perturbations. The matrix
    \(D\varphi^t(x)\) is the key object in deciding whether the flow preserves
    structures such as a symplectic form \(\omega\) or a volume form \(\mathrm{d}V\).
  </p>

  <hr/>

  <!-- 1.3.2 -->
  <h3 id="sec-1-3-2">1.3.2 The Lie Derivative: The Infinitesimal Generator of the Flow</h3>

  <p>
    A fundamental concept in differential geometry is that a vector field acts as an
    <strong>infinitesimal derivation</strong> on functions, tensor fields, and forms.
    This is formalised via the <em>Lie derivative</em>.
  </p>

  <h4>Action on functions</h4>

  <p>
    For a smooth function \(g : M \to \mathbb{R}\), the Lie derivative of \(g\) along \(f\)
    is defined by
  </p>

  <p class="math">\[
      (\mathcal{L}_f g)(x)
      = \left.\frac{d}{dt}\right|_{t=0} g(\varphi^t(x))
      = \nabla g(x)\cdot f(x).
  \]</p>

  <p>
    Thus \(f\) acts as a first-order differential operator. This is the basis for the
    concept of <em>invariant functions</em>, \(\mathcal{L}_f g = 0\), as covered in §1.2.
  </p>

  <h4>Action on vector fields</h4>

  <p>
    For a vector field \(X\) on \(M\), its Lie derivative with respect to \(f\) is
    the commutator:
  </p>

  <p class="math">\[
      \mathcal{L}_f X = [f,X].
  \]</p>

  <p>
    The commutator captures algebraic structure of vector fields and is the
    starting point for the Baker–Campbell–Hausdorff series used in splitting methods.
  </p>

  <hr/>

  <!-- 1.3.3 -->
  <h3 id="sec-1-3-3">1.3.3 Exponential of a Vector Field and Formal Flow Maps</h3>

  <p>
    A central conceptual tool is the formal identification of the flow \(\varphi^t\)
    of an autonomous vector field \(f\) with the exponential of the derivation
    \(f\cdot\nabla\).  Let
  </p>

  <p class="math">\[
      F := f\cdot\nabla
      = \sum_{i=1}^d f_i(x)\frac{\partial}{\partial x_i}.
  \]</p>

  <p>
    The flow operator acting on functions satisfies the ODE
  </p>

  <p class="math">\[
      \frac{d}{dt}(g \circ \varphi^t) = F(g\circ \varphi^t), \qquad (g\circ\varphi^0)=g.
  \]</p>

  <p>
    Solving gives the formal exponential representation:
  </p>

  <p class="math">\[
      g(\varphi^t(x)) = \big(e^{tF}g\big)(x),
  \]</p>

  <p>
    where
  </p>

  <p class="math">\[
      e^{tF} = \sum_{n=0}^\infty \frac{t^n}{n!} F^n.
    \]</p>

  <p>
    The operator \(e^{tF}\) is thus the abstract “flow operator.” In geometric
    numerical integration, splitting methods approximate \(e^{h(A+B)}\) by
    compositions of \(e^{hA}\) and \(e^{hB}\).
  </p>

  <h4>Figure 1.3 — Illustration of flow as exponential of generator</h4>

  <figure id="fig-1-3">
    <svg width="520" height="200" style="border:1px solid #ccc;">
      <!-- Conceptual diagram -->
      <text x="20" y="100" font-size="14">x</text>
      <text x="80" y="100" font-size="14">→</text>
      <text x="120" y="100" font-size="16">e^{tF}x</text>
      <line x1="130" y1="105" x2="260" y2="105"
            stroke="black" stroke-width="1" marker-end="url(#arrow)"/>
      <text x="270" y="100" font-size="14">φ^t(x)</text>

      <defs>
        <marker id="arrow" markerWidth="10" markerHeight="10"
                refX="5" refY="3" orient="auto">
          <path d="M0,0 L0,6 L9,3 z" fill="#000" />
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 1.3</strong> – The flow \(\varphi^t\) corresponds formally to
      the exponential map \(e^{tF}\) of the differential operator \(F=f\cdot\nabla\).
    </figcaption>
  </figure>

  <hr/>

  <!-- 1.3.4 -->
  <h3 id="sec-1-3-4">1.3.4 Baker–Campbell–Hausdorff (BCH) and the Lie Algebra of Flows</h3>

  <p>
    The set of vector fields on a manifold forms a Lie algebra under the commutator
    \([f,g]\).  
    The exponentials \(e^{tF}\) form local flows, and compositions of flows can be
    described using the <strong>Baker–Campbell–Hausdorff formula</strong>:
  </p>

  <p class="math">\[
      e^{hA} e^{hB}
      = \exp\!\left(
        h(A+B)
        + \tfrac{h^2}{2}[A,B]
        + \tfrac{h^3}{12}[A,[A,B]]
        - \tfrac{h^3}{12}[B,[A,B]]
        + \cdots
      \right).
  \]</p>

  <p>
    In our context, \(A\) and \(B\) are differential operators associated with
    vector fields (or Hamiltonian vector fields), and the BCH formula gives the
    exact vector field whose flow is approximated by a composition of subflows.
  </p>

  <p>
    This is the algebraic backbone of splitting methods, composition methods,
    and Magnus integrators. See Blanes & Casas <span class="citation">[BC26]</span> or
    Hairer–Lubich–Wanner <span class="citation">[HLW06]</span>.
  </p>

  <hr/>

  <!-- 1.3.5 -->
  <h3 id="sec-1-3-5">1.3.5 Non-Autonomous Flows and Time-Ordered Exponentials</h3>

  <p>
    For non-autonomous systems,
  </p>

  <p class="math">\[
      \dot{y} = f(t,y),
    \]</p>

  <p>
    the evolution operator \(\Phi^{t,s}\) (flow from time \(s\) to \(t\)) satisfies
  </p>

  <p class="math">\[
      \frac{\partial}{\partial t}(\Phi^{t,s}g)
      = F(t)\,\Phi^{t,s}g,
      \qquad F(t) := f(t,\cdot)\cdot\nabla,
  \]</p>

  <p>
    with \(\Phi^{s,s}=\mathrm{id}\). The formal solution is a
    <strong>time-ordered exponential</strong>:
  </p>

  <p class="math">\[
      \Phi^{t,s} = \mathcal{T}\exp\!\left(
        \int_s^t F(\tau)\, d\tau
      \right),
  \]</p>

  <p>
    where \(\mathcal{T}\) denotes chronological ordering:
  </p>

  <p class="math">\[
      \mathcal{T}\exp\!\left(\int_s^t F(\tau)\,d\tau\right)
      = \mathrm{id}
      + \int_s^t F(\tau_1)d\tau_1
      + \int_s^t\!\!\int_s^{\tau_1}
        F(\tau_1)F(\tau_2)\,d\tau_2\,d\tau_1
      + \cdots
    \]</p>

  <p>
    This formula is computationally useless in raw form, but it is the foundation
    for the <strong>Magnus expansion</strong>, which provides computable closed-form
    commutator expressions for accurate integrators of non-autonomous linear systems.
    See <span class="citation">[BC26, Ch. 5]</span>.
  </p>

  <hr/>

  <!-- 1.3.6 -->
  <h3 id="sec-1-3-6">1.3.6 Interactive Example: Flow Composition and BCH Behaviour</h3>

  <p>
    The example below shows how the composition of two simple planar flows
    behaves differently from their combined flow, illustrating non-commutativity
    of vector fields and the emergence of commutator terms.
  </p>

  <p>
    We consider vector fields
  </p>

  <p class="math">\[
      f(x,y) = (1,\,0), \qquad
      g(x,y) = (0,\,x),
    \]</p>

  <p>
    whose flows do not commute.
  </p>

  <figure id="fig-1-4">
    <canvas id="bchCanvas" width="520" height="260"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 1.4</strong> – Numerical experiment showing the non-commutativity
      of flows. We compare the composition
      \( \varphi_f^h \circ \varphi_g^h \) with
      \( \varphi_g^h \circ \varphi_f^h \).
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById('bchCanvas');
      if (!canvas) return;
      const ctx = canvas.getContext('2d');

      const w = canvas.width, h = canvas.height;
      ctx.font="12px sans-serif";

      // coordinate transforms
      const xmin=-1, xmax=3, ymin=-1, ymax=3;
      const X = x => (x-xmin)/(xmax-xmin)*w;
      const Y = y => h - (y-ymin)/(ymax-ymin)*h;

      // vector fields
      function f(x,y){ return {dx:1, dy:0}; }
      function g(x,y){ return {dx:0, dy:x}; }

      // flows for small h
      const hstep = 0.4;
      function flowF(x,y){
        return {x:x + hstep, y:y};
      }
      function flowG(x,y){
        return {x:x, y:y + hstep*x};
      }

      // initial point
      const x0 = 0.2, y0 = 0.5;

      // compositions
      let A = flowF(flowG(x0,y0).x, flowG(x0,y0).y); // F∘G
      let B = flowG(flowF(x0,y0).x, flowF(x0,y0).y); // G∘F

      ctx.clearRect(0,0,w,h);
      ctx.fillStyle="#000";

      // axes
      ctx.beginPath();
      ctx.moveTo(X(xmin), Y(0));
      ctx.lineTo(X(xmax), Y(0));
      ctx.moveTo(X(0), Y(ymin));
      ctx.lineTo(X(0), Y(ymax));
      ctx.strokeStyle="#888";
      ctx.stroke();

      // draw points
      function drawPoint(pt,color,label){
        ctx.fillStyle=color;
        ctx.beginPath();
        ctx.arc(X(pt.x),Y(pt.y),5,0,2*Math.PI);
        ctx.fill();
        ctx.fillText(label, X(pt.x)+7, Y(pt.y)-7);
      }

      drawPoint({x:x0,y:y0}, "#000", "x0");
      drawPoint(A, "#c00", "F∘G");
      drawPoint(B, "#006", "G∘F");

      // legend
      ctx.fillStyle="#c00"; ctx.fillRect(20,20,10,10);
      ctx.fillStyle="#000"; ctx.fillText("F∘G", 40, 28);
      ctx.fillStyle="#06c"; ctx.fillRect(20,40,10,10);
      ctx.fillStyle="#000"; ctx.fillText("G∘F", 40, 48);
    })();
  </script>

  <p>
    The separation of the red and blue points visualises the Lie bracket
    \([f,g]\neq 0\).  In splitting methods of order &gt; 1, these commutators
    appear explicitly in the error terms and are managed by higher-order compositions.
  </p>

  <hr/>

  <!-- 1.3.7 -->
  <h3 id="sec-1-3-7">1.3.7 Summary</h3>

  <p>
    In this section we have:
  </p>

  <ul>
    <li>Identified flows as one-parameter subgroups of diffeomorphisms,</li>
    <li>Introduced Lie derivatives as infinitesimal generators,</li>
    <li>Defined formal flow operators via exponentials of differential operators,</li>
    <li>Shown how BCH governs compositions of flows,</li>
    <li>Explained time-ordered exponentials and Magnus expansions for non-autonomous systems,</li>
    <li>Illustrated non-commutativity of vector fields via interactive examples.</li>
  </ul>

  <p>
    These ideas form the algebraic-geometric backbone of modern structure-preserving
    algorithms. We now move to Chapter 2, where symplectic geometry and Hamiltonian
    flows are developed rigorously.
  </p>

  <hr/>

  <h3 id="sec-1-3-8">1.3.8 References for Section 1.3</h3>

  <ol>
    <li>
      <strong>[AM78]</strong> R. Abraham &amp; J.E. Marsden,
      <em>Foundations of Mechanics</em>,
      Benjamin/Cummings, 1978.
    </li>
    <li>
      <strong>[HLW06]</strong> E. Hairer, C. Lubich &amp; G. Wanner,
      <em>Geometric Numerical Integration</em>, 2nd ed.,
      Springer, 2006.
    </li>
    <li>
      <strong>[BC26]</strong> S. Blanes &amp; F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>,
      2nd ed., CRC Press, 2026.
    </li>
  </ol>

</section>

<section id="sec-2-1">
  <h2>2.1 Symplectic Manifolds</h2>

  <p>
    Symplectic geometry provides the natural mathematical framework for Hamiltonian
    mechanics. In geometric numerical integration, the primary objective of a
    <strong>symplectic integrator</strong> is to preserve the underlying symplectic
    structure of the continuous system at the discrete level.
  </p>

  <p>
    This section formally introduces symplectic manifolds, symplectic forms,
    canonical coordinates, Darboux charts, and key structural identities.
    These concepts are foundational for Sections 2.2–2.3 and for all later
    Hamiltonian geometric integrators.
  </p>

  <hr/>

  <!-- 2.1.1 -->
  <h3 id="sec-2-1-1">2.1.1 Differential Forms and Alternating Bilinear Structures</h3>

  <p>
    Let \(M\) be a smooth manifold of even dimension \(2m\).
    A <strong>2-form</strong> on \(M\) is a smooth function assigning to each
    \(x\in M\) an alternating bilinear form
  </p>

  <p class="math">\[
      \omega_x : T_xM \times T_xM \to \mathbb{R}, \qquad
      \omega_x(u,v) = -\omega_x(v,u).
  \]</p>

  <p>
    A 2-form is called <em>non-degenerate</em> if
  </p>

  <p class="math">\[
      \forall x\in M: \quad \omega_x(u,\cdot)=0 \implies u=0.
  \]</p>

  <p>
    Non-degeneracy implies that the linear map
  </p>

  <p class="math">\[
      T_xM \to T_x^*M, \qquad 
      u \mapsto \omega_x(u,\cdot)
    \]</p>

  <p>
    is an isomorphism; hence \(\dim M\) must be even.
  </p>

  <p>
    The <strong>exterior derivative</strong> of a 2-form \(\omega\) is a 3-form
    \(d\omega\); the condition \(d\omega = 0\) is called <em>closedness</em>.
  </p>

  <figure id="fig-2-1" style="text-align:center;">
    <svg width="420" height="200" style="border:1px solid #ccc;">
      <text x="10" y="20" font-size="14">
        Alternating form ωₓ(u,v)
      </text>
      <!-- Basis vectors -->
      <line x1="200" y1="150" x2="260" y2="80"
            stroke="#006" stroke-width="2" marker-end="url(#arr1)"/>
      <line x1="200" y1="150" x2="140" y2="80"
            stroke="#900" stroke-width="2" marker-end="url(#arr2)"/>

      <text x="265" y="75" font-size="12">u</text>
      <text x="120" y="75" font-size="12">v</text>

      <!-- Area "parallelogram" -->
      <polygon points="200,150 260,80 320,150"
               fill="rgba(0,100,255,0.1)" stroke="#00f" stroke-width="1"/>

      <defs>
        <marker id="arr1" markerWidth="12" markerHeight="12" refX="5" refY="6"
                orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#006"/>
        </marker>
        <marker id="arr2" markerWidth="12" markerHeight="12" refX="5" refY="6"
                orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#900"/>
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 2.1</strong> – In each tangent space the 2-form
      \( \omega_x(u,v) \) measures a signed “symplectic area”.
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.1.2 -->
  <h3 id="sec-2-1-2">2.1.2 Symplectic Manifolds: Definitions</h3>

  <p><strong>Definition 2.1 (Symplectic manifold).</strong>
    A pair \( (M, \omega) \) is called a <em>symplectic manifold</em> if:
  </p>

  <ol>
    <li>\( \omega \) is a smooth 2-form on \(M\),</li>
    <li>\( \omega \) is <strong>non-degenerate</strong>,</li>
    <li>\( \omega \) is <strong>closed</strong>: \( d\omega = 0 \).</li>
  </ol>

  <p>
    A symplectic manifold is necessarily even-dimensional, but <em>unlike Riemannian
    manifolds it has no preferred notion of length or angle</em>.  It is purely
    “area-based”.
  </p>

  <h4>Canonical example (ℝ<sup>2m</sup> with standard ω)</h4>

  <p class="math">\[
      \omega_0 = \sum_{i=1}^m dq_i \wedge dp_i
      = dq_1\wedge dp_1 + \cdots + dq_m\wedge dp_m.
  \]</p>

  <p>
    In matrix form, writing \( z=(q,p) = (q_1,\dots,q_m,p_1,\dots,p_m) \),
    \(\omega_0(u,v) = u^\top \Omega v\), where
  </p>

  <p class="math">\[
      \Omega = \begin{pmatrix}
        0 & I_m\\
        -I_m & 0
      \end{pmatrix}.
    \]</p>

  <p>
    This will be the prototype for numerical symplecticity in later chapters.
  </p>

  <hr/>

  <!-- 2.1.3 -->
  <h3 id="sec-2-1-3">2.1.3 Darboux Theorem: All Symplectic Manifolds Look Locally Canonical</h3>

  <p><strong>Theorem 2.1 (Darboux, 1882).</strong>
    Let \( (M,\omega) \) be a symplectic manifold.  
    For every point \(x_0\in M\), there exists a neighbourhood \(U\) and local
    coordinates
  </p>

  <p class="math">\[
      (q_1,\dots,q_m,p_1,\dots,p_m): U \to \mathbb{R}^{2m}
  \]</p>

  <p>
    such that, in these coordinates,
  </p>

  <p class="math">\[
      \omega = \sum_{i=1}^m dq_i \wedge dp_i.
    \]</p>

  <p>
    Thus <em>all symplectic manifolds are locally “canonical”</em>, unlike Riemannian
    manifolds which have curvature invariants.
  </p>

  <figure id="fig-2-2" style="text-align:center;">
    <svg width="420" height="240" style="border:1px solid #ccc;">
      <text x="20" y="30" font-size="14">General symplectic manifold (M,ω)</text>
      <ellipse cx="200" cy="150" rx="150" ry="70"
               fill="none" stroke="#333"/>
      <rect x="260" y="40" width="140" height="100"
            fill="rgba(0,80,200,0.1)" stroke="#00f"/>
      <text x="270" y="60" font-size="12">(q,p)-chart</text>
      <line x1="240" y1="120" x2="260" y2="90"
            stroke="#333" marker-end="url(#arrow2)"/>
      <defs>
        <marker id="arrow2" markerWidth="10" markerHeight="10"
                refX="5" refY="3" orient="auto">
          <path d="M0,0 L0,6 L9,3 z" fill="#000"/>
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 2.2</strong> – Darboux theorem: locally, every symplectic manifold
      looks like standard \((q,p)\)-space.
    </figcaption>
  </figure>

  <p>
    Darboux's theorem is crucial because it implies that <strong>symplecticity is a
    coordinate-free property</strong>.
    Numerical symplectic integrators should therefore preserve the symplectic form
    in any coordinate chart.
  </p>

  <hr/>

  <!-- 2.1.4 -->
  <h3 id="sec-2-1-4">2.1.4 Symplectic Maps and Canonical Transformations</h3>

  <p><strong>Definition 2.2 (Symplectic diffeomorphism).</strong>
    A diffeomorphism \( \Psi : M \to M \) is <em>symplectic</em> if
  </p>

  <p class="math">\[
      \Psi^* \omega = \omega,
    \]</p>

  <p>
    or equivalently, for all \(x\in M\),
  </p>

  <p class="math">\[
      D\Psi(x)^\top\, \omega_{\Psi(x)}\, D\Psi(x) = \omega_x.
    \]</p>

  <p>
    A symplectic diffeomorphism is traditionally called a
    <strong>canonical transformation</strong> in classical mechanics.
  </p>

  <h4>Hamiltonian flows are symplectic</h4>

  <p><strong>Proposition 2.1.</strong>
    Let \(X_H\) be the Hamiltonian vector field defined by
    \(i_{X_H}\omega = dH\).  
    Then its flow \( \varphi_H^t \) satisfies
  </p>

  <p class="math">\[
      (\varphi_H^t)^*\omega = \omega.
    \]</p>

  <p>
    <em>Proof sketch.</em>
    Consider the Lie derivative:
  </p>

  <p class="math">\[
      \frac{d}{dt} (\varphi_H^t)^*\omega
      = (\varphi_H^t)^*(\mathcal{L}_{X_H}\omega)
      = (\varphi_H^t)^*(d(i_{X_H}\omega) + i_{X_H}d\omega)
      = (\varphi_H^t)^*(ddH + i_{X_H} 0)
      = 0.
    \]</p>

  <p>
    Thus, \((\varphi_H^t)^*\omega\) is constant in \(t\), equal to \(\omega\) at \(t=0\).
  </p>

  <p>
    This property is the backbone of the long-time qualitative accuracy of symplectic
    integrators.
  </p>

  <hr/>

  <!-- 2.1.5 -->
  <h3 id="sec-2-1-5">2.1.5 Symplectic Area Preservation: A Visual Demonstration</h3>

  <p>
    The distinguishing feature of symplectic maps is that they preserve oriented
    2-dimensional areas defined by the symplectic form, not necessarily Euclidean
    areas.
  </p>

  <p>
    The interactive figure below demonstrates how a linear map behaves when it is:
  </p>
  <ul>
    <li>symplectic (area preserved),</li>
    <li>not symplectic (area distorted).</li>
  </ul>

  <figure id="fig-2-3" style="text-align:center;">
    <canvas id="sympCanvas" width="620" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.3</strong> – Symplectic vs non-symplectic linear transformations.
      We compare the transformed unit square under a symplectic matrix
      \(A\) (e.g. rotation in the \((q,p)\)-plane) and under a non-symplectic matrix
      (shear or scaling). Symplectic area (ω-area) is preserved, Euclidean area need not be.
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById("sympCanvas");
      if (!canvas) return;
      const ctx = canvas.getContext("2d");

      const w = canvas.width, h = canvas.height;

      // Coordinate maps
      const xmin=-2, xmax=2, ymin=-2, ymax=2;
      const X = x => (x-xmin)/(xmax-xmin)*w;
      const Y = y => h - (y-ymin)/(ymax-ymin)*h;

      // Base shape (unit square)
      const square = [
        {x:0, y:0}, {x:1, y:0}, {x:1, y:1}, {x:0, y:1}
      ];

      // Symplectic example: rotation
      const theta = Math.PI/6;
      const A_symp = [
        [ Math.cos(theta), Math.sin(theta)],
        [-Math.sin(theta), Math.cos(theta)]
      ];

      // Non-symplectic example: shear
      const A_nons = [
        [1.3, 0.6],
        [0.0, 1.0]
      ];

      function apply(A, p){
        return {
          x: A[0][0]*p.x + A[0][1]*p.y,
          y: A[1][0]*p.x + A[1][1]*p.y
        };
      }

      function drawPolygon(poly,color,label){
        ctx.beginPath();
        ctx.moveTo(X(poly[0].x),Y(poly[0].y));
        for(let k=1;k<poly.length;k++)
          ctx.lineTo(X(poly[k].x),Y(poly[k].y));
        ctx.closePath();
        ctx.strokeStyle=color; 
        ctx.lineWidth=2; 
        ctx.stroke();
        ctx.fillStyle=color;
        ctx.fillText(label, X(poly[2].x)+5, Y(poly[2].y)-5);
      }

      ctx.clearRect(0,0,w,h);
      ctx.font="14px sans-serif";

      // draw axes
      ctx.strokeStyle="#888";
      ctx.beginPath();
      ctx.moveTo(X(xmin),Y(0)); ctx.lineTo(X(xmax),Y(0));
      ctx.moveTo(X(0),Y(ymin)); ctx.lineTo(X(0),Y(ymax));
      ctx.stroke();

      // Transform shapes
      const sq_symp = square.map(pt => apply(A_symp, pt));
      const sq_nons = square.map(pt => apply(A_nons, pt));

      // Draw
      drawPolygon(square,"#000","original");
      drawPolygon(sq_symp,"#06c","symplectic");
      drawPolygon(sq_nons,"#c00","non-symplectic");
    })();
  </script>

  <p>
    Notice that:
  </p>

  <ul>
    <li>
      The <em>symplectic</em> map preserves the oriented parallelogram area under
      \(dq\wedge dp\). Indeed for symplectic \(A\),  
      \( A^\top \Omega A = \Omega \).
    </li>
    <li>
      The non-symplectic map distorts symplectic area, violating the defining identity.
    </li>
  </ul>

  <hr/>

  <!-- 2.1.6 -->
  <h3 id="sec-2-1-6">2.1.6 Summary</h3>

  <p>
    In this section we introduced:
  </p>

  <ul>
    <li>2-forms and alternating bilinear structures,</li>
    <li>definition of symplectic manifolds,</li>
    <li>Darboux theorem (local canonical structure),</li>
    <li>symplectic diffeomorphisms and canonical transformations,</li>
    <li>Hamiltonian flows as symplectic maps,</li>
    <li>visual and numerical illustrations of symplectic area preservation.</li>
  </ul>

  <p>
    These ideas are the backbone of symplectic integration.  
    Section 2.2 will introduce <strong>Hamiltonian vector fields</strong>,
    <strong>Poisson brackets</strong>, and the deep relation between \(\omega\),
    Hamilton's equations, and structure preservation.
  </p>

  <hr/>

  <!-- References -->
  <h3 id="sec-2-1-7">2.1.7 References for Section 2.1</h3>

  <ol>
    <li><strong>[AM78]</strong> R. Abraham &amp; J.E. Marsden,  
      <em>Foundations of Mechanics</em>, 2nd ed., Addison–Wesley, 1978.
    </li>
    <li><strong>[Arn89]</strong> V.I. Arnold,  
      <em>Mathematical Methods of Classical Mechanics</em>, 2nd ed.,
      Springer, 1989.
    </li>
    <li><strong>[MS17]</strong> D. McDuff &amp; D. Salamon,  
      <em>Introduction to Symplectic Topology</em>, 3rd ed.,
      Oxford University Press, 2017.
    </li>
    <li><strong>[HLW06]</strong> E. Hairer, C. Lubich &amp; G. Wanner,
      <em>Geometric Numerical Integration</em>, 2nd ed., Springer, 2006.
    </li>
    <li><strong>[BC26]</strong> S. Blanes &amp; F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>,
      2nd ed., CRC Press, 2026.
    </li>
  </ol>

</section>

<section id="sec-2-2">
  <h2>2.2 Hamiltonian Vector Fields and Poisson Brackets</h2>

  <p>
    Hamiltonian mechanics is naturally expressed on a symplectic manifold
    \((M,\omega)\) by associating to each <em>Hamiltonian function</em> 
    \(H : M \to \mathbb{R}\) a unique vector field \(X_H\) via the
    symplectic form. In canonical coordinates, this yields Hamilton’s equations.
    In this section we:
  </p>

  <ol>
    <li>Define Hamiltonian vector fields on a symplectic manifold,</li>
    <li>Derive Hamilton’s equations in \((q,p)\)-coordinates,</li>
    <li>Introduce the Poisson bracket and its properties,</li>
    <li>Work through simple examples,</li>
    <li>Visualise Hamiltonian flows as tangent to level sets of \(H\).</li>
  </ol>

  <hr/>

  <!-- 2.2.1 -->
  <h3 id="sec-2-2-1">2.2.1 Hamiltonian Vector Fields on a Symplectic Manifold</h3>

  <p>
    Let \((M,\omega)\) be a symplectic manifold as defined in §2.1. For each smooth
    Hamiltonian \(H : M \to \mathbb{R}\), we define the associated
    <strong>Hamiltonian vector field</strong> \(X_H\) by:
  </p>

  <p class="math">
    \[
      i_{X_H}\,\omega = dH,
    \]
  </p>

  <p>
    where \(i_{X_H}\) denotes interior contraction with the vector field \(X_H\).
    At each point \(x\in M\),
  </p>

  <p class="math">
    \[
      \omega_x(X_H(x), \cdot) = dH_x(\cdot).
    \]
  </p>

  <p>
    Because \(\omega_x\) is non-degenerate, this relation uniquely determines
    \(X_H(x)\) for each \(x\), giving a globally defined vector field \(X_H\).
  </p>

  <h4>Interpretation</h4>

  <p>
    The map
  </p>

  <p class="math">
    \[
      \flat_\omega : T_xM \to T_x^*M, 
      \qquad v \mapsto \omega_x(v,\cdot)
    \]
  </p>

  <p>
    is an isomorphism (“musical isomorphism”). Then
  </p>

  <p class="math">
    \[
      X_H(x) = \big(\flat_\omega^{-1}\big)(dH_x),
    \]
  </p>

  <p>
    i.e. \(X_H\) is the vector field obtained by “raising the index” of the
    differential \(dH\) using the symplectic form. The resulting flow
    \(\varphi_H^t\) is the Hamiltonian evolution of the system with Hamiltonian \(H\).
  </p>

  <hr/>

  <!-- 2.2.2 -->
  <h3 id="sec-2-2-2">2.2.2 Hamilton’s Equations in Canonical Coordinates</h3>

  <p>
    On the standard symplectic vector space \(M = \mathbb{R}^{2m}\) with coordinates
    \(z = (q,p) = (q_1,\dots,q_m,p_1,\dots,p_m)\) and symplectic form
  </p>

  <p class="math">
    \[
      \omega_0 = \sum_{i=1}^m dq_i \wedge dp_i,
    \]
  </p>

  <p>
    the Hamiltonian vector field has the familiar coordinate expression
    given by <strong>Hamilton’s equations</strong>.
  </p>

  <p>
    Writing \(X_H(z) = (\dot{q},\dot{p})\), the condition
    \(i_{X_H}\omega_0 = dH\) yields
  </p>

  <p class="math">
    \[
      \dot{q}_i = \frac{\partial H}{\partial p_i},
      \qquad
      \dot{p}_i = -\frac{\partial H}{\partial q_i},
      \qquad i=1,\dots,m.
    \]
  </p>

  <p>
    In matrix notation, with
  </p>

  <p class="math">
    \[
      \Omega = \begin{pmatrix}
        0 & I_m\\
        -I_m & 0
      \end{pmatrix},
      \qquad
      z = \begin{pmatrix}q\\p\end{pmatrix},
    \]
  </p>

  <p>
    we can write the Hamiltonian system as
  </p>

  <p class="math">
    \[
      \dot{z} = X_H(z) = \Omega \nabla H(z).
    \]
  </p>

  <p>
    The flow \(\varphi_H^t\) generated by this ODE is symplectic, as shown
    in §2.1.4.
  </p>

  <hr/>

  <!-- 2.2.3 -->
  <h3 id="sec-2-2-3">2.2.3 Energy Conservation and Tangency to Level Sets</h3>

  <p>
    A fundamental property of Hamiltonian flows is that the Hamiltonian itself
    is a first integral of its own flow.
  </p>

  <p><strong>Proposition 2.2 (Conservation of energy).</strong>
    Let \(H : M \to \mathbb{R}\) be a Hamiltonian and \(X_H\) the associated
    Hamiltonian vector field. Then, along the flow \(\varphi_H^t\),
  </p>

  <p class="math">
    \[
      \frac{d}{dt} H(\varphi_H^t(x)) = 0.
    \]
  </p>

  <p><em>Proof.</em>
    We have
  </p>

  <p class="math">
    \[
      \frac{d}{dt} H(\varphi_H^t(x))
      = dH_{\varphi_H^t(x)}\!\big(\dot{\varphi}_H^t(x)\big)
      = dH_{\varphi_H^t(x)}\!\big(X_H(\varphi_H^t(x))\big).
    \]
  </p>

  <p>
    Using the defining relation \(i_{X_H}\omega = dH\), we get
  </p>

  <p class="math">
    \[
      dH(X_H) = \omega(X_H, X_H) = 0
    \]
  </p>

  <p>
    because \(\omega\) is skew-symmetric. Hence the derivative vanishes identically.
    \(\square\)
  </p>

  <p>
    Thus Hamiltonian trajectories lie on level sets of \(H\). In canonical
    coordinates this means:
  </p>

  <p class="math">
    \[
      \nabla H(z) \cdot X_H(z) = 0,
    \]
  </p>

  <p>
    i.e. the vector field is everywhere tangent to the level surfaces of \(H\).
  </p>

  <figure id="fig-2-4" style="text-align:center;">
    <canvas id="hamFlowCanvas" width="620" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.4</strong> – Level sets of a Hamiltonian
      \(H(q,p) = \tfrac{1}{2}(p^2 + q^2)\) (circles) with Hamiltonian vector field
      \(X_H = (p, -q)\) shown as arrows. Arrows are tangent to the level sets,
      illustrating energy conservation.
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById("hamFlowCanvas");
      if (!canvas) return;
      const ctx = canvas.getContext("2d");

      const w = canvas.width, h = canvas.height;
      const xmin=-2, xmax=2, ymin=-2, ymax=2;
      const X = x => (x-xmin)/(xmax-xmin)*w;
      const Y = y => h - (y-ymin)/(ymax-ymin)*h;

      ctx.clearRect(0,0,w,h);
      ctx.font = "12px sans-serif";

      // Draw axes
      ctx.strokeStyle="#999";
      ctx.beginPath();
      ctx.moveTo(X(xmin), Y(0)); ctx.lineTo(X(xmax), Y(0));
      ctx.moveTo(X(0), Y(ymin)); ctx.lineTo(X(0), Y(ymax));
      ctx.stroke();

      // Draw some level sets of H = (p^2 + q^2)/2: circles
      ctx.strokeStyle="#ccc";
      const radii = [0.5,1,1.5];
      radii.forEach(r => {
        ctx.beginPath();
        ctx.arc(X(0), Y(0),
                r/(xmax-xmin)*w*0.5*2, // approximate scaling
                0, 2*Math.PI);
        ctx.stroke();
      });

      // Vector field X_H = (p, -q)
      ctx.strokeStyle="#006";
      const N = 13;
      for(let i=0;i<N;i++){
        for(let j=0;j<N;j++){
          const q = xmin + (xmax-xmin)*i/(N-1);
          const p = ymin + (ymax-ymin)*j/(N-1);
          const dx = p, dy = -q;
          const norm = Math.sqrt(dx*dx+dy*dy) || 1e-6;
          const scale = 0.25;
          const uq = dx/norm*scale;
          const up = dy/norm*scale;
          const x1 = X(q-0.5*uq);
          const y1 = Y(p-0.5*up);
          const x2 = X(q+0.5*uq);
          const y2 = Y(p+0.5*up);
          ctx.beginPath();
          ctx.moveTo(x1,y1);
          ctx.lineTo(x2,y2);
          ctx.stroke();
        }
      }
    })();
  </script>

  <hr/>

  <!-- 2.2.4 -->
  <h3 id="sec-2-2-4">2.2.4 The Poisson Bracket</h3>

  <p>
    On a symplectic manifold \((M,\omega)\), the assignment \(H \mapsto X_H\)
    can be used to define a Lie algebra structure on smooth functions via the
    <strong>Poisson bracket</strong>.
  </p>

  <p><strong>Definition 2.3 (Poisson bracket).</strong>
    For \(F,G \in C^\infty(M)\), their Poisson bracket is
  </p>

  <p class="math">
    \[
      \{F,G\} := \omega(X_F,X_G)
      = dF(X_G) = -\,dG(X_F).
    \]
  </p>

  <p>
    In canonical coordinates on \(\mathbb{R}^{2m}\), this reduces to the familiar
    formula
  </p>

  <p class="math">
    \[
      \{F,G\}
      = \sum_{i=1}^m
        \left(
          \frac{\partial F}{\partial q_i}
          \frac{\partial G}{\partial p_i}
          - 
          \frac{\partial F}{\partial p_i}
          \frac{\partial G}{\partial q_i}
        \right).
    \]
  </p>

  <h4>Basic properties</h4>

  <p>
    The Poisson bracket has the following properties:
  </p>

  <ol>
    <li><strong>Bilinearity:</strong> \(\{aF + bG, H\} = a\{F,H\} + b\{G,H\}\).</li>
    <li><strong>Skew-symmetry:</strong> \(\{F,G\} = -\{G,F\}\).</li>
    <li><strong>Leibniz rule:</strong> \(\{F,GH\} = \{F,G\}H + G\{F,H\}\).</li>
    <li><strong>Jacobi identity:</strong> \(\{F,\{G,H\}\} + \{G,\{H,F\}\} + \{H,\{F,G\}\}=0.\)</li>
  </ol>

  <p>
    In particular, the Jacobi identity means that \((C^\infty(M),\{\cdot,\cdot\})\)
    is a Lie algebra. The map
  </p>

  <p class="math">
    \[
      C^\infty(M) \to \mathfrak{X}(M), \qquad 
      H \mapsto X_H
    \]
  </p>

  <p>
    is a Lie algebra homomorphism up to sign:
  </p>

  <p class="math">
    \[
      [X_F,X_G] = X_{\{F,G\}}.
    \]
  </p>

  <p>
    This identity is pivotal in the analysis of splitting and composition methods,
    where commutators of vector fields appear in the BCH expansion (see §1.3.4).
  </p>

  <hr/>

  <!-- 2.2.5 -->
  <h3 id="sec-2-2-5">2.2.5 Constants of Motion and Poisson Commutation</h3>

  <p>
    Let \(H\) be the Hamiltonian of the system. A function \(I : M\to\mathbb{R}\)
    is a <em>constant of motion</em> (first integral) if
  </p>

  <p class="math">
    \[
      \{I,H\} = 0.
    \]
  </p>

  <p>
    To see this, note that the time derivative of \(I\) along the Hamiltonian flow is
  </p>

  <p class="math">
    \[
      \frac{d}{dt} I(\varphi_H^t(x))
      = \{I,H\}(\varphi_H^t(x)).
    \]
  </p>

  <p>
    Thus \(\frac{d}{dt} I(\varphi_H^t(x)) = 0\) iff \(\{I,H\} = 0\) along the trajectory.
  </p>

  <p>
    When we design geometric integrators, we are often interested in methods that
    preserve certain Poisson commuting quantities, at least approximately.
  </p>

  <hr/>

  <!-- 2.2.6 -->
  <h3 id="sec-2-2-6">2.2.6 Examples</h3>

  <h4>(a) Harmonic oscillator in ℝ²</h4>

  <p>
    For the harmonic oscillator with Hamiltonian
  </p>

  <p class="math">
    \[
      H(q,p) = \tfrac{1}{2}(p^2 + q^2),
    \]
  </p>

  <p>
    we have
  </p>

  <p class="math">
    \[
      \frac{\partial H}{\partial p} = p, \qquad
      \frac{\partial H}{\partial q} = q,
    \]
  </p>

  <p>
    thus
  </p>

  <p class="math">
    \[
      \dot{q} = p, \qquad \dot{p} = -q.
    \]
  </p>

  <p>
    The flow is a rotation in phase space; energy level sets are concentric circles.
  </p>

  <h4>(b) Central force in ℝ³</h4>

  <p>
    Consider a particle in \(\mathbb{R}^3\) with position \(x\) and momentum \(p\),
    Hamiltonian
  </p>

  <p class="math">
    \[
      H(x,p) = \frac{1}{2m} |p|^2 + V(|x|),
    \]
  </p>

  <p>
    where \(V\) is a radial potential. The angular momentum
  </p>

  <p class="math">
    \[
      L = x \times p
    \]
  </p>

  <p>
    is a constant of motion, which can be verified by checking \(\{L_i,H\}=0\),
    or geometrically via rotational symmetry and Noether’s theorem. This is a
    basic example where geometric structure (rotational invariance) leads to
    conserved quantities.
  </p>

  <figure id="tab-2-2">
    <table border="1" cellpadding="4" cellspacing="0"
           style="border-collapse:collapse; width:100%;">
      <thead>
        <tr>
          <th>Hamiltonian \(H\)</th>
          <th>Phase space</th>
          <th>Hamiltonian vector field \(X_H\)</th>
          <th>Conserved quantity</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>\(\tfrac{1}{2}(p^2 + q^2)\)</td>
          <td>\(\mathbb{R}^2\)</td>
          <td>\((p,-q)\)</td>
          <td>Energy \(H\)</td>
        </tr>
        <tr>
          <td>\(\tfrac{1}{2m}|p|^2 + V(|x|)\)</td>
          <td>\(\mathbb{R}^3\times\mathbb{R}^3\)</td>
          <td>\((p/m,\,-\nabla V)\)</td>
          <td>Energy \(H\), angular momentum \(L\)</td>
        </tr>
      </tbody>
    </table>
    <figcaption>
      <strong>Table 2.2</strong> – Examples of Hamiltonian vector fields and constants of motion.
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.2.7 -->
  <h3 id="sec-2-2-7">2.2.7 Interactive Poisson Bracket Explorer (2D)</h3>

  <p>
    The small interactive demo below evaluates the Poisson bracket
    \(\{F,G\}\) at a grid of points for some simple choices of
    functions \(F,G\) in the plane. It highlights (in colour) where
    the bracket vanishes.
  </p>

  <figure id="fig-2-5" style="text-align:center;">
    <canvas id="pbCanvas" width="620" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.5</strong> – Approximate sign of \(\{F,G\}\) on a grid
      in \((q,p)\)-space for selected functions \(F,G\). Blue points ≈ negative,
      red points ≈ positive, gray ≈ near zero.
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById("pbCanvas");
      if (!canvas) return;
      const ctx = canvas.getContext("2d");

      const w = canvas.width, h = canvas.height;
      const xmin=-2, xmax=2, ymin=-2, ymax=2;
      const X = x => (x-xmin)/(xmax-xmin)*w;
      const Y = y => h - (y-ymin)/(ymax-ymin)*h;

      // Example: choose F(q,p) = H(q,p) = (p^2+q^2)/2, G(q,p) = q
      function F(q,p){ return 0.5*(p*p+q*q); }
      function G(q,p){ return q; }

      function dF_dq(q,p){ return q; }
      function dF_dp(q,p){ return p; }
      function dG_dq(q,p){ return 1; }
      function dG_dp(q,p){ return 0; }

      function poisson(q,p){
        return dF_dq(q,p)*dG_dp(q,p) - dF_dp(q,p)*dG_dq(q,p);
      }

      ctx.clearRect(0,0,w,h);
      ctx.font="12px sans-serif";

      // axes
      ctx.strokeStyle="#999";
      ctx.beginPath();
      ctx.moveTo(X(xmin),Y(0)); ctx.lineTo(X(xmax),Y(0));
      ctx.moveTo(X(0),Y(ymin)); ctx.lineTo(X(0),Y(ymax));
      ctx.stroke();

      const N = 40;
      for(let i=0;i<N;i++){
        for(let j=0;j<N;j++){
          const q = xmin + (xmax-xmin)*(i+0.5)/N;
          const p = ymin + (ymax-ymin)*(j+0.5)/N;
          const val = poisson(q,p);
          let color;
          const eps = 0.2;
          if (Math.abs(val) < eps) color = "#aaa";
          else if (val > 0) color = "#c00";
          else color = "#06c";
          ctx.fillStyle = color;
          ctx.fillRect(X(q)-2, Y(p)-2, 4, 4);
        }
      }

      ctx.fillStyle="#000";
      ctx.fillText("Example: F = H = (p^2+q^2)/2, G = q ⇒ {F,G} = -p", 10, 20);
      ctx.fillText("Gray: |{F,G}| ≈ small, blue/red: negative/positive", 10, 36);
    })();
  </script>

  <p>
    In this example, \(\{H,q\} = -p\), so the bracket vanishes along the
    horizontal axis \(p=0\) and changes sign across it. This simple picture
    connects the algebraic definition with a geometric field on phase space.
  </p>

  <hr/>

  <!-- 2.2.8 -->
  <h3 id="sec-2-2-8">2.2.8 Summary and Outlook</h3>

  <p>
    We have:
  </p>

  <ul>
    <li>Defined Hamiltonian vector fields via the symplectic form,</li>
    <li>Derived Hamilton’s equations in canonical coordinates,</li>
    <li>Shown that Hamiltonian flows conserve energy and are tangent to level sets of \(H\),</li>
    <li>Introduced the Poisson bracket and its key Lie-algebraic properties,</li>
    <li>Connected Poisson commuting functions to constants of motion.</li>
  </ul>

  <p>
    In the next section (2.3), we develop the role of symmetry in Hamiltonian
    systems, introduce <strong>momentum maps</strong>, and state a version of
    <strong>Noether’s theorem</strong> in the symplectic setting, preparing
    the ground for symmetry-preserving geometric integrators.
  </p>

  <hr/>

  <h3 id="sec-2-2-9">2.2.9 References for Section 2.2</h3>

  <ol>
    <li><strong>V.I. Arnold</strong>,
      <em>Mathematical Methods of Classical Mechanics</em>, 2nd ed., Springer, 1989.
    </li>
    <li><strong>R. Abraham &amp; J.E. Marsden</strong>,
      <em>Foundations of Mechanics</em>, 2nd ed., Addison–Wesley, 1978.
    </li>
    <li><strong>D. McDuff &amp; D. Salamon</strong>,
      <em>Introduction to Symplectic Topology</em>, 3rd ed., Oxford Univ. Press, 2017.
    </li>
    <li><strong>E. Hairer, C. Lubich &amp; G. Wanner</strong>,
      <em>Geometric Numerical Integration</em>, 2nd ed., Springer, 2006.
    </li>
    <li><strong>S. Blanes &amp; F. Casas</strong>,
      <em>A Concise Introduction to Geometric Numerical Integration</em>,
      2nd ed., CRC Press, 2026.
    </li>
  </ol>

</section>

<section id="sec-2-3">
  <h2>2.3 Symmetries, Momentum Maps, and Noether’s Theorem</h2>

  <p>
    The structure of Hamiltonian systems is deeply connected with symmetry.
    Continuous symmetries give rise to conserved quantities, and these conserved
    quantities in turn constrain the geometry of the system’s flow.
    This section formalises:
  </p>

  <ol>
    <li>Symplectic group actions and infinitesimal generators,</li>
    <li>Momentum maps and their characterisation,</li>
    <li>Noether’s theorem in the symplectic setting,</li>
    <li>Examples: rotations, translations, angular momentum, linear momentum,</li>
    <li>Visualisation of symmetric Hamiltonian flows.</li>
  </ol>

  <hr/>

  <!-- 2.3.1 -->
  <h3 id="sec-2-3-1">2.3.1 Symmetries as Group Actions on Symplectic Manifolds</h3>

  <p>
    Let \(G\) be a Lie group with Lie algebra \(\mathfrak{g}\).
    A smooth (left) group action on a symplectic manifold \((M,\omega)\) is a map
  </p>

  <p class="math">
    \[
      \Phi: G \times M \to M,
      \qquad
      \Phi(g,x) = g\cdot x,
    \]
  </p>

  <p>
    satisfying:
  </p>

  <ul>
    <li>\(e\cdot x = x\) for identity \(e\in G\),</li>
    <li>\(g_1\cdot (g_2\cdot x) = (g_1g_2)\cdot x\).</li>
  </ul>

  <p>
    The action is called <em>symplectic</em> if each map
  </p>

  <p class="math">
    \[
      \Phi_g : M \to M, \qquad x\mapsto g\cdot x,
    \]
  </p>

  <p>
    is a symplectic diffeomorphism:
  </p>

  <p class="math">
    \[
      \Phi_g^* \omega = \omega.
    \]
  </p>

  <hr/>

  <!-- 2.3.2 -->
  <h3 id="sec-2-3-2">2.3.2 Infinitesimal Generators of Group Actions</h3>

  <p>
    For each \(\xi \in \mathfrak{g}\) we define the <strong>infinitesimal generator</strong>
    of the action:
  </p>

  <p class="math">
    \[
      \xi_M(x) := \left.\frac{d}{dt}\right|_{t=0} \exp(t\xi)\cdot x \in T_xM.
    \]
  </p>

  <p>
    Because the action is symplectic, each \(\xi_M\) satisfies:
  </p>

  <p class="math">
    \[
      \mathcal{L}_{\xi_M}\omega = 0.
    \]
  </p>

  <p>
    The vector field \(\xi_M\) is symplectic but not necessarily Hamiltonian.
    If there exists a smooth function \(J_\xi\) such that
  </p>

  <p class="math">
    \[
      i_{\xi_M}\omega = dJ_\xi,
    \]
  </p>

  <p>
    then the symmetry is called <strong>Hamiltonian</strong>.
  </p>

  <hr/>

  <!-- 2.3.3 -->
  <h3 id="sec-2-3-3">2.3.3 Momentum Maps</h3>

  <p>
    For a Hamiltonian group action, the map
  </p>

  <p class="math">
    \[
      J : M \to \mathfrak{g}^*,
    \]
  </p>

  <p>
    is called the <strong>momentum map</strong> if
  </p>

  <p class="math">
    \[
      \langle J(x), \xi\rangle = J_\xi(x),
      \qquad
      dJ_\xi = i_{\xi_M}\omega,
    \]
  </p>

  <p>
    for all \(\xi\in\mathfrak{g}\).
  </p>

  <p>
    The momentum map collects all conserved quantities associated with the symmetry.
  </p>

  <h4>Equivariance</h4>

  <p>
    A momentum map is called <strong>equivariant</strong> if:
  </p>

  <p class="math">
    \[
      J(g\cdot x) = \mathrm{Ad}^*_{g} \, J(x),
    \]
  </p>

  <p>
    where \(\mathrm{Ad}^*\) is the coadjoint action.  
    Equivariance leads to powerful structural results but is not strictly required
    for basic conservation laws.
  </p>

  <hr/>

  <!-- 2.3.4 -->
  <h3 id="sec-2-3-4">2.3.4 Noether’s Theorem in the Symplectic Setting</h3>

  <p><strong>Theorem 2.3 (Noether).</strong>
    Let \(G\) act on a symplectic manifold \((M,\omega)\) by symplectic
    diffeomorphisms. Suppose the Hamiltonian \(H : M\to\mathbb{R}\) is
    invariant under the action:
  </p>

  <p class="math">
    \[
      H(g\cdot x) = H(x),\qquad \forall g\in G.
    \]
  </p>

  <p>
    Then for each \(\xi\in\mathfrak{g}\), the corresponding momentum map
    component \(J_\xi = \langle J,\xi\rangle\) satisfies:
  </p>

  <p class="math">
    \[
      \{J_\xi, H\} = 0.
    \]
  </p>

  <p>
    That is, <em>symmetry implies a conserved quantity</em>.
  </p>

  <h4>Proof sketch</h4>

  <p>
    If \(H\) is invariant under the flow of \(\xi_M\), then:
  </p>

  <p class="math">
    \[
      \mathcal{L}_{\xi_M} H = 0.
    \]
  </p>

  <p>
    But
  </p>

  <p class="math">
    \[
      \mathcal{L}_{\xi_M} H
      = dH(\xi_M)
      = \omega(X_H,\xi_M)
      = \{J_\xi, H\}.
    \]
  </p>

  <p>
    Hence the Poisson bracket vanishes, giving conservation of \(J_\xi\).
  </p>

  <hr/>

  <!-- 2.3.5 -->
  <h3 id="sec-2-3-5">2.3.5 Examples of Momentum Maps</h3>

  <h4>(a) Spatial translations</h4>

  <p>
    On \(M=\mathbb{R}^{2m}\) with coordinates \((q,p)\), the group \(G=\mathbb{R}^m\)
    acts by translations:
  </p>

  <p class="math">
    \[
      v \cdot (q,p) = (q+v,p).
    \]
  </p>

  <p>
    The infinitesimal generator corresponding to direction \(e_i\in\mathbb{R}^m\) is
    simply
  </p>

  <p class="math">
    \[
      (e_i)_M = \frac{\partial}{\partial q_i}.
    \]
  </p>

  <p>
    Solving \(i_{(e_i)_M}\omega = dJ_{e_i}\) gives
  </p>

  <p class="math">
    \[
      J_{e_i} = p_i.
    \]
  </p>

  <p>
    Thus the momentum map is \(J(q,p) = p\), i.e. linear momentum.
  </p>

  <h4>(b) Rotations in \(\mathbb{R}^3\)</h4>

  <p>
    For \(G = SO(3)\) acting on phase space
    \(M = T^*\mathbb{R}^3 \cong \mathbb{R}^3 \times \mathbb{R}^3\) by rotations:
  </p>

  <p class="math">
    \[
      R\cdot(x,p) = (Rx, Rp),
    \]
  </p>

  <p>
    the Lie algebra \(\mathfrak{so}(3)\) identifies with \(\mathbb{R}^3\),
    with infinitesimal action:
  </p>

  <p class="math">
    \[
      \xi_M = (\xi \times x,\, \xi \times p).
    \]
  </p>

  <p>
    Then the momentum map is
  </p>

  <p class="math">
    \[
      J(x,p) = x\times p = L,
    \]
  </p>

  <p>
    i.e. the angular momentum vector.
  </p>

  <figure id="fig-2-6" style="text-align:center;">
    <svg width="500" height="260" style="border:1px solid #ccc;">
      <text x="10" y="20" font-size="14">Angular momentum: J(x,p)=x×p</text>
      <!-- Cross product diagram -->
      <line x1="180" y1="140" x2="260" y2="90"
            stroke="#06c" stroke-width="2" marker-end="url(#ar1)" />
      <text x="265" y="85" font-size="12">x</text>

      <line x1="180" y1="140" x2="120" y2="60"
            stroke="#900" stroke-width="2" marker-end="url(#ar2)" />
      <text x="110" y="55" font-size="12">p</text>

      <!-- Resultant -->
      <line x1="180" y1="140" x2="300" y2="200"
            stroke="#060" stroke-width="3" marker-end="url(#ar3)" />
      <text x="310" y="205" font-size="12">x×p</text>

      <defs>
        <marker id="ar1" markerWidth="12" markerHeight="12"
                refX="5" refY="6" orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#06c"/>
        </marker>
        <marker id="ar2" markerWidth="12" markerHeight="12"
                refX="5" refY="6" orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#900"/>
        </marker>
        <marker id="ar3" markerWidth="12" markerHeight="12"
                refX="5" refY="6" orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#060"/>
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 2.6</strong> – Angular momentum as the momentum map for 
      rotational symmetry.
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.3.6 -->
  <h3 id="sec-2-3-6">2.3.6 Interactive Example: Rotational Symmetry and Angular Momentum Conservation</h3>

  <p>
    The JavaScript demo below shows the vector field for the Hamiltonian
    \[
      H(x,y,p_x,p_y) = \frac{1}{2}(p_x^2+p_y^2) + V(r), \qquad r=\sqrt{x^2+y^2},
    \]
    with \(V(r) = \tfrac{1}{2}r^2\) for simplicity.

    The motion occurs on circles and angular momentum \(L = x p_y - y p_x\) is conserved.
  </p>

  <figure id="fig-2-7" style="text-align:center;">
    <canvas id="rotSymCanvas" width="620" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.7</strong> – Hamiltonian flow with rotational symmetry.
      Streamlines are circular; the angular momentum is conserved.
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById("rotSymCanvas");
      if (!canvas) return;
      const ctx = canvas.getContext("2d");

      const w = canvas.width, h = canvas.height;
      const xmin=-2, xmax=2, ymin=-2, ymax=2;
      const X = x => (x-xmin)/(xmax-xmin)*w;
      const Y = y => h - (y-ymin)/(ymax-ymin)*h;

      ctx.clearRect(0,0,w,h);
      ctx.font="12px sans-serif";

      // Axes
      ctx.strokeStyle="#777";
      ctx.beginPath();
      ctx.moveTo(X(xmin),Y(0)); ctx.lineTo(X(xmax),Y(0));
      ctx.moveTo(X(0),Y(ymin)); ctx.lineTo(X(0),Y(ymax));
      ctx.stroke();

      // Draw vector field: for harmonic oscillator with rotational symmetry
      const N = 15;
      for(let i=0;i<N;i++){
        for(let j=0;j<N;j++){
          const x = xmin + (xmax-xmin)*i/(N-1);
          const y = ymin + (ymax-ymin)*j/(N-1);
          const px = y;    // approximate direction for demonstration
          const py = -x;
          const norm = Math.sqrt(px*px+py*py)||1;
          const scale = 0.2;
          const ux = px/norm*scale;
          const uy = py/norm*scale;

          ctx.beginPath();
          ctx.moveTo(X(x-ux/2),Y(y-uy/2));
          ctx.lineTo(X(x+ux/2),Y(y+uy/2));
          ctx.strokeStyle="#06c";
          ctx.stroke();
        }
      }

      ctx.fillStyle="#000";
      ctx.fillText("Rotationally symmetric vector field (example)",10,20);
      ctx.fillText("Flowlines are circles: angular momentum conserved",10,35);
    })();
  </script>

  <hr/>

  <!-- 2.3.7 -->
  <h3 id="sec-2-3-7">2.3.7 Summary</h3>

  <p>
    In this section, we introduced:
  </p>

  <ul>
    <li>Symplectic group actions and infinitesimal generators,</li>
    <li>Momentum maps collecting the conserved quantities,</li>
    <li>The symplectic formulation of Noether’s theorem,</li>
    <li>Translations ↔ linear momentum; rotations ↔ angular momentum,</li>
    <li>Visualisations of symmetric Hamiltonian flows.</li>
  </ul>

  <p>
    This prepares the ground for Chapters 3–4:  
    <strong>Symplectic integrators</strong> (leapfrog, splitting, variational)  
    must preserve symplectic form, and **symmetry-preserving methods** preserve  
    momentum maps. Both ideas are essential in long-time stability analysis.
  </p>

  <hr/>

  <h3 id="sec-2-3-8">2.3.8 References for Section 2.3</h3>

  <ol>
    <li><strong>[Arn89]</strong> V. Arnol'd,
      <em>Mathematical Methods of Classical Mechanics</em>,
      Springer, 1989.
    </li>
    <li><strong>[AM78]</strong> R. Abraham &amp; J.E. Marsden,
      <em>Foundations of Mechanics</em>, 2nd ed.,
      Addison–Wesley, 1978.
    </li>
    <li><strong>[MS17]</strong> D. McDuff &amp; D. Salamon,
      <em>Introduction to Symplectic Topology</em>,
      Oxford University Press, 2017.
    </li>
    <li><strong>[HLW06]</strong> E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration</em>, 2nd ed.,
      Springer, 2006.
    </li>
    <li><strong>[BC26]</strong> S. Blanes &amp; F. Casas,
      <em>Concise Introduction to GNI</em>, 2nd ed.,
      CRC Press, 2026.
    </li>
  </ol>

</section>

<section id="sec-2-4">
  <h2>2.4 Poisson Manifolds and Poisson Brackets</h2>

  <p>
    Symplectic manifolds model unconstrained Hamiltonian mechanics.  
    But many important systems are <em>constrained</em>, <em>reduced by symmetry</em>, or 
    live on spaces whose geometry is not symplectic — e.g. a rigid body’s angular 
    momentum space <span class="math">\(\mathfrak{so}(3)^*\)</span>, plasma models, Euler equations, 
    Lie–Poisson systems, and systems obtained after symmetry reduction.
  </p>

  <p>
    Poisson manifolds provide the natural geometric framework for all of these.
    The theory is a strict generalisation of symplectic geometry:
  </p>

  <ul>
    <li>Every symplectic manifold is Poisson.</li>
    <li>Not every Poisson manifold is symplectic.</li>
    <li>Poisson manifolds allow degenerate brackets and foliations 
        into symplectic leaves.</li>
    <li>Reduction (Marsden–Weinstein), constraints (Dirac), and Lie–Poisson 
        dynamics all arise within this framework.</li>
  </ul>

  <hr/>

  <!-- 2.4.1 -->
  <h3 id="sec-2-4-1">2.4.1 Definition of a Poisson Structure</h3>

  <p>
    A <strong>Poisson bracket</strong> on a smooth manifold \(M\) is a bilinear map
  </p>

  <p class="math">
    \[
      \{\,\cdot\,,\,\cdot\,\}: C^\infty(M)\times C^\infty(M) \to C^\infty(M)
    \]
  </p>

  <p>
    satisfying:
  </p>

  <ol>
    <li><strong>Skew-symmetry:</strong>
      <span class="math">\(\{f,g\} = -\{g,f\}\)</span>.</li>
    <li><strong>Leibniz rule:</strong>
      <span class="math">\(\{f,gh\} = \{f,g\}h + g\{f,h\}\)</span>.</li>
    <li><strong>Jacobi identity:</strong></li>
    <p class="math">
      \[
        \{f,\{g,h\}\} + \{g,\{h,f\}\} + \{h,\{f,g\}\} = 0.
      \]
    </p>
  </ol>

  <p>
    A manifold equipped with such a bracket is a <strong>Poisson manifold</strong>
    \((M,\{\cdot,\cdot\})\).
  </p>

  <hr/>

  <!-- 2.4.2 -->
  <h3 id="sec-2-4-2">2.4.2 The Poisson Tensor</h3>

  <p>
    A Poisson bracket is encoded by a bivector field
    <span class="math">\(\pi \in \Gamma(\Lambda^2 TM)\)</span> such that:
  </p>

  <p class="math">
    \[
      \{f,g\} = \pi(df,dg).
    \]
  </p>

  <p>
    The Jacobi identity is equivalent to:
  </p>

  <p class="math">
    \[
      [\pi,\pi]_{\mathrm{SN}} = 0,
    \]
  </p>

  <p>
    where <span class="math">\([\cdot,\cdot]_{\mathrm{SN}}\)</span> is the 
    <strong>Schouten–Nijenhuis bracket</strong>.
  </p>

  <h4>Example: canonical Poisson tensor</h4>

  <p>
    In canonical coordinates <span class="math">\((q,p) \in \mathbb{R}^{2m}\)</span>,
  </p>

  <p class="math">
    \[
      \pi =
      \begin{pmatrix}
      0 & I_m \\
      -I_m & 0
      \end{pmatrix}.
    \]
  </p>

  <p>
    This reproduces the standard symplectic bracket.  
    In a general Poisson manifold, the rank of 
    <span class="math">\(\pi(x)\)</span> may vary with \(x\).
  </p>

  <hr/>

  <!-- 2.4.3 -->
  <h3 id="sec-2-4-3">2.4.3 Hamiltonian Vector Fields on a Poisson Manifold</h3>

  <p>
    Given \(H\in C^\infty(M)\), the <strong>Hamiltonian vector field</strong> is:
  </p>

  <p class="math">
    \[
      X_H(f) = \{f,H\},\qquad \forall f\in C^\infty(M).
    \]
  </p>

  <p>
    Equivalently,
  </p>

  <p class="math">
    \[
      X_H = \pi^\sharp(dH),
    \]
  </p>

  <p>
    where <span class="math">\(\pi^\sharp: T^*M\to TM\)</span> is contraction with \(\pi\):
  </p>

  <p class="math">
    \[
      \pi^\sharp(\alpha) = \pi(\alpha,\cdot).
    \]
  </p>

  <p>
    Thus, Poisson geometry generalises symplectic dynamics to allow degeneracy.
  </p>

  <hr/>

  <!-- 2.4.4 -->
  <h3 id="sec-2-4-4">2.4.4 Symplectic Leaves</h3>

  <p>
    If \(\pi(x)\) has rank \(2k(x)\), we define the distribution
  </p>

  <p class="math">
    \[
      \mathcal{D}_x = \pi^\sharp(T_x^* M)\subset T_xM.
    \]
  </p>

  <p>
    The <strong>Stefan–Sussmann theorem</strong> implies that this integrable 
    distribution defines a foliation of \(M\) into immersed submanifolds 
    <strong>symplectic leaves</strong> \(S\subset M\), on which:
  </p>

  <ul>
    <li>\(\pi\) has constant rank,</li>
    <li>the restriction \(\omega_S = \pi^{-1}\) defines a bona fide symplectic form,</li>
    <li>Hamiltonian vector fields are tangent to leaves.</li>
  </ul>

  <figure id="fig-2-8" style="text-align:center;">
    <svg width="500" height="260" style="border:1px solid #ccc;">
      <!-- Draw big ellipsoid representing manifold -->
      <ellipse cx="250" cy="130" rx="200" ry="110"
               fill="#eef" stroke="#99c" stroke-width="2"/>
      <text x="190" y="35" font-size="14">Poisson manifold M</text>

      <!-- Two symplectic leaves -->
      <ellipse cx="250" cy="120" rx="120" ry="40"
               fill="#cfc" stroke="#393" stroke-width="2"/>
      <text x="245" y="120" font-size="12" text-anchor="middle">
        Symplectic leaf S₁
      </text>

      <ellipse cx="250" cy="190" rx="90" ry="30"
               fill="#fcc" stroke="#933" stroke-width="2"/>
      <text x="250" y="190" font-size="12" text-anchor="middle">
        Symplectic leaf S₂
      </text>
    </svg>
    <figcaption>
      <strong>Figure 2.8</strong> – A Poisson manifold foliated by symplectic leaves.
    </figcaption>
  </figure>

  <p>
    Poisson manifolds are therefore “stratified symplectic manifolds”.
  </p>

  <hr/>

  <!-- 2.4.5 -->
  <h3 id="sec-2-4-5">2.4.5 Poisson Maps</h3>

  <p>
    A smooth map <span class="math">\(F: (M,\pi_M)\to (N,\pi_N)\)</span> is a 
    <strong>Poisson map</strong> if:
  </p>

  <p class="math">
    \[
      \{f\circ F, g\circ F\}_M = \{f,g\}_N \circ F
      \qquad \forall f,g\in C^\infty(N).
    \]
  </p>

  <p>
    Example: symplectic maps are Poisson maps with respect to the canonical bracket.
  </p>

  <p>
    In geometric numerical integration, a <strong>Poisson integrator</strong> satisfies:
  </p>

  <p class="math">
    \[
      \{f,g\}\circ \Phi_h = \{f\circ \Phi_h,\, g\circ \Phi_h\},
    \]
  </p>

  <p>
    which generalises structure preservation when the system is not symplectic globally.
  </p>

  <hr/>

  <!-- 2.4.6 -->
  <h3 id="sec-2-4-6">2.4.6 Lie–Poisson Brackets (Rigid Body as Example)</h3>

  <p>
    A fundamental class of Poisson manifolds arises from Lie algebras.  
    If \(G\) is a Lie group with Lie algebra \(\mathfrak{g}\), then the dual 
    space <span class="math">\(\mathfrak{g}^*\)</span> carries a natural Poisson structure:
  </p>

  <p class="math">
    \[
      \{F,G\}(\mu)
      = \langle \mu,\; [dF(\mu), dG(\mu)] \rangle,
    \]
  </p>

  <p>
    where the bracket is the Lie bracket on \(\mathfrak{g}\).
  </p>

  <h4>Rigid body</h4>

  <p>
    Take \(\mathfrak{g} = \mathfrak{so}(3)\cong\mathbb{R}^3\) with cross product.
    Then the Lie–Poisson equations are Euler’s equations:
  </p>

  <p class="math">
    \[
      \dot{L} = L \times \nabla H(L),
    \]
  </p>

  <p>
    where \(L\in\mathbb{R}^3\) is angular momentum.
  </p>

  <p>
    Symplectic leaves are spheres \(||L||=\mathrm{const}\).
  </p>

  <figure id="fig-2-9" style="text-align:center;">
    <svg width="300" height="230" style="border:1px solid #ccc;">
      <circle cx="150" cy="115" r="80" fill="#eef" stroke="#99c" stroke-width="2"/>
      <text x="150" y="25" font-size="14" text-anchor="middle">
        Symplectic leaf: sphere |L| = const
      </text>
      <line x1="150" y1="115" x2="190" y2="60"
            stroke="#c33" stroke-width="3" marker-end="url(#arr_sph)"/>
      <text x="195" y="55" font-size="12">X_H</text>

      <defs>
        <marker id="arr_sph" markerWidth="12" markerHeight="12"
                refX="5" refY="6" orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#c33"/>
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 2.9</strong> – Lie–Poisson dynamics for the free rigid body.
      The motion is confined to a sphere, a symplectic leaf of \(\mathfrak{so}(3)^*\).
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.4.7 -->
  <h3 id="sec-2-4-7">2.4.7 Interactive Demo: Lie–Poisson Flow on a Sphere</h3>

  <p>
    The following JavaScript simulation shows a simple Lie–Poisson flow on the unit
    sphere:
  </p>

  <p class="math">
    \[
    \dot{L} = L \times (A L),
    \]
  </p>

  <p>
    where \(A=\mathrm{diag}(a_1,a_2,a_3)\) models anisotropic rigid body inertia.
  </p>

  <figure id="fig-2-10" style="text-align:center;">
    <canvas id="liePoissonCanvas" width="400" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.10</strong> – Numerical trace of a Lie–Poisson flow projected onto the sphere.
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas = document.getElementById("liePoissonCanvas");
    if (!canvas) return;
    const ctx = canvas.getContext("2d");

    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, R=110;
    ctx.clearRect(0,0,w,h);

    // parameters
    const A=[1,2,3];  // distinct inertias for demo
    let L=[0.1,0.9,0.3];
    const dt=0.03;

    function normalize(v){
      const n=Math.hypot(v[0],v[1],v[2]); return [v[0]/n,v[1]/n,v[2]/n];
    }
    L = normalize(L);

    function cross(a,b){
      return [
        a[1]*b[2]-a[2]*b[1],
        a[2]*b[0]-a[0]*b[2],
        a[0]*b[1]-a[1]*b[0]
      ];
    }

    function step(){
      const AL=[A[0]*L[0], A[1]*L[1], A[2]*L[2]];
      const dL=cross(L,AL);
      L=[L[0]+dt*dL[0], L[1]+dt*dL[1], L[2]+dt*dL[2]];
      L=normalize(L);
    }

    function project(L){
      // simple orthographic projection
      return [cx + R*L[0], cy - R*L[1]];
    }

    function draw(){
      ctx.clearRect(0,0,w,h);

      // sphere outline
      ctx.beginPath();
      ctx.arc(cx,cy,R,0,2*Math.PI);
      ctx.strokeStyle="#666"; ctx.lineWidth=2; ctx.stroke();

      // current point
      const p=project(L);
      ctx.beginPath();
      ctx.arc(p[0],p[1],5,0,2*Math.PI);
      ctx.fillStyle="#c00"; ctx.fill();
    }

    function animate(){
      step();
      draw();
      requestAnimationFrame(animate);
    }
    animate();
  })();
  </script>

  <hr/>

  <!-- 2.4.8 -->
  <h3 id="sec-2-4-8">2.4.8 Summary</h3>

  <p>
    In this section we introduced the Poisson generalisation of Hamiltonian 
    mechanics:
  </p>

  <ul>
    <li>Definition of Poisson bracket via the Poisson tensor.</li>
    <li>Hamiltonian vector fields on a Poisson manifold.</li>
    <li>Foliation into symplectic leaves.</li>
    <li>Poisson maps and their role in structure-preserving numerical integration.</li>
    <li>Lie–Poisson systems and rigid body dynamics as canonical examples.</li>
  </ul>

  <p>
    These ideas underpin geometric numerical integration for systems 
    that are <em>not globally symplectic</em>—particularly Lie–Poisson integration, 
    splitting on noncanonical brackets, and reduced systems.
  </p>

  <hr/>

  <!-- 2.4.9 -->
  <h3 id="sec-2-4-9">2.4.9 References for Section 2.4</h3>

  <ol>
    <li><strong>[Vai94]</strong>
      I. Vaisman,
      <em>Lectures on the Geometry of Poisson Manifolds</em>,
      Birkhäuser, 1994.
    </li>
    <li><strong>[Lib13]</strong>
      A. Libermann &amp; C. Marle,
      <em>Symplectic Geometry and Analytical Mechanics</em>,
      Springer, 2013.
    </li>
    <li><strong>[MR99]</strong>
      J.E. Marsden &amp; T. Ratiu,
      <em>Introduction to Mechanics and Symmetry</em>,
      Springer, 1999.
    </li>
    <li><strong>[HLW06]</strong>
      E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.
    </li>
    <li><strong>[BC26]</strong>
      S. Blanes &amp; F. Casas,
      <em>Concise Introduction to GNI</em>, 2nd ed.,
      CRC Press, 2026.
    </li>
  </ol>

</section>

<section id="sec-2-5">
  <h2>2.5 Darboux’s Theorem and Canonical Coordinates</h2>

  <p>
    One of the most profound results in symplectic geometry is that it admits
    <em>no local invariants</em>.
    Unlike Riemannian geometry—where curvature, torsion, and other invariants
    distinguish local geometries—every symplectic structure looks locally
    identical to the standard canonical form.
  </p>

  <p>
    This is the content of <strong>Darboux’s theorem</strong>.
    It implies that Hamilton’s equations always admit canonical coordinates
    \((q,p)\) locally, regardless of global geometry, topology, or constraints.
  </p>

  <hr/>

  <!-- 2.5.1 -->
  <h3 id="sec-2-5-1">2.5.1 Statement of Darboux’s Theorem</h3>

  <p><strong>Theorem 2.5 (Darboux).</strong>
    Let \((M,\omega)\) be a symplectic manifold of dimension \(2m\).
    For every point \(x\in M\), there exists a coordinate chart
  </p>

  <p class="math">
    \[
      (U; q_1,\dots,q_m, p_1,\dots,p_m)
    \]
  </p>

  <p>
    such that on \(U\):
  </p>

  <p class="math">
    \[
      \omega = \sum_{i=1}^m dq_i \wedge dp_i.
    \]
  </p>

  <p>
    In other words, <em>all symplectic manifolds are locally canonical</em>.
  </p>

  <p>
    No metric, no curvature, no Christoffel symbols: symplectic geometry has no
    local invariants.
  </p>

  <hr/>

  <!-- 2.5.2 -->
  <h3 id="sec-2-5-2">2.5.2 Geometric Meaning</h3>

  <p>
    Darboux’s theorem tells us that:
  </p>

  <ul>
    <li>The symplectic form \(\omega\) is <em>locally exact</em>:
      <span class="math">\(\omega = d\theta\)</span>.</li>
    <li>There always exist “position–momentum” variables \((q_i,p_i)\).</li>
    <li>
      Symplectic manifolds have no local moduli:  
      every point has a neighbourhood symplectomorphic to an open set of
      <span class="math">\(\mathbb{R}^{2m}\)</span> with the standard form.
    </li>
    <li>
      All Hamiltonian systems are <em>locally equivalent</em> to standard
      canonical Hamiltonian mechanics.
    </li>
  </ul>

  <p>
    The importance for numerical integration is immense:
  </p>

  <ul>
    <li>Canonical integrators (e.g., Störmer–Verlet) apply locally on any symplectic manifold.</li>
    <li>Local structure preservation implies global qualitative faithfulness.</li>
  </ul>

  <hr/>

  <!-- 2.5.3 -->
  <h3 id="sec-2-5-3">2.5.3 Sketch of Proof (Moser’s Argument)</h3>

  <p>
    The classical proof uses <strong>Moser’s method</strong>.
    The idea is to connect the given symplectic form \(\omega\) to the canonical
    form \(\omega_0\) smoothly, and construct a diffeomorphism that carries one
    to the other.
  </p>

  <ol>
    <li>
      Choose local coordinates near a point so that
      <span class="math">\(\omega(x) = \omega_0\)</span> at the point.
    </li>

    <li>
      Define a 1-parameter family of forms:
      <span class="math">
        \[
        \omega_t = (1-t)\omega_0 + t\omega, \qquad t\in[0,1].
        \]
      </span>
    </li>

    <li>
      Solve Moser’s equation for a time-dependent vector field \(X_t\):
      <span class="math">
        \[
        i_{X_t}\,\omega_t = -\alpha, \qquad \text{with } \omega - \omega_0 = d\alpha.
        \]
      </span>
    </li>

    <li>
      Integrate \(X_t\) to obtain an isotopy \(\varphi_t\).
    </li>

    <li>
      Check that:
      <span class="math">
        \[
        \frac{d}{dt}\varphi_t^*\omega_t = 0
        \Rightarrow \varphi_1^*\omega = \omega_0.
        \]
      </span>
    </li>
  </ol>

  <p>
    Thus, \(\varphi_1\) gives the desired canonical coordinates.
  </p>

  <figure id="fig-2-11" style="text-align:center;">
    <svg width="500" height="250" style="border:1px solid #ccc;">
      <!-- start and end symplectic forms -->
      <rect x="60" y="90" width="120" height="80"
            fill="#eef" stroke="#66a" stroke-width="2"/>
      <text x="120" y="83" font-size="13" text-anchor="middle">
        ω₀ (canonical)
      </text>

      <rect x="320" y="90" width="120" height="80"
            fill="#fee" stroke="#a66" stroke-width="2"/>
      <text x="380" y="83" font-size="13" text-anchor="middle">
        ω (general)
      </text>

      <!-- arrow -->
      <line x1="180" y1="130" x2="320" y2="130"
            stroke="#000" stroke-width="2"
            marker-end="url(#arr_D)"/>

      <text x="250" y="118" font-size="12" text-anchor="middle">
        φ₁ (symplectomorphism)
      </text>

      <defs>
        <marker id="arr_D" markerWidth="10" markerHeight="10"
                refX="5" refY="5" orient="auto">
          <path d="M0,0 L0,10 L10,5 z" fill="#000"/>
        </marker>
      </defs>
    </svg>

    <figcaption>
      <strong>Figure 2.11</strong> – Moser’s argument: constructing a flow that
      takes a general symplectic form to the canonical one.
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.5.4 -->
  <h3 id="sec-2-5-4">2.5.4 Canonical Poisson Bracket Appears Automatically</h3>

  <p>
    In Darboux coordinates, the Poisson tensor becomes:
  </p>

  <p class="math">
    \[
      \pi =
      \begin{pmatrix}
      0 & I \\ -I & 0
      \end{pmatrix},
    \qquad
    \{q_i,p_j\} = \delta_{ij},\quad \{q_i,q_j\}=0,\quad \{p_i,p_j\}=0.
    \]
  </p>

  <p>
    Hence, Hamilton’s equations take their standard form:
  </p>

  <p class="math">
    \[
      \dot{q}_i = \frac{\partial H}{\partial p_i},
      \qquad
      \dot{p}_i = -\frac{\partial H}{\partial q_i}.
    \]
  </p>

  <p>
    The appearance of these equations is not tied to special coordinates:
    <strong>every Hamiltonian system is locally canonical.</strong>
  </p>

  <hr/>

  <!-- 2.5.5 -->
  <h3 id="sec-2-5-5">2.5.5 Consequences for Geometric Numerical Integration</h3>

  <p>
    Darboux’s theorem implies:
  </p>

  <ul>
    <li>
      <strong>All symplectic integrators are formulated in canonical coordinates
      without loss of generality.</strong>
    </li>

    <li>
      Structure-preserving algorithms apply on any symplectic manifold
      through local charts.
    </li>

    <li>
      Global topology affects global behavior, but not the local structure of
      Hamiltonian flows.
    </li>

    <li>
      Numerically, canonical coordinates allow:
      <ul>
        <li>local symplectic discretisation,</li>
        <li>splitting methods,</li>
        <li>variational integrators,</li>
        <li>explicit computations of flows of separable Hamiltonians.</li>
      </ul>
    </li>
  </ul>

  <p>
    The theorem is therefore foundational for the entire numerical theory in
    later chapters.
  </p>

  <hr/>

  <!-- 2.5.6 -->
  <h3 id="sec-2-5-6">2.5.6 Relation to Poisson Geometry (From Section 2.4)</h3>

  <p>
    Darboux’s theorem has no analogue on Poisson manifolds:
  </p>

  <ul>
    <li>Poisson tensors may have varying rank.</li>
    <li>Symplectic leaves may be curved or not even embedded.</li>
    <li>No universal local normal form exists globally on a Poisson manifold.</li>
  </ul>

  <p>
    However:
  </p>

  <ul>
    <li>Each symplectic leaf <em>does</em> admit Darboux coordinates.</li>
    <li>
      Thus Lie–Poisson systems evolve on manifolds that are locally symplectic
      hypersurfaces.
    </li>
  </ul>

  <hr/>

  <!-- 2.5.7 -->
  <h3 id="sec-2-5-7">2.5.7 References for Section 2.5</h3>

  <ol>
    <li><strong>[Arn89]</strong> V. Arnol'd,
      <em>Mathematical Methods of Classical Mechanics</em>, Springer, 1989.</li>

    <li><strong>[MS17]</strong> McDuff &amp; Salamon,
      <em>Introduction to Symplectic Topology</em>, OUP, 2017.</li>

    <li><strong>[Wei71]</strong> A. Weinstein,
      “Symplectic manifolds and their Lagrangian submanifolds”,  
      <em>Advances in Mathematics</em>, 1971.</li>

    <li><strong>[HLW06]</strong> Hairer, Lubich, Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.</li>

    <li><strong>[BC26]</strong> Blanes &amp; Casas,  
      <em>Concise Introduction to GNI</em>, 2nd ed., CRC Press, 2026.</li>
  </ol>

</section>

<section id="sec-2-6">
  <h2>2.6 Lie–Poisson Reduction and Coadjoint Orbits</h2>

  <p>
    In previous sections we saw:
  </p>

  <ul>
    <li>Hamiltonian systems on symplectic manifolds (Sections 2.1–2.3),</li>
    <li>Poisson manifolds as a generalisation (Section 2.4),</li>
    <li>Darboux’s theorem ensuring local canonical form (Section 2.5).</li>
  </ul>

  <p>
    We now treat <strong>Lie–Poisson reduction</strong> — one of the deepest links between
    symmetry, geometry, and Hamiltonian mechanics.  
    It explains why systems such as:
  </p>

  <ul>
    <li>rigid body dynamics,</li>
    <li>ideal fluid mechanics (Euler equations),</li>
    <li>plasmas (Vlasov–Poisson),</li>
    <li>beam dynamics and kinetic equations,</li>
    <li>quantum spin systems,</li>
  </ul>

  <p>
    evolve on dual Lie algebras and preserve the <em>coadjoint orbit</em> structure.
  </p>

  <p>
    This section provides the foundation for <strong>Lie–Poisson integrators</strong>,
    which appear later in geometric numerical integration: algorithms that
    preserve Casimirs, coadjoint orbits, and Lie–Poisson brackets exactly.
  </p>

  <hr/>

  <!-- 2.6.1 -->
  <h3 id="sec-2-6-1">2.6.1 Motivation: Reduction by Symmetry</h3>

  <p>
    Suppose a Hamiltonian system has a symmetry group \(G\).  
    By Noether’s theorem:
  </p>

  <p class="math">
    \[
    \text{symmetry} \;\Rightarrow\; \text{momentum map} \;\Rightarrow\; \text{conserved quantity}.
    \]
  </p>

  <p>
    Reduction asks the opposite question:
  </p>

  <blockquote>
    <p><em>Can we eliminate redundant degrees of freedom introduced by symmetry?</em></p>
  </blockquote>

  <p>
    For instance, the rigid body rotation group \(SO(3)\) acts freely on the
    configuration space.  
    By reducing the symmetry, the true dynamics live not on the tangent bundle
    of the group but on <span class="math">\(\mathfrak{so}(3)^*\cong\mathbb{R}^3\)</span>.
  </p>

  <hr/>

  <!-- 2.6.2 -->
  <h3 id="sec-2-6-2">2.6.2 The Coadjoint Action</h3>

  <p>
    Let \(G\) be a Lie group with Lie algebra \(\mathfrak{g}\).
    The <strong>adjoint action</strong> of \(G\) on \(\mathfrak{g}\) is:
  </p>

  <p class="math">
    \[
      \mathrm{Ad}_g(X) := g X g^{-1}.
    \]
  </p>

  <p>
    Dualising gives the <strong>coadjoint action</strong>:
  </p>

  <p class="math">
    \[
      \mathrm{Ad}^*_g : \mathfrak{g}^* \to \mathfrak{g}^*, \qquad
      \langle \mathrm{Ad}_g^*\mu, X\rangle = \langle \mu, \mathrm{Ad}_{g^{-1}}X\rangle.
    \]
  </p>

  <p>
    The orbits of this action,
  </p>

  <p class="math">
    \[
      \mathcal{O}_\mu = \{\mathrm{Ad}_g^*\mu : g\in G\},
    \]
  </p>

  <p>
    are called <strong>coadjoint orbits</strong>.
  </p>

  <p>
    Crucially:
  </p>

  <blockquote>
    <strong>Coadjoint orbits are naturally symplectic manifolds.</strong>  
  </blockquote>

  <hr/>

  <!-- 2.6.3 -->
  <h3 id="sec-2-6-3">2.6.3 Kirillov–Kostant–Souriau (KKS) Symplectic Form</h3>

  <p>
    Each coadjoint orbit \(\mathcal{O}_\mu\subset \mathfrak{g}^*\) carries a
    canonical symplectic form defined as follows.
  </p>

  <p class="math">
    \[
      \omega_\mu(\xi_{\mathfrak{g}^*},\eta_{\mathfrak{g}^*})
      = \langle \mu,\;[\xi,\eta]\rangle.
    \]
  </p>

  <p>
    Here \(\xi_{\mathfrak{g}^*}\) is the infinitesimal generator of the
    coadjoint action associated with \(\xi\in\mathfrak{g}\):
  </p>

  <p class="math">
    \[
      \xi_{\mathfrak{g}^*}(\mu) = \mathrm{ad}_\xi^*\mu.
    \]
  </p>

  <p>
    Thus each coadjoint orbit is a symplectic leaf of the Lie–Poisson bracket
    of Section 2.4.
  </p>

  <figure id="fig-2-12" style="text-align:center;">
    <svg width="480" height="240" style="border:1px solid #ccc;">
      <text x="180" y="20" font-size="14">Symplectic leaf (coadjoint orbit)</text>

      <!-- Big ellipse for g* -->
      <ellipse cx="240" cy="120" rx="200" ry="90"
               fill="#eef" stroke="#99c" stroke-width="2"/>
      <text x="240" y="210" font-size="12" text-anchor="middle">
        Dual algebra 𝔤*
      </text>

      <!-- A coadjoint orbit inside -->
      <ellipse cx="240" cy="120" rx="110" ry="45"
               fill="#cfc" stroke="#393" stroke-width="2"/>
      <text x="240" y="120" font-size="12" text-anchor="middle">
        Orbit 𝒪<sub>μ</sub>
      </text>
    </svg>

    <figcaption>
      <strong>Figure 2.12</strong> –  
      A coadjoint orbit appears as a symplectic leaf in the Lie–Poisson manifold 
      \(\mathfrak{g}^*\).
    </figcaption>
  </figure>

  <hr/>

  <!-- 2.6.4 -->
  <h3 id="sec-2-6-4">2.6.4 Lie–Poisson Bracket on 𝔤*</h3>

  <p>
    For \(\mathfrak{g}^*\) the Poisson bracket of functions \(F,G\) is:
  </p>

  <p class="math">
    \[
      \{F,G\}(\mu) = 
      \langle \mu,\; [dF(\mu), dG(\mu)] \rangle.
    \]
  </p>

  <ul>
    <li>The symplectic leaves are the coadjoint orbits.</li>
    <li>Casimirs are invariants constant on orbits.</li>
    <li>Hamiltonian dynamics are tangent to each orbit.</li>
  </ul>

  <p>
    This provides a direct bridge between symmetry reduction and Poisson geometry.
  </p>

  <hr/>

  <!-- 2.6.5 -->
  <h3 id="sec-2-6-5">2.6.5 Euler–Poincaré and Lie–Poisson Equations</h3>

  <p>
    Consider a Hamiltonian \(H:\mathfrak{g}^*\to\mathbb{R}\).  
    The Hamiltonian vector field on the Poisson manifold \(\mathfrak{g}^*\) is:
  </p>

  <p class="math">
    \[
      \dot{\mu} = \mathrm{ad}^*_{\nabla H(\mu)} \mu.
    \]
  </p>

  <p>
    This is the <strong>Lie–Poisson equation</strong>.
  </p>

  <h4>Example: Rigid Body</h4>

  <p>
    For \(\mathfrak{so}(3)^*\cong\mathbb{R}^3\):
  </p>

  <p class="math">
    \[
      \dot{L} = L \times \Omega, \qquad 
      \Omega = \nabla H(L) = (I^{-1}L).
    \]
  </p>

  <p>
    This yields Euler’s equations of rigid body rotation —  
    a Hamiltonian flow on the sphere \(|L|=\mathrm{const}\).
  </p>

  <hr/>

  <!-- 2.6.6 -->
  <h3 id="sec-2-6-6">2.6.6 Casimirs and Reduced Phase Space</h3>

  <p>
    A <strong>Casimir</strong> on a Poisson manifold satisfies:
  </p>

  <p class="math">
    \[
      \{C,F\} = 0\qquad\forall F.
    \]
  </p>

  <p>
    On a Lie–Poisson manifold \(\mathfrak{g}^*\), Casimirs label the symplectic leaves.
  </p>

  <h4>Example: rigid body</h4>

  <p class="math">
    \[
      C(L) = \|L\|^2
    \]
  </p>

  <p>
    is a Casimir.  
    It defines spherical leaves:
  </p>

  <p class="math">
    \[
      \mathcal{O}_r = \{L\in\mathbb{R}^3 : \|L\|= r\}.
    \]
  </p>

  <p>
    A Lie–Poisson integrator must preserve Casimirs exactly —  
    a primary requirement in geometric numerical integration.
  </p>

  <hr/>

  <!-- 2.6.7 -->
  <h3 id="sec-2-6-7">2.6.7 Interactive Demo: Coadjoint Orbit Motion</h3>

  <p>
    The following JavaScript simulation shows motion on a coadjoint orbit
    for the \(\mathfrak{so}(3)^*\) example:
  </p>

  <figure id="fig-2-13" style="text-align:center;">
    <canvas id="orbitCanvas" width="420" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 2.13</strong> – Flow on a coadjoint orbit (unit sphere).
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("orbitCanvas");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, R=120;
    // inertia parameters
    const A=[1,2,4];
    let L=[0.3,0.7,0.6];
    const dt=0.02;

    function norm(v){ return Math.hypot(v[0],v[1],v[2]); }
    function normalize(v){ const n=norm(v); return [v[0]/n,v[1]/n,v[2]/n]; }
    L=normalize(L);

    function cross(a,b){
      return [
        a[1]*b[2]-a[2]*b[1],
        a[2]*b[0]-a[0]*b[2],
        a[0]*b[1]-a[1]*b[0]
      ];
    }

    function step(){
      const AL=[A[0]*L[0],A[1]*L[1],A[2]*L[2]];
      const dL=cross(L,AL);
      L=[L[0]+dt*dL[0],L[1]+dt*dL[1],L[2]+dt*dL[2]];
      L=normalize(L);
    }

    function proj(v){ return [cx+R*v[0], cy-R*v[1]]; }

    function draw(){
      ctx.clearRect(0,0,w,h);
      ctx.beginPath(); ctx.arc(cx,cy,R,0,2*Math.PI);
      ctx.strokeStyle="#666"; ctx.lineWidth=2; ctx.stroke();
      const p=proj(L);
      ctx.beginPath(); ctx.arc(p[0],p[1],6,0,2*Math.PI);
      ctx.fillStyle="#c00"; ctx.fill();
    }

    (function animate(){
      step(); draw(); requestAnimationFrame(animate);
    })();
  })();
  </script>

  <hr/>

  <!-- 2.6.8 -->
  <h3 id="sec-2-6-8">2.6.8 Summary</h3>

  <p>
    In this section we developed the geometric machinery of reduced Hamiltonian
    systems:
  </p>

  <ul>
    <li>Coadjoint action and coadjoint orbits,</li>
    <li>KKS symplectic structure,</li>
    <li>Lie–Poisson brackets on dual Lie algebras,</li>
    <li>Euler–Poincaré and Lie–Poisson equations,</li>
    <li>Casimirs and reduced dynamics,</li>
    <li>Hamiltonian flows restricted to symplectic leaves.</li>
  </ul>

  <p>
    This geometric background is essential for numerical methods that preserve:
  </p>

  <ul>
    <li>Casimirs,</li>
    <li>coadjoint orbits,</li>
    <li>Lie–Poisson brackets,</li>
    <li>energy behaviour,</li>
    <li>long-time invariants of reduced systems.</li>
  </ul>

  <hr/>

  <!-- 2.6.9 -->
  <h3 id="sec-2-6-9">2.6.9 References for Section 2.6</h3>

  <ol>
    <li><strong>[MR99]</strong> Marsden &amp; Ratiu,
      <em>Introduction to Mechanics and Symmetry</em>, Springer, 1999.</li>

    <li><strong>[Arn89]</strong> Arnol'd,
      <em>Mathematical Methods of Classical Mechanics</em>, Springer, 1989.</li>

    <li><strong>[Hol08]</strong> Holm,
      <em>Geometric Mechanics: Part II</em>, Imperial College Press, 2008.</li>

    <li><strong>[Wei83]</strong> Weinstein,
      “The local structure of Poisson manifolds”,
      <em>J. Differential Geometry</em>, 1983.</li>

    <li><strong>[HLW06]</strong> Hairer, Lubich, Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.</li>

    <li><strong>[BC26]</strong> Blanes &amp; Casas,
      <em>Concise Introduction to GNI (2nd ed.)</em>, CRC Press, 2026.</li>
  </ol>

</section>

<section id="sec-3-1">
  <h2>3.1 Why Symplectic Integrators?</h2>

  <p>
    Conventional numerical ODE methods (Runge–Kutta, multistep, etc.) approximate
    solutions to differential equations with high accuracy over short time
    intervals.  
    But for <strong>Hamiltonian systems</strong>, long-time behaviour—not short-time
    accuracy—is critical.
  </p>

  <p>
    Symplectic integrators are designed explicitly to preserve:
  </p>

  <ul>
    <li>the symplectic form <span class="math">\(\omega\)</span>,</li>
    <li>qualitative phase-space geometry,</li>
    <li>near-conservation of energy over exponentially long time intervals,</li>
    <li>confinement of trajectories to deformed tori (KAM-like behaviour),</li>
    <li>momentum maps and invariants under symmetry when combined with reduction.</li>
  </ul>

  <p>
    This section explains the <em>fundamental reasons</em> why symplectic integrators
    dramatically outperform conventional schemes for Hamiltonian dynamics.
  </p>

  <hr/>

  <!-- 3.1.1 -->
  <h3 id="sec-3-1-1">3.1.1 Failure of Standard Integrators: Energy Drift</h3>

  <p>
    Consider a Hamiltonian system
  </p>

  <p class="math">
    \[
      \dot{z} = X_H(z), \qquad H(z) = \text{constant along solutions}.
    \]
  </p>

  <p>
    Standard integrators rarely preserve this exactly.
    Even if a method has high order, the computed energy \(H(z_n)\) typically
    satisfies:
  </p>

  <p class="math">
    \[
      H(z_n) = H(z_0) + C h t + \mathcal{O}(h),
    \]
  </p>

  <p>
    showing a <strong>linear drift in time</strong>.
  </p>

  <h4>Example: explicit Euler</h4>

  <p class="math">
    \[
      z_{n+1} = z_n + h X_H(z_n)
    \]
  </p>

  <p>
    Explicit Euler is not symplectic and produces spiralling trajectories even for
    simple systems like the harmonic oscillator.
  </p>

  <figure id="fig-3-1" style="text-align:center;">
    <svg width="420" height="250" style="border:1px solid #ccc;">
      <text x="10" y="20" font-size="14">Explicit Euler on harmonic oscillator</text>

      <!-- spiralling trajectory -->
      <g stroke="#c33" fill="none">
        <path d="M200,125 
                 m -60,0
                 a 60,50 0 1,0 120,0
                 a 55,50 0 1,1 -110,0
                 a 50,40 0 1,0 100,0
                 a 45,40 0 1,1 -90,0
                 a 40,30 0 1,0 80,0
                 a 35,30 0 1,1 -70,0"
              stroke-width="2"/>
      </g>

      <!-- true circle -->
      <circle cx="200" cy="125" r="60"
              stroke="#06c" stroke-width="2" fill="none"/>

      <text x="200" y="230" font-size="12" text-anchor="middle">
        Red: Euler spirals outward (energy ↑).  
        Blue: true orbit = closed circle.
      </text>
    </svg>
    <figcaption>
      <strong>Figure 3.1</strong> – Standard methods typically exhibit energy drift.
    </figcaption>
  </figure>

  <hr/>

  <!-- 3.1.2 -->
  <h3 id="sec-3-1-2">3.1.2 What Symplectic Integrators Preserve</h3>

  <p>
    A numerical map <span class="math">\(\Phi_h: M\to M\)</span> is <strong>symplectic</strong> if:
  </p>

  <p class="math">
    \[
      \Phi_h^* \omega = \omega.
    \]
  </p>

  <p>
    In canonical coordinates, this reads:
  </p>

  <p class="math">
    \[
      (D\Phi_h)^T J (D\Phi_h) = J,
      \qquad
      J=\begin{pmatrix}0 & I \\ -I & 0\end{pmatrix}.
    \]
  </p>

  <p>
    Symplectic methods conserve:
  </p>

  <ul>
    <li><strong>symplectic form</strong> (exactly),</li>
    <li><strong>volume</strong> (Liouville theorem),</li>
    <li><strong>momentum maps</strong> in symmetric systems,</li>
    <li><strong>qualitative dynamics</strong>: KAM tori, stability, periodicity.</li>
  </ul>

  <p>
    But the most striking property involves <strong>backward error analysis</strong>.
  </p>

  <hr/>

  <!-- 3.1.3 -->
  <h3 id="sec-3-1-3">3.1.3 Backward Error Analysis: Modified Hamiltonian</h3>

  <p>
    For symplectic integrators, one can show that:
  </p>

  <blockquote>
    <p>
      <strong>The numerical solution exactly follows the flow of a modified Hamiltonian</strong>
      <span class="math">\(\tilde{H}\)</span>, where
      \[
        \tilde{H} = H + h^p H_{p+1} + h^{p+2} H_{p+2} + \cdots.
      \]
    </p>
  </blockquote>

  <p>
    This implies:
  </p>

  <p class="math">
    \[
      \tilde{H}(z_n) = \tilde{H}(z_0) \quad \text{exactly}.
    \]
  </p>

  <p>
    Therefore, the true energy satisfies:
  </p>

  <p class="math">
    \[
      |H(z_n) - H(z_0)| \le C h^p
    \]
  </p>

  <p>
    for times that grow like:
  </p>

  <p class="math">
    \[
      t = \mathcal{O}(e^{c/h}).
    \]
  </p>

  <p>
    This is an <strong>exponentially long interval of near-conservation</strong> —  
    a result that no non-symplectic method can match.
  </p>

  <hr/>

  <!-- 3.1.4 -->
  <h3 id="sec-3-1-4">3.1.4 KAM Behaviour: Symplectic Methods Preserve Tori</h3>

  <p>
    For nearly integrable systems,
    the motion lies on invariant tori (Kolmogorov–Arnold–Moser theory).
  </p>

  <p>
    A symplectic integrator maps invariant tori to <em>slightly deformed tori</em>,
    preserving quasiperiodic structure.
  </p>

  <p>
    A non-symplectic method destroys tori, causing:
  </p>

  <ul>
    <li>secular energy drift,</li>
    <li>spurious chaos or false stability,</li>
    <li>long-time misrepresentation of dynamics.</li>
  </ul>

  <figure id="fig-3-2" style="text-align:center;">
    <svg width="450" height="240" style="border:1px solid #ccc;">
      <text x="120" y="20" font-size="14">Symplectic</text>
      <text x="330" y="20" font-size="14">Non-symplectic</text>

      <!-- symplectic tori -->
      <g stroke="#06c" fill="none">
        <ellipse cx="120" cy="130" rx="70" ry="40" stroke-width="2"/>
        <ellipse cx="120" cy="130" rx="55" ry="30" stroke-width="2"/>
        <ellipse cx="120" cy="130" rx="40" ry="20" stroke-width="2"/>
      </g>

      <!-- non-symplectic distortions -->
      <g stroke="#c33" fill="none">
        <path d="M280,130
                 m -60,0
                 a 60,45 0 1,0 120,0
                 a 50,35 0 1,1 -100,0
                 a 40,25 0 1,0  80,0"
              stroke-width="2"/>
      </g>
    </svg>
    <figcaption>
      <strong>Figure 3.2</strong> – Symplectic methods preserve tori; non-symplectic methods distort them.
    </figcaption>
  </figure>

  <hr/>

  <!-- 3.1.5 -->
  <h3 id="sec-3-1-5">3.1.5 Interactive Demo: Symplectic vs Non-Symplectic Integrators</h3>

  <p>
    Below is a JavaScript comparison for the harmonic oscillator:
  </p>

  <ul>
    <li><strong>Explicit Euler</strong> (non-symplectic)</li>
    <li><strong>Symplectic Euler</strong> (symplectic)</li>
  </ul>

  <figure id="fig-3-3" style="text-align:center;">
    <canvas id="symplecticDemo" width="500" height="260"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.3</strong> –  
      Red: explicit Euler spirals outward.  
      Blue: symplectic Euler preserves a deformed ellipse.
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("symplecticDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");

    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, scale=60;

    let zE=[1,0];   // explicit Euler: (q,p)
    let zS=[1,0];   // symplectic Euler
    const hstep=0.05;

    function euler_step(z){
      // dq = p, dp = -q
      const q=z[0], p=z[1];
      return [q+hstep*p, p-hstep*q];
    }

    function symplectic_euler_step(z){
      let q=z[0], p=z[1];
      p = p - hstep*q;      // implicit in p, explicit in q
      q = q + hstep*p;
      return [q,p];
    }

    function proj(z){
      const [q,p]=z;
      return [cx + scale*q, cy - scale*p];
    }

    function draw_point(pt,color){
      ctx.fillStyle=color;
      ctx.beginPath();
      ctx.arc(pt[0],pt[1],3,0,2*Math.PI);
      ctx.fill();
    }

    function step_and_draw(){
      // explicit Euler
      zE=euler_step(zE);
      draw_point(proj(zE),"#c33");

      // symplectic Euler
      zS=symplectic_euler_step(zS);
      draw_point(proj(zS),"#06c");

      requestAnimationFrame(step_and_draw);
    }

    ctx.clearRect(0,0,w,h);
    step_and_draw();
  })();
  </script>

  <hr/>

  <!-- 3.1.6 -->
  <h3 id="sec-3-1-6">3.1.6 Summary</h3>

  <p>
    This section motivates the use of symplectic integrators by explaining:
  </p>

  <ul>
    <li>why standard numerical methods fail long-term (energy drift),</li>
    <li>what symplectic integrators preserve (geometry, tori, invariants),</li>
    <li>the key fact from backward error analysis: existence of a modified Hamiltonian,</li>
    <li>KAM-like behaviour and long-time fidelity,</li>
    <li>clear numerical examples with Euler vs Symplectic Euler.</li>
  </ul>

  <p>
    These ideas form the conceptual foundation for the concrete algorithms
    presented in the remainder of Chapter 3.
  </p>

  <hr/>

  <!-- 3.1.7 -->
  <h3 id="sec-3-1-7">3.1.7 References for Section 3.1</h3>

  <ol>
    <li><strong>[HLW06]</strong>
      Hairer, Lubich, Wanner.
      <em>Geometric Numerical Integration</em>, Springer, 2006.</li>

    <li><strong>[BC26]</strong>
      Blanes &amp; Casas.
      <em>Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      CRC Press, 2026.</li>

    <li><strong>[BG94]</strong>
      Benettin &amp; Giorgilli,
      “On the Hamiltonian interpolation of near-to-the-identity symplectic maps”,
      <em>Nonlinearity</em>, 1994.</li>

    <li><strong>[Ske99]</strong>
      Skeel,
      “Integration of Hamiltonian systems”,  
      <em>Handbook of Numerical Analysis</em>, 1999.</li>
  </ol>

</section>

<section id="sec-3-2">
  <h2>3.2 Symplectic Euler, Störmer–Verlet, and Basic Symplectic Schemes</h2>

  <p>
    The simplest symplectic integrators arise from the <strong>splitting</strong> of a separable
    Hamiltonian
  </p>

  <p class="math">
    \[
      H(q,p) = T(p) + V(q),
    \]
  </p>

  <p>
    where \(T\) is kinetic energy and \(V\) potential energy.  
    This structure allows the Hamiltonian vector field to be decomposed into two
    exactly integrable flows: the <em>drift</em> and the <em>kick</em>.
  </p>

  <p>
    From these flows one constructs the <strong>Symplectic Euler</strong> (two variants) and the
    <strong>Störmer–Verlet</strong> (or <strong>Leapfrog</strong>) integrator.
  </p>

  <p>
    These are the foundation for higher-order symplectic composition methods
    introduced later.
  </p>

  <hr/>

  <!-- 3.2.1 -->
  <h3 id="sec-3-2-1">3.2.1 Separable Hamiltonians and Exact Splitting</h3>

  <p>
    For 
    <span class="math">\(H = T(p) + V(q)\)</span>
    the Hamiltonian vector field decomposes:
  </p>

  <p class="math">
    \[
      X_H = X_T + X_V.
    \]
  </p>

  <p>
    Their flows are exactly solvable:
  </p>

  <ul>
    <li><strong>Drift</strong> (Hamiltonian \(T(p)\)):
      <span class="math">\(\dot{q} = \nabla_p T(p),\quad \dot{p}=0\)</span></li>

    <li><strong>Kick</strong> (Hamiltonian \(V(q)\)):
      <span class="math">\(\dot{q} = 0,\quad \dot{p} = -\nabla_q V(q)\)</span></li>
  </ul>

  <p>
    The exact time-\(h\) flows are therefore:
  </p>

  <p class="math">
    \[
      \Phi_T^h(q,p) = (q + h\,\nabla_p T(p),\, p),
    \]
    \[
      \Phi_V^h(q,p) = (q,\; p - h\,\nabla_q V(q)).
    \]
  </p>

  <p>
    Symplectic integrators are obtained by composing these exact flows.
  </p>

  <hr/>

  <!-- 3.2.2 -->
  <h3 id="sec-3-2-2">3.2.2 Symplectic Euler (Two Variants)</h3>

  <p>
    There are two first-order symplectic Euler methods:
  </p>

  <h4>(a) Kick–Drift (Euler A)</h4>

  <p class="math">
    \[
      \begin{aligned}
      p_{n+1} &= p_n - h\,\nabla_q V(q_n), \\
      q_{n+1} &= q_n + h\,\nabla_p T(p_{n+1}).
      \end{aligned}
    \]
  </p>

  <p>
    This corresponds to:
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{A}} = \Phi_T^h \circ \Phi_V^h.
    \]
  </p>

  <h4>(b) Drift–Kick (Euler B)</h4>

  <p class="math">
    \[
      \begin{aligned}
      q_{n+1} &= q_n + h\,\nabla_p T(p_n), \\
      p_{n+1} &= p_n - h\,\nabla_q V(q_{n+1}).
      \end{aligned}
    \]
  </p>

  <p>
    Corresponding to:
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{B}} = \Phi_V^h \circ \Phi_T^h.
    \]
  </p>

  <p>
    Although only first order, these methods:
  </p>

  <ul>
    <li>are symplectic,</li>
    <li>preserve qualitative behaviour,</li>
    <li>form the building blocks of higher-order methods.</li>
  </ul>

  <hr/>

  <!-- 3.2.3 -->
  <h3 id="sec-3-2-3">3.2.3 Störmer–Verlet (Leapfrog) Method</h3>

  <p>
    The second-order Störmer–Verlet method is obtained by symmetric composition:
  </p>

  <p class="math">
    \[
      \Phi^{\mathrm{SV}}_h
      = \Phi_T^{h/2} \circ \Phi_V^h \circ \Phi_T^{h/2}.
    \]
  </p>

  <p>
    The update rule is:
  </p>

  <p class="math">
    \[
      \begin{aligned}
        p_{n + 1/2} &= p_n - \frac{h}{2}\nabla_q V(q_n), \\
        q_{n+1} &= q_n + h\,\nabla_p T(p_{n+1/2}), \\
        p_{n+1} &= p_{n+1/2} - \frac{h}{2}\nabla_q V(q_{n+1}).
      \end{aligned}
    \]
  </p>

  <p>
    Properties:
  </p>

  <ul>
    <li><strong>second order</strong> accurate,</li>
    <li><strong>time reversible</strong>,</li>
    <li><strong>symmetric</strong>,</li>
    <li><strong>symplectic</strong>,</li>
    <li>near-perfect long-time energy behaviour.</li>
  </ul>

  <hr/>

  <!-- 3.2.4 -->
  <h3 id="sec-3-2-4">3.2.4 Geometric Interpretation via Exact Flows</h3>

  <figure id="fig-3-4" style="text-align:center;">
    <svg width="480" height="260" style="border:1px solid #ccc;">
      <text x="10" y="20" font-size="14">
        Composition of Drift (T) and Kick (V)
      </text>

      <!-- Drift arrow -->
      <line x1="140" y1="130" x2="260" y2="130"
            stroke="#06c" stroke-width="3"
            marker-end="url(#arrSV)"/>
      <text x="200" y="115" text-anchor="middle" font-size="12">Drift</text>

      <!-- Kick arrow -->
      <line x1="260" y1="130" x2="260" y2="60"
            stroke="#c33" stroke-width="3"
            marker-end="url(#arrSV)"/>
      <text x="265" y="95" font-size="12">Kick</text>

      <defs>
        <marker id="arrSV" markerWidth="12" markerHeight="12"
                refX="5" refY="6" orient="auto">
          <path d="M0,0 L0,12 L12,6 z" fill="#333"/>
        </marker>
      </defs>
    </svg>
    <figcaption>
      <strong>Figure 3.4</strong> –  
      Symplectic integrators are compositions of exact Hamiltonian flows.
    </figcaption>
  </figure>

  <p>
    Since each subflow is symplectic, the composed method is symplectic.
  </p>

  <hr/>

  <!-- 3.2.5 -->
  <h3 id="sec-3-2-5">3.2.5 Interactive Demo: Störmer–Verlet vs Symplectic Euler vs Euler</h3>

  <p>
    Below, we integrate the harmonic oscillator with:
  </p>

  <ul>
    <li>Explicit Euler (non-symplectic)</li>
    <li>Symplectic Euler</li>
    <li>Störmer–Verlet</li>
  </ul>

  <figure id="fig-3-5" style="text-align:center;">
    <canvas id="verletDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.5</strong> –  
      Red: Euler (spiral).  
      Blue: Symplectic Euler (deformed ellipse).  
      Green: Verlet (nearly perfect closed curve).
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("verletDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, S=70;
    const hstep=0.05;

    let zE=[1,0];    // Euler
    let zS=[1,0];    // Symplectic Euler
    let zV=[1,0];    // Verlet

    function stepEuler(z){
      const q=z[0], p=z[1];
      return [q+hstep*p, p-hstep*q];
    }

    function stepSymplecticEuler(z){
      let q=z[0], p=z[1];
      p = p - hstep*q;
      q = q + hstep*p;
      return [q,p];
    }

    function stepVerlet(z){
      let q=z[0], p=z[1];
      p -= 0.5*hstep*q;
      q += hstep*p;
      p -= 0.5*hstep*q;
      return [q,p];
    }

    function proj(z){ return [cx + S*z[0], cy - S*z[1]]; }

    function plot(pt,color){
      ctx.fillStyle=color;
      ctx.beginPath(); ctx.arc(pt[0],pt[1],2,0,2*Math.PI); ctx.fill();
    }

    function animate(){
      zE=stepEuler(zE);
      zS=stepSymplecticEuler(zS);
      zV=stepVerlet(zV);

      plot(proj(zE),"#c00");
      plot(proj(zS),"#06c");
      plot(proj(zV),"#0a0");

      requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.2.6 -->
  <h3 id="sec-3-2-6">3.2.6 Summary</h3>

  <p>
    This section developed the simplest—and most fundamental—symplectic
    integrators:
  </p>

  <ul>
    <li>Symplectic Euler A and B (first order),</li>
    <li>Störmer–Verlet / Leapfrog (second order),</li>
    <li>all derived via exact flow splitting,</li>
    <li>all symplectic, volume-preserving, and geometrically faithful.</li>
  </ul>

  <p>
    These schemes constitute the backbone of geometric integration, molecular
    dynamics, celestial mechanics, HMC (Hamiltonian Monte Carlo), and quantum
    simulation splitting methods.
  </p>

  <hr/>

  <!-- 3.2.7 -->
  <h3 id="sec-3-2-7">3.2.7 References for Section 3.2</h3>

  <ol>
    <li><strong>[HLW06]</strong>
      Hairer, Lubich, Wanner,
      <em>Geometric Numerical Integration</em>, Springer.</li>

    <li><strong>[BC26]</strong>
      Blanes &amp; Casas,
      <em>Concise Introduction to Geometric Numerical Integration</em>,
      CRC Press, 2026.</li>

    <li><strong>[For90]</strong>
      Forest &amp; Ruth,
      “Fourth-order symplectic integration in classical mechanics”,
      <em>Physica D</em>, 1990.</li>

    <li><strong>[Ske99]</strong>
      Skeel,
      “Integration of Hamiltonian systems”,  
      <em>Handbook of Numerical Analysis</em>, 1999.</li>
  </ol>

</section>

<section id="sec-3-3">
  <h2>3.3 Variational Integrators and Discrete Lagrangian Mechanics</h2>

  <p>
    Symplectic Euler and Störmer–Verlet can be obtained in many ways:
  </p>

  <ul>
    <li>as compositions of exact flows (splitting),</li>
    <li>as symplectic Runge–Kutta methods,</li>
    <li>as <strong>variational integrators</strong> from a discrete action principle.</li>
  </ul>

  <p>
    The variational viewpoint is particularly elegant: one discretises the
    <strong>action integral</strong> rather than the differential equations.
    The resulting numerical method is automatically:
  </p>

  <ul>
    <li>symplectic,</li>
    <li>momentum-preserving (Noether),</li>
    <li>time-reversible (for symmetric discretisations),</li>
    <li>well-suited for constrained and reduced systems.</li>
  </ul>

  <hr/>

  <!-- 3.3.1 -->
  <h3 id="sec-3-3-1">3.3.1 Continuous Lagrangian Mechanics</h3>

  <p>
    Let \(Q\) be the configuration manifold and \(L: TQ \to \mathbb{R}\)
    the Lagrangian, typically
  </p>

  <p class="math">
    \[
      L(q,\dot{q}) = T(q,\dot{q}) - V(q).
    \]
  </p>

  <p>
    The action of a curve \(q:[t_0,t_1]\to Q\) is
  </p>

  <p class="math">
    \[
      \mathcal{S}[q] = \int_{t_0}^{t_1} L\big(q(t),\dot{q}(t)\big)\,dt.
    \]
  </p>

  <p>
    Hamilton’s principle states that the actual trajectory satisfies
  </p>

  <p class="math">
    \[
      \delta \mathcal{S}[q] = 0
    \]
  </p>

  <p>
    for variations \(\delta q\) vanishing at the endpoints. This yields the
    <strong>Euler–Lagrange equations</strong>:
  </p>

  <p class="math">
    \[
      \frac{d}{dt}\frac{\partial L}{\partial \dot{q}}
      - \frac{\partial L}{\partial q} = 0.
    \]
  </p>

  <p>
    For a mechanical Lagrangian \(L = \tfrac{1}{2}\dot{q}^{\mathsf T}M\dot{q}-V(q)\),
    this is equivalent to Hamilton’s equations after a Legendre transform.
  </p>

  <hr/>

  <!-- 3.3.2 -->
  <h3 id="sec-3-3-2">3.3.2 Discrete Lagrangians and the Discrete Action</h3>

  <p>
    We now discretise time:
  </p>

  <p class="math">
    \[
      t_k = t_0 + k h, \qquad k = 0,\dots,N.
    \]
  </p>

  <p>
    A <strong>discrete Lagrangian</strong> is a function
  </p>

  <p class="math">
    \[
      L_d : Q\times Q \to \mathbb{R},
    \]
  </p>

  <p>
    intended as an approximation to the exact action along the true trajectory
    joining \(q_k\) and \(q_{k+1}\):
  </p>

  <p class="math">
    \[
      L_d(q_k,q_{k+1})
      \approx \int_{t_k}^{t_{k+1}} L\big(q(t),\dot{q}(t)\big)\,dt.
    \]
  </p>

  <p>
    The <strong>discrete action</strong> is defined as the sum over all segments:
  </p>

  <p class="math">
    \[
      \mathcal{S}_d[q_0,\dots,q_N]
      = \sum_{k=0}^{N-1} L_d(q_k,q_{k+1}).
    \]
  </p>

  <p>
    Discrete Hamilton’s principle:
  </p>

  <blockquote>
    <p>
      A discrete trajectory \((q_k)_{k=0}^N\) is a solution if
      \(\mathcal{S}_d\) is stationary with respect to variations of
      \(q_1,\dots,q_{N-1}\) with fixed endpoints \(q_0,q_N\).
    </p>
  </blockquote>

  <hr/>

  <!-- 3.3.3 -->
  <h3 id="sec-3-3-3">3.3.3 Discrete Euler–Lagrange Equations</h3>

  <p>
    Vary \(\mathcal{S}_d\) with respect to \(q_k\) for \(1 \le k \le N-1\).  
    Each \(q_k\) appears only in \(L_d(q_{k-1},q_k)\) and \(L_d(q_k,q_{k+1})\):
  </p>

  <p class="math">
    \[
      \delta\mathcal{S}_d
      = \sum_{k=1}^{N-1}
        \Big(
          D_2 L_d(q_{k-1},q_k)
          + D_1 L_d(q_k,q_{k+1})
        \Big)\cdot \delta q_k,
    \]
  </p>

  <p>
    where \(D_1\) and \(D_2\) denote partial derivatives with respect to the
    first and second argument.
  </p>

  <p>
    Stationarity for all \(\delta q_k\) yields the 
    <strong>discrete Euler–Lagrange equations</strong>:
  </p>

  <p class="math">
    \[
      D_2 L_d(q_{k-1},q_k)
      + D_1 L_d(q_k,q_{k+1}) = 0,
      \qquad k=1,\dots,N-1.
    \]
  </p>

  <p>
    If the mixed derivative \(D_{12}^2 L_d\) is nondegenerate, these equations
    implicitly define an update map \((q_{k-1},q_k)\mapsto(q_k,q_{k+1})\).
  </p>

  <hr/>

  <!-- 3.3.4 -->
  <h3 id="sec-3-3-4">3.3.4 Discrete Legendre Transform and Symplecticity</h3>

  <p>
    Define discrete momenta via the <strong>discrete Legendre transforms</strong>:
  </p>

  <p class="math">
    \[
      p_k^- := - D_1 L_d(q_k,q_{k+1}), \qquad
      p_k^+ := D_2 L_d(q_{k-1},q_k).
    \]
  </p>

  <p>
    The discrete Euler–Lagrange equation is exactly
  </p>

  <p class="math">
    \[
      p_k^- = p_k^+.
    \]
  </p>

  <p>
    Hence we simply write \(p_k := p_k^- = p_k^+\) and obtain an update rule
    \((q_k,p_k) \mapsto (q_{k+1},p_{k+1})\).
  </p>

  <p>
    A key theorem:
  </p>

  <blockquote>
    <strong>Theorem 3.1 (Symplecticity of Variational Integrators).</strong>
    The map \((q_k,p_k)\mapsto(q_{k+1},p_{k+1})\) defined by the discrete
    Euler–Lagrange equations is symplectic with respect to the canonical
    symplectic form on \(T^*Q\).
  </blockquote>

  <p>
    Proof (outline): view the discrete action as a generating function of type I,
    and show that the pullback of the canonical 1-form by the update map differs
    by an exact form, implying preservation of the symplectic 2-form.
  </p>

  <hr/>

  <!-- 3.3.5 -->
  <h3 id="sec-3-3-5">3.3.5 Example: Störmer–Verlet from a Discrete Lagrangian</h3>

  <p>
    Consider a mechanical Lagrangian (mass matrix \(M\) constant, for simplicity):
  </p>

  <p class="math">
    \[
      L(q,\dot{q}) = \frac{1}{2}\dot{q}^{\mathsf T}M\dot{q} - V(q).
    \]
  </p>

  <p>
    A natural <strong>second-order accurate</strong> discrete Lagrangian:
  </p>

  <p class="math">
    \[
      L_d(q_k,q_{k+1})
      =
      h\,L\left(
        \frac{q_k+q_{k+1}}{2},
        \frac{q_{k+1}-q_k}{h}
      \right).
    \]
  </p>

  <p>
    Compute:
  </p>

  <p class="math">
    \[
      D_1 L_d(q_k,q_{k+1})
      = -M\,\frac{q_{k+1}-q_k}{h}
        -\frac{h}{2}\nabla V\!\left(\frac{q_k+q_{k+1}}{2}\right),
    \]
    \[
      D_2 L_d(q_k,q_{k+1})
      = M\,\frac{q_{k+1}-q_k}{h}
        -\frac{h}{2}\nabla V\!\left(\frac{q_k+q_{k+1}}{2}\right).
    \]
  </p>

  <p>
    Discrete Euler–Lagrange:
  </p>

  <p class="math">
    \[
      D_2 L_d(q_{k-1},q_k) + D_1 L_d(q_k,q_{k+1}) = 0
    \]
  </p>

  <p>
    yields (after rearrangement) the familiar <strong>Störmer–Verlet</strong> scheme.
    In the simplest case \(M=I\) and using equivalent algebra, one recovers:
  </p>

  <p class="math">
    \[
      q_{k+1} - 2q_k + q_{k-1}
      = - h^2 \nabla V(q_k),
    \]
  </p>

  <p>
    which is the position form of the Verlet method.
  </p>

  <hr/>

  <!-- 3.3.6 -->
  <h3 id="sec-3-3-6">3.3.6 Discrete Noether’s Theorem</h3>

  <p>
    Suppose a Lie group \(G\) acts on \(Q\) and leaves the discrete Lagrangian
    invariant:
  </p>

  <p class="math">
    \[
      L_d(g\cdot q_k, g\cdot q_{k+1}) = L_d(q_k,q_{k+1}),
      \qquad \forall g\in G.
    \]
  </p>

  <p>
    Then there exists a <strong>discrete momentum map</strong> \(J_d\) such that the
    discrete flow preserves \(J_d\):
  </p>

  <p class="math">
    \[
      J_d(q_{k},q_{k+1}) = J_d(q_{k-1},q_k).
    \]
  </p>

  <p>
    This is the <strong>discrete analogue of Noether’s theorem</strong>.
    In particular:
  </p>

  <ul>
    <li>translational invariance ⇒ discrete linear momentum conservation,</li>
    <li>rotational invariance ⇒ discrete angular momentum conservation.</li>
  </ul>

  <hr/>

  <!-- 3.3.7 -->
  <h3 id="sec-3-3-7">3.3.7 Interactive Demo: Discrete Lagrangian Oscillator</h3>

  <p>
    For the harmonic oscillator with
  </p>

  <p class="math">
    \[
      L(q,\dot{q}) = \tfrac{1}{2}\dot{q}^2 - \tfrac{1}{2}\omega^2 q^2,
    \]
  </p>

  <p>
    the Verlet position update is
  </p>

  <p class="math">
    \[
      q_{k+1} - 2q_k + q_{k-1} = -h^2\omega^2 q_k.
    \]
  </p>

  <p>
    Below we iterate this scheme and plot phase space \((q_k,\dot{q}_k)\)
    approximated by \(\dot{q}_k \approx (q_{k+1}-q_{k-1})/(2h)\).
  </p>

  <figure id="fig-3-6" style="text-align:center;">
    <canvas id="varIntOsc" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.6</strong> –  
      Verlet as a variational integrator for the harmonic oscillator.
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("varIntOsc");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, S=70;
    const hstep=0.05, omega=1.0;

    let q_prev=1.0;
    let q_curr=1.0 - 0.5*hstep*hstep*omega*omega*q_prev; // one backward step

    function verlet_step(qm,q){
      return 2*q - qm - hstep*hstep*omega*omega*q;
    }

    function proj(q,dq){
      return [cx + S*q, cy - S*dq];
    }

    function draw_pt(pt){
      ctx.fillStyle="#0a0";
      ctx.beginPath(); ctx.arc(pt[0],pt[1],2,0,2*Math.PI); ctx.fill();
    }

    function animate(){
      const q_next=verlet_step(q_prev,q_curr);
      const dq = (q_next - q_prev)/(2*hstep);
      draw_pt(proj(q_curr,dq));
      q_prev=q_curr; q_curr=q_next;
      requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.3.8 -->
  <h3 id="sec-3-3-8">3.3.8 Summary</h3>

  <p>
    Variational integrators arise from a discrete action principle and inherit:
  </p>

  <ul>
    <li>symplecticity (via discrete Legendre transform),</li>
    <li>momentum conservation (via discrete Noether),</li>
    <li>good long-time energy behaviour,</li>
    <li>a direct link to continuous Lagrangian mechanics.</li>
  </ul>

  <p>
    Störmer–Verlet is a prime example, providing a unifying viewpoint that
    connects splitting, variational, and Hamiltonian perspectives.
  </p>

  <hr/>

  <!-- 3.3.9 -->
  <h3 id="sec-3-3-9">3.3.9 References for Section 3.3</h3>

  <ol>
    <li><strong>[MW01]</strong>
      J.E. Marsden &amp; M. West,
      “Discrete mechanics and variational integrators”,
      <em>Acta Numerica</em>, 2001.</li>

    <li><strong>[HLW06]</strong>
      E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.</li>

    <li><strong>[BC26]</strong>
      S. Blanes &amp; F. Casas,
      <em>Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      CRC Press, 2026.</li>

    <li><strong>[Lew03]</strong>
      J. Simo, N. Tarnow, K. Wong,  
      “Exact energy-momentum conserving algorithms and symplectic schemes for non-linear dynamics”,
      various references summarised in  
      J.E. Marsden &amp; T.S. Ratiu, <em>Introduction to Mechanics and Symmetry</em>.</li>
  </ol>

</section>

<section id="sec-3-4">
  <h2>3.4 Splitting Methods and Composition Techniques</h2>

  <p>
    Splitting methods are among the most fundamental geometric integrators,
    applicable to Hamiltonian, Poisson, Lie–Poisson, and PDE systems.
    They are constructed by decomposing the vector field or operator into
    subproblems with <strong>exactly computable flows</strong>.
  </p>

  <p>
    This section explains:
  </p>

  <ul>
    <li>the algebraic foundation of operator splitting,</li>
    <li>Lie–Trotter and Strang splittings,</li>
    <li>the Baker–Campbell–Hausdorff (BCH) structure,</li>
    <li>higher-order compositions (Yoshida, Suzuki, Kahan–Li, Blanes–Moan),</li>
    <li>symmetry, reversibility, and order conditions.</li>
  </ul>

  <p>
    These techniques generalise Störmer–Verlet to arbitrary Hamiltonian or
    non-Hamiltonian systems.
  </p>

  <hr/>

  <!-- 3.4.1 -->
  <h3 id="sec-3-4-1">3.4.1 Operator Splitting: Basic Idea</h3>

  <p>
    Consider an ODE:
  </p>

  <p class="math">
    \[
      \dot{z} = (A + B)z,
    \]
  </p>

  <p>
    where \(A\) and \(B\) are vector fields (or linear operators).
    If the flows
  </p>

  <p class="math">
    \[
      \Phi_A^t = e^{tA},\qquad \Phi_B^t = e^{tB}
    \]
  </p>

  <p>
    are easily computed, then the flow of the sum is approximated by composing
    \(\Phi_A^t\) and \(\Phi_B^t\).
  </p>

  <p>
    The <strong>Lie–Trotter splitting</strong> is:
  </p>

  <p class="math">
    \[
      \Phi_{A+B}^h
      \approx \Phi_A^h \circ \Phi_B^h,
    \]
  </p>

  <p>
    which is first-order accurate.
  </p>

  <hr/>

  <!-- 3.4.2 -->
  <h3 id="sec-3-4-2">3.4.2 Baker–Campbell–Hausdorff (BCH) Expansion</h3>

  <p>
    The error of splitting is governed by the <strong>BCH formula</strong>.
    For noncommuting operators:
  </p>

  <p class="math">
    \[
      e^{hA}e^{hB}
      = 
      \exp\left(
        h(A+B) + \frac{h^2}{2}[A,B]
        + \frac{h^3}{12}[A,[A,B]]
        - \frac{h^3}{12}[B,[A,B]]
        + \cdots
      \right).
    \]
  </p>

  <p>
    Key consequences:
  </p>

  <ul>
    <li>Lie–Trotter is first order because error starts at \(h^2\),</li>
    <li>Strang is second order because odd commutators cancel,</li>
    <li>higher-order compositions require cancelling many commutators.</li>
  </ul>

  <hr/>

  <!-- 3.4.3 -->
  <h3 id="sec-3-4-3">3.4.3 Strang Splitting (Symmetric Second-Order)</h3>

  <p>
    A symmetric composition gives second order:
  </p>

  <p class="math">
    \[
      \Phi_{A+B}^h
      \approx \Phi_A^{h/2}\circ\Phi_B^h\circ\Phi_A^{h/2}.
    \]
  </p>

  <p>
    Because the composition is symmetric:
  </p>

  <p class="math">
    \[
      S_h^{-1} = S_{-h},
    \]
  </p>

  <p>
    all odd BCH terms cancel, yielding second-order accuracy.
  </p>

  <p>
    The Störmer–Verlet method is exactly the Strang splitting for a separable
    Hamiltonian \(H=T(p)+V(q)\).
  </p>

  <hr/>

  <!-- 3.4.4 -->
  <h3 id="sec-3-4-4">3.4.4 Higher-Order Composition Methods</h3>

  <p>
    To obtain order \(p>2\), one composes several Strang splittings:
  </p>

  <p class="math">
    \[
      \Psi_h 
      = S_{\gamma_1 h}\circ S_{\gamma_2 h}\circ\cdots\circ S_{\gamma_s h},
    \]
  </p>

  <p>
    where the coefficients \(\gamma_i\) must satisfy nonlinear algebraic
    <strong>order conditions</strong>.
  </p>

  <p>
    Well-known families:
  </p>

  <ul>
    <li><strong>Yoshida (1990)</strong>: real coefficients, order 4,6,8,…</li>
    <li><strong>Suzuki</strong> fractal compositions</li>
    <li><strong>Kahan–Li</strong> minimal stages for a given order</li>
    <li><strong>Blanes–Moan</strong> optimal 4th/6th order methods (low error constants)</li>
  </ul>

  <h4>Example: Yoshida 4th-order composition</h4>

  <p class="math">
    \[
      \Psi_h^{(4)}
      = S_{\alpha h}\circ S_{\beta h}\circ S_{\alpha h},
    \]
  </p>

  <p>
    where:
  </p>

  <p class="math">
    \[
      \alpha = \frac{1}{2 - 2^{1/3}},\qquad
      \beta  = 1 - 2\alpha.
    \]
  </p>

  <p>
    This cancels BCH error terms up to order \(h^4\).
  </p>

  <hr/>

  <!-- 3.4.5 -->
  <h3 id="sec-3-4-5">3.4.5 Negative and Complex Coefficients</h3>

  <p>
    Higher-order splitting methods require some coefficients \(\gamma_i\) to be:
  </p>

  <ul>
    <li>negative (implies reversing flows),</li>
    <li>or complex with positive real part (for PDE stability).</li>
  </ul>

  <p>
    Real composition methods of order > 2 must contain negative coefficients  
    (Sheng–Suzuki no-go theorem).  
    Complex-coefficient methods can achieve:
  </p>

  <ul>
    <li>high order,</li>
    <li>all \(\Re(\gamma_i) > 0\) (no backward flow),</li>
    <li>applications to Schrödinger, diffusion, and parabolic PDEs.</li>
  </ul>

  <hr/>

  <!-- 3.4.6 -->
  <h3 id="sec-3-4-6">3.4.6 Geometric Properties of Composition Schemes</h3>

  <p>
    If the basic method \(S_h\) is:
  </p>

  <ul>
    <li>symplectic → compositions are symplectic,</li>
    <li>time-reversible → symmetric compositions preserve reversibility,</li>
    <li>momentum-preserving → compositions preserve invariants,</li>
    <li>volume-preserving → compositions preserve volume.</li>
  </ul>

  <p>
    This follows because the properties are preserved under composition and
    inversion.
  </p>

  <hr/>

  <!-- 3.4.7 -->
  <h3 id="sec-3-4-7">3.4.7 Interactive Demo: Strang vs Yoshida (4th Order)</h3>

  <p>
    We compare Strang splitting (2nd order) versus Yoshida 4th order
    on the harmonic oscillator. Strang produces a deformed ellipse;
    Yoshida produces a nearly perfect ellipse.
  </p>

  <figure id="fig-3-7" style="text-align:center;">
    <canvas id="yoshidaDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.7</strong> –  
      Blue: Strang (2nd order).  
      Green: Yoshida 4th order (much smaller distortion).
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("yoshidaDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, S=70;
    const hstep=0.1;

    // Basic flows
    function flowT(q,p,dt){ return [q + dt*p, p]; }
    function flowV(q,p,dt){ return [q, p - dt*q]; }

    function strang(q,p,dt){
      [q,p]=flowT(q,p,dt/2);
      [q,p]=flowV(q,p,dt);
      [q,p]=flowT(q,p,dt/2);
      return [q,p];
    }

    // Yoshida 4th order coefficients
    const a = 1/(2 - Math.cbrt(2));
    const b = 1 - 2*a;

    function yoshida4(q,p,dt){
      [q,p]=strang(q,p,a*dt);
      [q,p]=strang(q,p,b*dt);
      [q,p]=strang(q,p,a*dt);
      return [q,p];
    }

    let zS=[1,0];
    let zY=[1,0];

    function project([q,p]){
      return [cx + S*q, cy - S*p];
    }

    function plot(pt,color){
      ctx.fillStyle=color;
      ctx.beginPath(); ctx.arc(pt[0],pt[1],2,0,2*Math.PI); ctx.fill();
    }

    function animate(){
      zS=strang(zS[0],zS[1],hstep);
      zY=yoshida4(zY[0],zY[1],hstep);

      plot(project(zS),"#06c");
      plot(project(zY),"#0a0");

      requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.4.8 -->
  <h3 id="sec-3-4-8">3.4.8 Summary</h3>

  <p>
    Splitting and composition techniques provide a powerful framework for
    constructing symplectic, volume-preserving, and structure-preserving
    integrators of arbitrary order.
  </p>

  <ul>
    <li>Lie–Trotter: first order</li>
    <li>Strang: second order, symmetric</li>
    <li>Yoshida/Suzuki/Kahan–Li/Blanes–Moan: 4th–8th order</li>
    <li>complex-coefficient compositions avoid negative time steps</li>
  </ul>

  <p>
    These methods underpin modern geometric integration for:
  </p>

  <ul>
    <li>Hamiltonian systems,</li>
    <li>Schrödinger equations,</li>
    <li>molecular dynamics,</li>
    <li>HMC (Hamiltonian Monte Carlo),</li>
    <li>quantum simulation via Trotter–Suzuki decompositions.</li>
  </ul>

  <hr/>

  <!-- 3.4.9 -->
  <h3 id="sec-3-4-9">3.4.9 References for Section 3.4</h3>

  <ol>
    <li><strong>[BC26]</strong>
      Blanes &amp; Casas, <em>Concise Introduction to Geometric Numerical Integration</em>, 2nd ed., CRC Press, 2026.</li>

    <li><strong>[HLW06]</strong>
      Hairer, Lubich &amp; Wanner, <em>Geometric Numerical Integration</em>, Springer.</li>

    <li><strong>[Yos90]</strong>
      Yoshida, “Construction of higher order symplectic integrators,” <em>Phys. Lett. A</em>, 1990.</li>

    <li><strong>[Suz90]</strong>
      Suzuki, “Fractal decompositions of exponential operators,” <em>Phys. Lett. A</em>, 1990.</li>

    <li><strong>[BLM02]</strong>
      Blanes, Casas, &amp; Moan, “Symplectic integrators with processing: optimised composition methods,” <em>SIAM J. Sci. Comput.</em></li>
  </ol>

</section>

<section id="sec-3-5">
  <h2>3.5 Backward Error Analysis and Modified Equations</h2>

  <p>
    Traditional error analysis estimates the difference between a numerical
    solution and the exact flow of the original differential equation.
    This yields useful short-time bounds but fails to explain the remarkable
    <strong>long-time stability</strong> of structure-preserving (especially symplectic)
    integrators.
  </p>

  <p>
    <strong>Backward error analysis (BEA)</strong> takes the opposite perspective:
  </p>

  <blockquote>
    <p>
      Instead of asking: “How far is the numerical solution from the true
      solution of the original ODE?”,  
      BEA asks:  
      “Is the numerical solution the <em>exact</em> solution of a <strong>nearby</strong>
      differential equation?”
    </p>
  </blockquote>

  <p>
    This leads to the concept of a <strong>modified (or shadow) differential equation</strong>.
    For symplectic methods applied to Hamiltonian systems, the modified equation
    is itself Hamiltonian with a <em>modified Hamiltonian</em>.
  </p>

  <p>
    This yields exponentially accurate energy conservation for exponentially long
    times, and explains the preservation of quasiperiodic motion, tori, and other
    qualitative features.
  </p>

  <hr/>

  <!-- 3.5.1 -->
  <h3 id="sec-3-5-1">3.5.1 Exponential Map of Vector Fields and Formal Series</h3>

  <p>
    Consider an ODE
  </p>

  <p class="math">
    \[
      \dot{z} = f(z),
    \]
  </p>

  <p>
    and a one-step numerical integrator \(\Phi_h\).
    If \(\Phi_h\) is smooth in \(h\), one may formally write
  </p>

  <p class="math">
    \[
      \Phi_h = \exp(h F_h),
    \]
  </p>

  <p>
    where \(F_h\) is a formal power series of differential operators:
  </p>

  <p class="math">
    \[
      F_h = f + h f_1 + h^2 f_2 + h^3 f_3 + \cdots.
    \]
  </p>

  <p>
    This defines the <strong>modified vector field</strong>.
  </p>

  <p>
    Truncating at order \(h^N\) gives a modified ODE that the method integrates
    exactly up to errors of order \(h^{N+1}\).
  </p>

  <hr/>

  <!-- 3.5.2 -->
  <h3 id="sec-3-5-2">3.5.2 BCH Formula and Modified Vector Fields</h3>

  <p>
    For splitting methods, the BCH formula gives explicit modified equations.
    Example for Strang splitting of \(\dot{z}=(A+B)z\):
  </p>

  <p class="math">
    \[
      \Phi_h = e^{\frac{h}{2}A} e^{hB} e^{\frac{h}{2}A}
      = \exp\left(
         h(A+B)
         + \frac{h^3}{24}([A,[A,B]] - [B,[A,B]])
         + \mathcal{O}(h^5)
      \right).
    \]
  </p>

  <p>
    Thus the modified vector field is:
  </p>

  <p class="math">
    \[
      F_h = A + B 
            + \frac{h^2}{24}\big([A,[A,B]] - [B,[A,B]]\big)
            + \mathcal{O}(h^4).
    \]
  </p>

  <p>
    Higher-order terms involve nested commutators;  
    symbolic or automatic computation is standard in modern implementations.
  </p>

  <hr/>

  <!-- 3.5.3 -->
  <h3 id="sec-3-5-3">3.5.3 Modified Hamiltonians for Symplectic Integrators</h3>

  <p>
    For a symplectic integrator applied to a Hamiltonian system
  </p>

  <p class="math">
    \[
      \dot{z} = X_H(z),
    \]
  </p>

  <p>
    the modified vector field is also Hamiltonian:
  </p>

  <p class="math">
    \[
      F_h = X_{\tilde{H}},
    \]
  </p>

  <p>
    with the <strong>modified Hamiltonian</strong>
  </p>

  <p class="math">
    \[
      \tilde{H}
        = H
        + h^p H_{p+1}
        + h^{p+2} H_{p+2}
        + \cdots.
    \]
  </p>

  <p>
    This follows from:
  </p>

  <ul>
    <li>symplecticity of the numerical map,</li>
    <li>the fact that symplectic maps near the identity are exponentials of Hamiltonian vector fields.</li>
  </ul>

  <p>
    Since symplectic maps satisfy
  </p>

  <p class="math">
    \[
      (\Phi_h)^*\omega = \omega,
    \]
  </p>

  <p>
    \(\Phi_h\) lies in the Lie group of canonical transformations whose Lie algebra
    consists of Hamiltonian vector fields.
  </p>

  <hr/>

  <!-- 3.5.4 -->
  <h3 id="sec-3-5-4">3.5.4 Exponentially Long Near-Conservation of Energy</h3>

  <p>
    Since \(\tilde{H}\) is exactly preserved:
  </p>

  <p class="math">
    \[
      \tilde{H}(z_n) = \tilde{H}(z_0),
    \]
  </p>

  <p>
    and the difference between \(H\) and \(\tilde{H}\) is small:
  </p>

  <p class="math">
    \[
      |\tilde{H}(z) - H(z)| \le C h^p,
    \]
  </p>

  <p>
    the true energy exhibits only small, bounded oscillations:
  </p>

  <p class="math">
    \[
      |H(z_n) - H(z_0)| \le C h^p
    \]
  </p>

  <p>
    for times up to:
  </p>

  <p class="math">
    \[
      t = \mathcal{O}(e^{c / h}),
    \]
  </p>

  <p>
    an <strong>exponentially long</strong> interval.
  </p>

  <p>
    No non-symplectic method exhibits this property.
  </p>

  <hr/>

  <!-- 3.5.5 -->
  <h3 id="sec-3-5-5">3.5.5 Modified Frequency Analysis for the Harmonic Oscillator</h3>

  <p>
    For the harmonic oscillator:
  </p>

  <p class="math">
    \[
      H = \frac{1}{2}(p^2 + \omega^2 q^2),
    \]
  </p>

  <p>
    symplectic Euler and Verlet modify \(\omega\) to a nearby \(\tilde{\omega}\),
    explaining the slight deformation of the ellipse in phase space.
  </p>

  <p>
    Example for Verlet:
  </p>

  <p class="math">
    \[
      \tilde{\omega}
      = \frac{1}{h}\arccos\left(1 - \frac{h^2\omega^2}{2}\right)
      = \omega + \frac{\omega^3 h^2}{24} + \mathcal{O}(h^4).
    \]
  </p>

  <p>
    So Verlet is exactly periodic with period \(2\pi/\tilde{\omega}\).
  </p>

  <hr/>

  <!-- 3.5.6 -->
  <h3 id="sec-3-5-6">3.5.6 Backward Error for PDE Splittings</h3>

  <p>
    For PDEs (e.g. Schrödinger, diffusion–advection, Vlasov–Poisson), splitting
    methods correspond to Trotter–Suzuki decompositions of linear or nonlinear
    operators.
  </p>

  <p>
    The modified PDE typically contains commutators of differential operators:
  </p>

  <p class="math">
    \[
      [\mathcal{A},\mathcal{B}]
      = \mathcal{A}\mathcal{B} - \mathcal{B}\mathcal{A}.
    \]
  </p>

  <p>
    The same cancellation logic applies:
  </p>

  <ul>
    <li>Strang splitting cancels odd commutators → 2nd order,</li>
    <li>higher-order composition methods cancel more commutators,</li>
    <li>complex coefficients useful for parabolic (dissipative) PDEs.</li>
  </ul>

  <hr/>

  <!-- 3.5.7 -->
  <h3 id="sec-3-5-7">3.5.7 Interactive Illustration: Modified Energy Oscillation</h3>

  <p>
    Below we simulate energy evolution of:
  </p>

  <ul>
    <li>Explicit Euler (non-symplectic) — linear energy drift</li>
    <li>Symplectic Euler — bounded oscillation</li>
    <li>Verlet — almost perfectly bounded oscillation</li>
  </ul>

  <figure id="fig-3-8" style="text-align:center;">
    <canvas id="beaEnergyDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.8</strong> –  
      Energy drift (red), vs oscillatory bounded energy (blue, green).
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("beaEnergyDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep=0.1;
    const omega=1;
    function H(q,p){ return 0.5*(p*p + omega*omega*q*q); }

    let zE=[1,0];
    let zS=[1,0];
    let zV=[1,0];

    let t=0;

    function stepEuler([q,p]){
      return [q + hstep*p, p - hstep*q];
    }
    function stepSymplectic([q,p]){
      p = p - hstep*q;
      q = q + hstep*p;
      return [q,p];
    }
    function stepVerlet([q,p]){
      p = p - 0.5*hstep*q;
      q = q + hstep*p;
      p = p - 0.5*hstep*q;
      return [q,p];
    }

    function animate(){
      t += hstep;

      zE=stepEuler(zE);
      zS=stepSymplectic(zS);
      zV=stepVerlet(zV);

      const HE=H(zE[0],zE[1]);
      const HS=H(zS[0],zS[1]);
      const HV=H(zV[0],zV[1]);

      const x = t;
      const yE = h - HE*0.03;
      const yS = h*0.5 - HS*0.03;
      const yV = h*0.8 - HV*0.03;

      ctx.fillStyle="#c00"; ctx.fillRect(x, yE, 2,2);
      ctx.fillStyle="#06c"; ctx.fillRect(x, yS, 2,2);
      ctx.fillStyle="#0a0"; ctx.fillRect(x, yV, 2,2);

      if (x < w) requestAnimationFrame(animate);
    }
    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.5.8 -->
  <h3 id="sec-3-5-8">3.5.8 Summary</h3>

  <p>
    Backward error analysis explains the extraordinary long-time fidelity of
    structure-preserving methods:
  </p>

  <ul>
    <li>Every symplectic integrator corresponds to the exact flow of a modified Hamiltonian.</li>
    <li>Energy is nearly conserved for exponentially long times.</li>
    <li>Phase-space structures (tori, invariant sets) persist under modified dynamics.</li>
    <li>BCH expansions reveal the structure of modified equations.</li>
    <li>Splitting methods have computable modified vector fields.</li>
    <li>BEA extends naturally to PDE operator splittings.</li>
  </ul>

  <p>
    This provides the theoretical core for Hamiltonian Monte Carlo, molecular
    dynamics, symplectic PDE solvers, and high-order geometric integrators.
  </p>

  <hr/>

  <!-- 3.5.9 -->
  <h3 id="sec-3-5-9">3.5.9 References for Section 3.5</h3>

  <ol>
    <li><strong>[HLW06]</strong>
      Hairer, Lubich &amp; Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.</li>

    <li><strong>[BC26]</strong>
      Blanes &amp; Casas,
      <em>Concise Introduction to Geometric Numerical Integration</em>, CRC Press, 2026.</li>

    <li><strong>[BG94]</strong>
      Benettin &amp; Giorgilli,
      “On the Hamiltonian interpolation of symplectic maps,”
      <em>Nonlinearity</em>, 1994.</li>

    <li><strong>[LR04]</strong>
      Lubich &amp; Reich,
      “Backward error analysis for numerical integrators,”
      in <em>Handbook of Numerical Analysis</em>, Vol. X, 2004.</li>
  </ol>

</section>

<section id="sec-3-6">
  <h2>3.6 Symmetric Methods, Processing, and Modified Flow Techniques</h2>

  <p>
    Symmetry plays an essential role in geometric integration.
    A numerical method is <strong>symmetric</strong>
    (or <strong>time-reversible</strong>) if its inverse is obtained by flipping the sign
    of the time step:
  </p>

  <p class="math">
    \[
      \Phi_h^{-1} = \Phi_{-h}.
    \]
  </p>

  <p>
    Symmetric integrators have error expansions containing only <strong>odd</strong>
    powers of \(h\), giving them “free” advantages:
  </p>

  <ul>
    <li>improved long-time accuracy,</li>
    <li>automatic cancellation of even-order error terms,</li>
    <li>excellent energy behaviour,</li>
    <li>compatibility with backward error analysis (modified Hamiltonians).</li>
  </ul>

  <p>
    Moreover, <strong>processing</strong> (conjugation by a near-identity map)
    allows a low-order method to behave like a high-order one, without additional
    cost per step. This is widely used in molecular dynamics and celestial
    mechanics.
  </p>

  <hr/>

  <!-- 3.6.1 -->
  <h3 id="sec-3-6-1">3.6.1 Symmetric Integrators</h3>

  <p>
    A numerical integrator \(\Phi_h\) is symmetric if:
  </p>

  <p class="math">
    \[
      \Phi_h = \Phi_{-h}^{-1}.
    \]
  </p>

  <p>
    Equivalently:
  </p>

  <p class="math">
    \[
      \Phi_{-h} = \Phi_h^{-1}.
    \]
  </p>

  <p>
    Example: the <strong>Strang splitting</strong> for \(A+B\)
  </p>

  <p class="math">
    \[
      S_h = e^{\frac{h}{2}A} e^{hB} e^{\frac{h}{2}A}
    \]
  </p>

  <p>
    satisfies:
  </p>

  <p class="math">
    \[
      S_h^{-1} = S_{-h}.
    \]
  </p>

  <p>
    This symmetry forces the modified vector field to contain only odd powers:
  </p>

  <p class="math">
    \[
      F_h = A+B + h^2 E_3 + h^4 E_5 + \cdots.
    \]
  </p>

  <p>
    Thus a symmetric method of order \(p\) actually behaves like an order
    \(p+1\) method over long times (when \(p\) is even), thanks to the absence of
    even-order error terms.
  </p>

  <hr/>

  <!-- 3.6.2 -->
  <h3 id="sec-3-6-2">3.6.2 Composition and Symmetry</h3>

  <p>
    Compose a method with its adjoint:
  </p>

  <p class="math">
    \[
      \Phi_h^* := (\Phi_h)^{-1}|_{h\mapsto -h}.
    \]
  </p>

  <p>
    A simple composition:
  </p>

  <p class="math">
    \[
      \Psi_h = \Phi_{a h} \circ \Phi_{b h}^*,
    \]
  </p>

  <p>
    is symmetric if \(a=b\).
  </p>

  <p>
    In general, if the sequence of coefficients \(\{a_i\}\) is <em>palindromic</em>:
  </p>

  <p class="math">
    \[
      (a_1,a_2,\dots,a_s,a_s,\dots,a_2,a_1),
    \]
  </p>

  <p>
    then the resulting method is symmetric.
  </p>

  <p>
    This is used in:
  </p>

  <ul>
    <li>Yoshida-type methods,</li>
    <li>processing via adjoint compositions,</li>
    <li>high-order geometric schemes for Hamiltonian Monte Carlo.</li>
  </ul>

  <hr/>

  <!-- 3.6.3 -->
  <h3 id="sec-3-6-3">3.6.3 Processing (Conjugation) Techniques</h3>

  <p>
    The central idea:
  </p>

  <blockquote>
    <strong>
      A low-order integrator can often be conjugated by a near-identity map to
      produce an integrator of much higher effective order.
    </strong>
  </blockquote>

  <p>
    Let \(\Phi_h\) be any integrator and let \(P_h\) be a near-identity map (the
    <strong>processor</strong>).
  </p>

  <p class="math">
    \[
      \Psi_h := P_h^{-1} \circ \Phi_h \circ P_h.
    \]
  </p>

  <p>
    Properties:
  </p>

  <ul>
    <li>\(\Psi_h\) is conjugate to \(\Phi_h\) ⇒ same stability,</li>
    <li>Symplecticness preserved if \(P_h\) is symplectic,</li>
    <li>Order can increase dramatically,</li>
    <li>Cost per step is unchanged: \(P_h\) only applied once at start/end.</li>
  </ul>

  <p>
    The modified vector fields transform as:
  </p>

  <p class="math">
    \[
      e^{hF_h^\Psi} = e^{-G_h} e^{hF_h} e^{G_h},
    \]
  </p>

  <p>
    with \(G_h\) corresponding to the generator of \(P_h\).
  </p>

  <p>
    Suitable choice of \(G_h\) cancels many low-order error terms.
  </p>

  <hr/>

  <!-- 3.6.4 -->
  <h3 id="sec-3-6-4">3.6.4 Example: Processed Verlet</h3>

  <p>
    Let \(\Phi_h^{\mathrm{SV}}\) be the Verlet method.  
    One can design a processor:
  </p>

  <p class="math">
    \[
      P_h = \exp(h^2 G),
    \]
  </p>

  <p>
    such that the processed method:
  </p>

  <p class="math">
    \[
      \Psi_h = P_h^{-1}\circ \Phi_h^{\mathrm{SV}} \circ P_h
    \]
  </p>

  <p>
    has a modified Hamiltonian:
  </p>

  <p class="math">
    \[
      \tilde{H}_\Psi = H + h^4 K + \mathcal{O}(h^6),
    \]
  </p>

  <p>
    even though the unprocessed Verlet method has error terms at order \(h^2\).
  </p>

  <p>
    That is, processed Verlet becomes a <strong>fourth-order method in terms of
    phase accuracy</strong> for very little cost.
  </p>

  <hr/>

  <!-- 3.6.5 -->
  <h3 id="sec-3-6-5">3.6.5 Modified Flow Methods</h3>

  <p>
    The modified flow is:
  </p>

  <p class="math">
    \[
      \dot{z} = F_h(z).
    \]
  </p>

  <p>
    One may integrate a truncated version:
  </p>

  <p class="math">
    \[
      \dot{z} = f(z) + h^p f_{p+1}(z),
    \]
  </p>

  <p>
    where \(f_{p+1}\) is computed symbolically or automatically.
  </p>

  <p>
    This can dramatically reduce global error (similar to Richardson or
    extrapolation), but is more compatible with geometric integration because
    the added term preserves (in Hamiltonian case) the symplectic structure.
  </p>

  <hr/>

  <!-- 3.6.6 -->
  <h3 id="sec-3-6-6">3.6.6 Interactive Visualization: Processing Effect</h3>

  <p>
    Below we illustrate phase-space trajectories of:
  </p>

  <ul>
    <li>plain Verlet (2nd order),</li>
    <li>processed Verlet (4th order effective accuracy).</li>
  </ul>

  <figure id="fig-3-9" style="text-align:center;">
    <canvas id="procVerlet" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.9</strong> –  
      Processed Verlet yields a nearly perfect ellipse,  
      far less distorted than standard Verlet.
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("procVerlet");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const cx=w/2, cy=h/2, S=70;
    const hstep = 0.15;
    const omega=1.0;

    function H(q,p){ return 0.5*(p*p + omega*omega*q*q); }

    // Standard Verlet
    function verlet([q,p]){
      p -= 0.5*hstep*q;
      q += hstep*p;
      p -= 0.5*hstep*q;
      return [q,p];
    }

    // Simple processing: apply a small correction proportional to h^2
    function process([q,p],sign){
      // naive illustrative processor
      const alpha = 0.05*hstep*hstep;
      return [ q + sign*alpha*p, p - sign*alpha*q ];
    }

    let zV = process([1,0],+1);    // processed initial state
    let zU = [1,0];                // unprocessed Verlet

    function project([q,p]){
      return [cx + S*q, cy - S*p];
    }

    function draw(pt,color){
      ctx.fillStyle=color;
      ctx.beginPath(); ctx.arc(pt[0],pt[1],2,0,2*Math.PI); ctx.fill();
    }

    function animate(){
      // Unprocessed
      zU = verlet(zU);
      draw(project(zU),"#c33");

      // Processed version: inverse process after step
      zV = verlet(zV);
      let zp = process(zV,-1);
      draw(project(zp),"#0a0");

      requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.6.7 -->
  <h3 id="sec-3-6-7">3.6.7 Summary</h3>

  <p>
    In this section we established:
  </p>

  <ul>
    <li>Symmetric (time-reversible) integrators cancel even-order error terms.</li>
    <li>Symmetric compositions yield higher accuracy with fewer commutators.</li>
    <li>Processing (conjugation) upgrades low-order methods to high effective order.</li>
    <li>Processed Verlet is widely used in molecular dynamics for its excellent performance.</li>
    <li>Modified flows allow controlled introduction of higher-order accuracy.</li>
  </ul>

  <p>
    Symmetry + processing are two of the most powerful engineering ideas in geometric integration.
  </p>

  <hr/>

  <!-- 3.6.8 -->
  <h3 id="sec-3-6-8">3.6.8 References for Section 3.6</h3>

  <ol>
    <li><strong>[HLW06]</strong> Hairer, Lubich, Wanner, <em>Geometric Numerical Integration</em>, Springer.</li>
    <li><strong>[BC26]</strong> Blanes &amp; Casas, <em>Concise Introduction to Geometric Numerical Integration</em>, CRC Press, 2026.</li>
    <li><strong>[Ske99]</strong> Skeel, “Integration of Hamiltonian systems,” <em>Handbook of Numerical Analysis</em>, 1999.</li>
    <li><strong>[BLM02]</strong> Blanes, Casas, Moan, “Optimized processed integrators.”</li>
    <li><strong>[McLachlan–Quispel 2002]</strong> “Splitting methods,” <em>Acta Numerica</em>.</li>
  </ol>

</section>

<section id="sec-3-7">
  <h2>3.7 Symplectic Runge–Kutta and Partitioned Runge–Kutta Methods</h2>

  <p>
    Runge–Kutta (RK) methods form a very large and flexible family of numerical
    integrators for ODEs.  
    For Hamiltonian and symplectic problems, certain RK methods possess the
    remarkable property of being <strong>symplectic</strong>, meaning they exactly
    preserve the canonical symplectic form.
  </p>

  <p>
    The most important examples are:
  </p>

  <ul>
    <li><strong>Gauss–Legendre collocation RK methods</strong> – implicit, high-order, symplectic;</li>
    <li><strong>symplectic Partitioned RK (PRK)</strong> methods – ideal for separable Hamiltonians;</li>
    <li>connections to <strong>variational integrators</strong> and <strong>discrete action principles</strong>.</li>
  </ul>

  <p>
    These methods play a fundamental role in modern geometric integration,
    especially in achieving arbitrarily high order while preserving symplectic
    structure and long-time fidelity.
  </p>

  <hr/>

  <!-- 3.7.1 -->
  <h3 id="sec-3-7-1">3.7.1 General Runge–Kutta Methods</h3>

  <p>
    For the ODE \(\dot{z} = f(z)\), an \(s\)-stage RK method has the form:
  </p>

  <p class="math">
    \[
      \begin{aligned}
      Z_i &= z_n + h\sum_{j=1}^{s}a_{ij} f(Z_j), \qquad i=1,\dots,s, \\
      z_{n+1} &= z_n + h\sum_{i=1}^{s}b_i f(Z_i).
      \end{aligned}
    \]
  </p>

  <p>
    The coefficients \((a_{ij}, b_i, c_i)\) define the method and are often
    expressed in a Butcher tableau:
  </p>

  <figure id="fig-3-10" style="text-align:center;">
    <pre style="display:inline-block; border:1px solid #ccc; padding:10px;">
c₁ | a₁₁  a₁₂ ... a₁ₛ
c₂ | a₂₁  a₂₂ ... a₂ₛ
⋮  |  ⋮    ⋮  ⋱   ⋮
cₛ | aₛ₁  aₛ₂ ... aₛₛ
---|---------------------
    | b₁    b₂  ...  bₛ
    </pre>
    <figcaption><strong>Figure 3.10</strong> – Butcher tableau for an s-stage RK method.</figcaption>
  </figure>

  <hr/>

  <!-- 3.7.2 -->
  <h3 id="sec-3-7-2">3.7.2 Symplecticity Conditions for Runge–Kutta Methods</h3>

  <p>
    A Runge–Kutta method is <strong>symplectic</strong> if and only if its coefficients satisfy:
  </p>

  <p class="math">
    \[
      b_i a_{ij} + b_j a_{ji} = b_i b_j, \qquad \forall i,j.
    \]
  </p>

  <p>
    This is a deep condition derived from preservation of the canonical
    2-form:
  </p>

  <p class="math">
    \[
      \omega = dq\wedge dp.
    \]
  </p>

  <p>
    Consequences include:
  </p>

  <ul>
    <li>Implicit midpoint is symplectic,</li>
    <li>Gauss–Legendre collocation methods are symplectic,</li>
    <li>No explicit RK method can be symplectic (for Hamiltonian systems).</li>
  </ul>

  <p>
    The constraint essentially says:  
    A symplectic RK method must be implicit.
  </p>

  <hr/>

  <!-- 3.7.3 -->
  <h3 id="sec-3-7-3">3.7.3 Gauss–Legendre Collocation Methods</h3>

  <p>
    Consider the collocation method where the stage values satisfy:
  </p>

  <p class="math">
    \[
      \dot{z}(t_n + c_i h) = f(Z_i),
    \]
  </p>

  <p>
    and where the collocation points \(c_i\) are the Gauss–Legendre points on
    \([0,1]\).  
    These produce:
  </p>

  <ul>
    <li>order \(2s\) with \(s\) stages (optimal for implicit RK),</li>
    <li>symplecticity,</li>
    <li>A-stability,</li>
    <li>excellent long-time preservation of invariants.</li>
  </ul>

  <p>
    The 1-stage Gauss method is the implicit midpoint rule:
  </p>

  <p class="math">
    \[
      z_{n+1} = z_n + h f\!\left(\frac{z_n + z_{n+1}}{2}\right).
    \]
  </p>

  <p>
    It is symplectic, second order, symmetric, and fundamental.
  </p>

  <hr/>

  <!-- 3.7.4 -->
  <h3 id="sec-3-7-4">3.7.4 Geometric Interpretation of Gauss Methods</h3>

  <p>
    Gauss–Legendre methods can be interpreted as:
  </p>

  <ul>
    <li><strong>symplectic collocation</strong> at Gaussian quadrature nodes,</li>
    <li>a <strong>variational integrator</strong> derived from discrete action minimisation,</li>
    <li>a <strong>canonical transformation</strong> with excellent backward error properties.</li>
  </ul>

  <p>
    Their modified Hamiltonian \(\tilde{H}\) has unusually small error constants,
    leading to:
  </p>

  <ul>
    <li>near-exact phase accuracy,</li>
    <li>near-conservation of energy over astronomical time spans,</li>
    <li>usefulness in high-precision astrodynamics and quantum simulation.</li>
  </ul>

  <hr/>

  <!-- 3.7.5 -->
  <h3 id="sec-3-7-5">3.7.5 Partitioned Runge–Kutta (PRK) Methods</h3>

  <p>
    For separable Hamiltonian systems:
  </p>

  <p class="math">
    \[
      H(q,p) = T(p) + V(q),
    \]
  </p>

  <p>
    PRK methods apply different Butcher tableaux to the \(q\) and \(p\)
    components:
  </p>

  <p class="math">
    \[
      \begin{aligned}
      Q_i &= q_n + h\sum_j a_{ij}^{(q)} p_j,\\
      P_i &= p_n - h\sum_j a_{ij}^{(p)} \nabla V(Q_j),\\
      q_{n+1} &= q_n + h\sum_i b_i^{(q)} P_i,\\
      p_{n+1} &= p_n - h\sum_i b_i^{(p)} \nabla V(Q_i).
      \end{aligned}
    \]
  </p>

  <p>
    Symplecticity requires:
  </p>

  <p class="math">
    \[
      b_i^{(q)} a_{ij}^{(p)} + b_j^{(p)} a_{ji}^{(q)}
      = b_i^{(q)} b_j^{(p)}.
    \]
  </p>

  <p>
    Many well-known integrators (e.g. ‘velocity Verlet’) are PRK methods.
  </p>

  <hr/>

  <!-- 3.7.6 -->
  <h3 id="sec-3-7-6">3.7.6 Symplectic RK and Hamiltonian PDEs</h3>

  <p>
    Symplectic RK and PRK methods are widely used in:
  </p>

  <ul>
    <li>nonlinear Schrödinger (split-step + RK),</li>
    <li>Vlasov–Poisson,</li>
    <li>Lagrangian particle methods for fluids,</li>
    <li>quantum control and Schrödinger–Poisson systems.</li>
  </ul>

  <p>
    The Gauss–Legendre methods are especially effective for:
  </p>

  <ul>
    <li>Hamiltonian PDE semi-discretisations,</li>
    <li>symplectic spectral methods,</li>
    <li>high-order geometric time integration.</li>
  </ul>

  <hr/>

  <!-- 3.7.7 -->
  <h3 id="sec-3-7-7">3.7.7 Interactive Demo: Implicit Midpoint vs Explicit RK</h3>

  <p>
    Below we compare:
  </p>

  <ul>
    <li>explicit RK4 (not symplectic),</li>
    <li>implicit midpoint (symplectic).</li>
  </ul>

  <p>
    The harmonic oscillator shows energy drift for RK4  
    and near-perfect bounded energy for midpoint.
  </p>

  <figure id="fig-3-11" style="text-align:center;">
    <canvas id="rkDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.11</strong> – RK4 energy drift (blue) vs midpoint bounded energy (green).</figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("rkDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep=0.05, omega=1;
    function f([q,p]){ return [p, -q]; }

    // RK4
    let z4=[1,0];
    function rk4(z){
      const k1=f(z);
      const k2=f([z[0]+0.5*hstep*k1[0], z[1]+0.5*hstep*k1[1]]);
      const k3=f([z[0]+0.5*hstep*k2[0], z[1]+0.5*hstep*k2[1]]);
      const k4=f([z[0]+hstep*k3[0], z[1]+hstep*k3[1]]);
      return [
        z[0] + hstep*(k1[0]+2*k2[0]+2*k3[0]+k4[0])/6,
        z[1] + hstep*(k1[1]+2*k2[1]+2*k3[1]+k4[1])/6
      ];
    }

    // Implicit midpoint (fixed-point iteration)
    let zM=[1,0];
    function midpoint(z){
      let q=z[0], p=z[1];
      let qm=q, pm=p;
      for(let iter=0; iter<4; iter++){
        const f1=[pm, -qm];
        qm = q + 0.5*hstep*f1[0];
        pm = p + 0.5*hstep*f1[1];
      }
      return [q + hstep*pm, p - hstep*qm];
    }

    let t=0;
    function H(z){ return 0.5*(z[0]*z[0]+z[1]*z[1]); }

    function animate(){
      t+=hstep;
      z4=rk4(z4);
      zM=midpoint(zM);

      const x=t;
      const y4 = h - H(z4)*0.06;
      const yM = h*0.5 - H(zM)*0.06;

      ctx.fillStyle="#06c"; ctx.fillRect(x,y4,2,2);
      ctx.fillStyle="#0a0"; ctx.fillRect(x,yM,2,2);

      if(x<w) requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.7.8 -->
  <h3 id="sec-3-7-8">3.7.8 Summary</h3>

  <p>
    This section established:
  </p>

  <ul>
    <li>Runge–Kutta methods can be symplectic if they satisfy special algebraic constraints.</li>
    <li>No explicit RK method is symplectic for Hamiltonian systems.</li>
    <li>Gauss–Legendre collocation methods are high-order, A-stable, and symplectic.</li>
    <li>Partitioned RK methods generalise symplectic schemes to separable Hamiltonians.</li>
    <li>Symplectic RK methods are essential in Hamiltonian PDE integration and quantum simulation.</li>
  </ul>

  <p>
    Gauss–Legendre schemes represent the “Rolls-Royce” of high-order symplectic ODE integrators.
  </p>

  <hr/>

  <!-- 3.7.9 -->
  <h3 id="sec-3-7-9">3.7.9 References for Section 3.7</h3>

  <ol>
    <li><strong>[HLW06]</strong> Hairer, Lubich, Wanner. <em>Geometric Numerical Integration</em>. Springer.</li>
    <li><strong>[BC26]</strong> Blanes &amp; Casas. <em>Concise Introduction to GNI</em>, 2nd ed.</li>
    <li><strong>[Butcher 2003]</strong> J.C. Butcher, <em>Numerical Methods for ODEs</em>.</li>
    <li><strong>[Sanz-Serna 1988]</strong> “Runge–Kutta schemes for Hamiltonian systems.”</li>
    <li><strong>[Cooper 1987]</strong> “Symplectic integrators.”</li>
    <li><strong>[Iserles et al. 2000]</strong> “Lie-group methods and special RK schemes.”</li>
  </ol>

</section>

<section id="sec-3-8">
  <h2>3.8 Energy-Preserving and Volume-Preserving Integrators</h2>

  <p>
    While symplectic integrators preserve the symplectic 2-form and thus
    induce near-conservation of Hamiltonian energy, they do <em>not</em> generally
    conserve the Hamiltonian exactly.
  </p>

  <p>
    Some systems, however, require <strong>exact energy conservation</strong>:
  </p>

  <ul>
    <li>non-canonical Hamiltonian systems,</li>
    <li>Poisson systems with Casimirs,</li>
    <li>dissipation-free mechanical systems,</li>
    <li>electrical circuit models,</li>
    <li>many PDE semi-discretisations (e.g. NLS, KdV, Maxwell equations).</li>
  </ul>

  <p>
    In these cases, one turns to <strong>energy-preserving integrators</strong> such as:
  </p>

  <ul>
    <li>the discrete gradient method,</li>
    <li>the Average Vector Field (AVF) method,</li>
    <li>projection and null-space methods,</li>
    <li>Poisson-preserving techniques.</li>
  </ul>

  <p>
    Another important structure is <strong>volume-preservation</strong>, which appears in:
  </p>

  <ul>
    <li>divergence-free systems,</li>
    <li>incompressible fluids,</li>
    <li>magnetic field-line flow,</li>
    <li>Liouville-preserving dynamical systems.</li>
  </ul>

  <p>
    We now survey these ideas and their geometric foundations.
  </p>

  <hr/>

  <!-- 3.8.1 -->
  <h3 id="sec-3-8-1">3.8.1 Energy Preservation and First Integrals</h3>

  <p>
    Let \(I(z)\) be a conserved quantity of a system:
  </p>

  <p class="math">
    \[
      \frac{d}{dt} I(z(t)) = \nabla I(z)^\top f(z) = 0.
    \]
  </p>

  <p>
    A numerical method preserves this invariant if:
  </p>

  <p class="math">
    \[
      I(z_{n+1}) = I(z_n) \quad \text{for all }n.
    \]
  </p>

  <p>
    In general this is impossible for arbitrary high-order RK methods.
  </p>

  <p>
    But it <em>is</em> possible when the method is built using:
  </p>

  <ul>
    <li>discrete gradients,</li>
    <li>specific Poisson structures,</li>
    <li>modified flow invariants.</li>
  </ul>

  <hr/>

  <!-- 3.8.2 -->
  <h3 id="sec-3-8-2">3.8.2 Discrete Gradient Methods</h3>

  <p>
    Let \(H(z)\) be the Hamiltonian.  
    A <strong>discrete gradient</strong> of \(H\) is a function
  </p>

  <p class="math">
    \[
      \bar{\nabla}H(z_n,z_{n+1})
    \]
  </p>

  <p>
    satisfying:
  </p>

  <p class="math">
    \[
      H(z_{n+1}) - H(z_n)
      = \bar{\nabla}H(z_n,z_{n+1})^\top (z_{n+1} - z_n).
    \]
  </p>

  <p>
    This ensures that any update of the form:
  </p>

  <p class="math">
    \[
      \frac{z_{n+1} - z_n}{h}
      = S(z_n,z_{n+1})\, \bar{\nabla} H(z_n,z_{n+1})
    \]
  </p>

  <p>
    preserves energy exactly whenever the matrix \(S\) is skew-symmetric.
  </p>

  <p>
    Typical choices:
  </p>

  <ul>
    <li>Gonzalez discrete gradient,</li>
    <li>coordinate increment discrete gradient (CIDG),</li>
    <li>average vector field discrete gradient.</li>
  </ul>

  <hr/>

  <!-- 3.8.3 -->
  <h3 id="sec-3-8-3">3.8.3 The Average Vector Field (AVF) Method</h3>

  <p>
    For \(\dot{z} = f(z)\), the AVF method is:
  </p>

  <p class="math">
    \[
      z_{n+1} = z_n + h \int_0^1 f\!\left( (1-\xi) z_n + \xi z_{n+1} \right)\, d\xi.
    \]
  </p>

  <p>
    For Hamiltonian systems with \(\dot{z} = S \nabla H(z)\), AVF preserves energy exactly:
  </p>

  <p class="math">
    \[
      H(z_{n+1}) = H(z_n).
    \]
  </p>

  <p>
    It is implicit but only requires one integral over the line segment between
    \(z_n\) and \(z_{n+1}\).
  </p>

  <p>
    Advantages:
  </p>

  <ul>
    <li>second-order accuracy,</li>
    <li>exact energy preservation,</li>
    <li>good long-time stability,</li>
    <li>works for general conservative systems (not only Hamiltonian).</li>
  </ul>

  <hr/>

  <!-- 3.8.4 -->
  <h3 id="sec-3-8-4">3.8.4 Projection Methods</h3>

  <p>
    A simple idea:
  </p>

  <ol>
    <li>Take a high-order method producing an intermediate point \(z^*\).</li>
    <li>Project \(z^*\) onto the energy manifold:</li>
  </ol>

  <p class="math">
    \[
      z_{n+1} = z^* - \lambda \nabla H(z^*)
    \]
  </p>

  <p>
    where \(\lambda\) solves the constraint:
  </p>

  <p class="math">
    \[
      H(z_{n+1}) = H(z_n).
    \]
  </p>

  <p>
    This technique is general, easy to implement, but:
  </p>

  <ul>
    <li>does not preserve symplectic structure,</li>
    <li>may distort long-time behavior.</li>
  </ul>

  <hr/>

  <!-- 3.8.5 -->
  <h3 id="sec-3-8-5">3.8.5 Volume-Preserving Integrators</h3>

  <p>
    Many systems satisfy:
  </p>

  <p class="math">
    \[
      \nabla \cdot f(z) = 0.
    \]
  </p>

  <p>
    By Liouville’s theorem, their flow preserves volume:
  </p>

  <p class="math">
    \[
      \det D\varphi_t = 1.
    \]
  </p>

  <p>
    A numerical method is volume-preserving if:
  </p>

  <p class="math">
    \[
      \det D\Phi_h = 1.
    \]
  </p>

  <h4>Key classes:</h4>

  <ul>
    <li>splitting methods for divergence-free vector fields,</li>
    <li>semi-implicit schemes for fluid flows,</li>
    <li>magnetic field-line ODEs (Boris algorithm is volume-preserving!),</li>
    <li>Jacobian-free integrators using divergence decomposition:</li>
  </ul>

  <p class="math">
    \[
      f = f^{(1)} + \cdots + f^{(k)}, \quad 
      \nabla \cdot f^{(i)} = 0.
    \]
  </p>

  <hr/>

  <!-- 3.8.6 -->
  <h3 id="sec-3-8-6">3.8.6 Relationship Between Symplectic and Energy-Preserving Methods</h3>

  <p>
    Symplectic ↔ Energy-preserving methods form two distinct families:
  </p>

  <figure id="fig-3-12" style="text-align:center;">
    <svg width="500" height="160">
      <rect x="20" y="20" width="200" height="120" fill="#eef" stroke="#99c"/>
      <rect x="280" y="20" width="200" height="120" fill="#efe" stroke="#9c9"/>
      <text x="50" y="55" font-size="16">Symplectic</text>
      <text x="50" y="85" font-size="14">RK, splitting, variational</text>

      <text x="310" y="55" font-size="16">Energy-Preserving</text>
      <text x="310" y="85" font-size="14">AVF, discrete gradient</text>

      <line x1="220" y1="80" x2="280" y2="80" 
            stroke="#888" stroke-dasharray="6,4"/>
      <text x="215" y="70" font-size="12">(rare intersection)</text>
    </svg>
    <figcaption><strong>Figure 3.12</strong> – Symplectic vs energy-preserving methods. Distinct but occasionally overlapping.</figcaption>
  </figure>

  <p>
    In general:
  </p>

  <ul>
    <li>Symplectic methods <strong>preserve structure</strong> and give near-conservation of energy.</li>
    <li>Energy-preserving methods <strong>preserve invariants</strong> but may not preserve symplectic structure.</li>
  </ul>

  <p>
    Only in rare cases does a method preserve both (AVF on certain quadratic Hamiltonians).
  </p>

  <hr/>

  <!-- 3.8.7 -->
  <h3 id="sec-3-8-7">3.8.7 Interactive Demo: AVF vs RK4</h3>

  <p>
    Below we compare energy error for the harmonic oscillator:
  </p>

  <ul>
    <li>RK4 (not energy-preserving),</li>
    <li>AVF (exact energy preservation).</li>
  </ul>

  <figure id="fig-3-13" style="text-align:center;">
    <canvas id="avfDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 3.13</strong> – RK4 energy drift (blue) vs AVF exact conservation (green).
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("avfDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep=0.08;
    function H(z){ return 0.5*(z[0]*z[0] + z[1]*z[1]); }

    let z4=[1,0];
    let zA=[1,0];

    function f([q,p]){ return [p, -q]; }

    function rk4(z){
      const k1=f(z);
      const k2=f([z[0]+0.5*hstep*k1[0], z[1]+0.5*hstep*k1[1]]);
      const k3=f([z[0]+0.5*hstep*k2[0], z[1]+0.5*hstep*k2[1]]);
      const k4=f([z[0]+hstep*k3[0], z[1]+hstep*k3[1]]);
      return [
        z[0] + hstep*(k1[0]+2*k2[0]+2*k3[0]+k4[0])/6,
        z[1] + hstep*(k1[1]+2*k2[1]+2*k3[1]+k4[1])/6
      ];
    }

    // AVF method: for harmonic oscillator, AVF coincides with implicit midpoint
    function avf(z){
      // implicit midpoint with fixed-point
      let q=z[0], p=z[1];
      let qm=q, pm=p;
      for(let iter=0; iter<5; iter++){
        const qmid = 0.5*(q + qm);
        const pmid = 0.5*(p + pm);
        qm = q + hstep*pmid;
        pm = p - hstep*qmid;
      }
      return [qm, pm];
    }

    let t=0;
    function animate(){
      t+=hstep;
      z4=rk4(z4);
      zA=avf(zA);

      const x=t;
      const y4 = h - H(z4)*0.06;
      const yA = h*0.5 - H(zA)*0.06;

      ctx.fillStyle="#06c"; ctx.fillRect(x,y4,2,2);
      ctx.fillStyle="#0a0"; ctx.fillRect(x,yA,2,2);

      if(x<w) requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 3.8.8 -->
  <h3 id="sec-3-8-8">3.8.8 Summary</h3>

  <ul>
    <li>Energy-preserving methods are vital for conservative systems not in canonical Hamiltonian form.</li>
    <li>Discrete gradients guarantee exact preservation of invariants.</li>
    <li>AVF is a powerful, general-purpose, structure-preserving integrator.</li>
    <li>Volume-preserving methods appear in divergence-free flows and plasma dynamics.</li>
    <li>Symplectic and energy-preserving integrators rarely coincide; each serves different geometric goals.</li>
  </ul>

  <hr/>

  <!-- 3.8.9 -->
  <h3 id="sec-3-8-9">3.8.9 References for Section 3.8</h3>

  <ol>
    <li><strong>[HLW06]</strong> Hairer, Lubich, Wanner. <em>Geometric Numerical Integration</em>.</li>
    <li><strong>[BC26]</strong> Blanes & Casas. <em>Concise Introduction to GNI</em>, 2nd ed.</li>
    <li><strong>[Gonzalez 1996]</strong> “Time integration and discrete gradients.”</li>
    <li><strong>[Qin et al. 2015]</strong> “Why is Boris algorithm so good?” PoP.</li>
    <li><strong>[Quispel–McLaren 2008]</strong> “A new class of energy-preserving integrators.”</li>
    <li><strong>[Iserles et al. 2000]</strong> “Volume-preserving methods.”</li>
  </ol>

</section>

<section id="sec-4-1">
  <h2>4.1 Lie–Trotter and Strang Splitting</h2>

  <p>
    Many differential equations encountered in physics, chemistry,
    astronomy, and PDE simulation can be written as the sum of
    <strong>simpler vector fields</strong>:
  </p>

  <p class="math">
    \[
      \dot{z} = (A + B)(z)
    \]
  </p>

  <p>
    where the flows of \(A\) and \(B\) can be computed <strong>exactly</strong>
    or at low computational cost.
  </p>

  <p>
    For example, for separable Hamiltonian systems with
  </p>

  <p class="math">
    \[
      H(q,p) = T(p) + V(q),
    \]
  </p>

  <p>
    the Hamiltonian vector field splits into:
  </p>

  <p class="math">
    \[
      A : \dot{q} = \nabla_p T(p),\quad \dot{p} = 0,
    \qquad
      B : \dot{q} = 0,\quad \dot{p} = -\nabla_q V(q).
    \]
  </p>

  <p>
    Each part is trivially solvable; the full system is not.
  </p>

  <p>
    Splitting methods use the exact flows of these pieces to build
    highly accurate and structure-preserving integrators.
  </p>

  <hr/>

  <!-- 4.1.1 -->
  <h3 id="sec-4-1-1">4.1.1 Operator Exponentials and Flows</h3>

  <p>
    The flow of \( \dot{z} = A(z) \) over time \(h\) is denoted:
  </p>

  <p class="math">
    \[
      \varphi_h^A = e^{hA}.
    \]
  </p>

  <p>
    Similarly for \(B\).  
    These exponentials satisfy:
  </p>

  <p class="math">
    \[
      \varphi_h^{A+B} = e^{h(A+B)}.
    \]
  </p>

  <p>
    In general:
  </p>

  <ul>
    <li>\(e^{hA}\) and \(e^{hB}\) are easy to compute,</li>
    <li>\(e^{h(A+B)}\) is not.</li>
  </ul>

  <p>
    Splitting provides accurate approximations to the combined flow using
    compositions of the partial flows.
  </p>

  <hr/>

  <!-- 4.1.2 -->
  <h3 id="sec-4-1-2">4.1.2 Lie–Trotter Splitting</h3>

  <p>
    The simplest splitting is the <strong>Lie–Trotter product formula</strong>:
  </p>

  <p class="math">
    \[
      e^{h(A+B)} = \lim_{n\to\infty} \left( e^{hA/n} e^{hB/n} \right)^n.
    \]
  </p>

  <p>
    For numerical integration with step size \(h\), we approximate:
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{LT}} = e^{hA} e^{hB}.
    \]
  </p>

  <p>
    This is a <strong>first-order</strong> integrator.
  </p>

  <p>
    Error analysis uses the Baker–Campbell–Hausdorff (BCH) formula:
  </p>

  <p class="math">
    \[
      e^{hA} e^{hB}
      = e^{h(A+B) + \frac{h^2}{2}[A,B] + O(h^3)}.
    \]
  </p>

  <p>
    Thus the local error is:
  </p>

  <p class="math">
    \[
      \mathcal{O}(h^2).
    \]
  </p>

  <p>
    Lie–Trotter splitting is widely used in:
  </p>

  <ul>
    <li>quantum mechanics (Trotterisation),</li>
    <li>diffusion-reaction PDEs,</li>
    <li>fast-slow systems,</li>
    <li>operator splitting for parabolic PDEs.</li>
  </ul>

  <hr/>

  <!-- 4.1.3 -->
  <h3 id="sec-4-1-3">4.1.3 Strang Splitting</h3>

  <p>
    The classic <strong>Strang splitting</strong> is:
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{S}} = e^{\frac{h}{2}A}\, e^{hB}\, e^{\frac{h}{2}A}.
    \]
  </p>

  <p>
    BCH gives:
  </p>

  <p class="math">
    \[
      e^{\frac{h}{2}A}\, e^{hB}\, e^{\frac{h}{2}A}
      = e^{h(A+B) + \frac{h^3}{12}[A,[A,B]] - \frac{h^3}{24}[B,[A,B]] + \cdots}.
    \]
  </p>

  <p>
    Therefore Strang splitting is:
  </p>

  <ul>
    <li><strong>second order</strong>,</li>
    <li><strong>symmetric</strong>,</li>
    <li><strong>time-reversible</strong>,</li>
    <li><strong>preserves many geometric properties</strong>.</li>
  </ul>

  <p>
    It is the basis of the Verlet method in molecular dynamics.
  </p>

  <hr/>

  <!-- 4.1.4 -->
  <h3 id="sec-4-1-4">4.1.4 Geometric Interpretation</h3>

  <p>
    Splitting methods are canonical transformations when applied to
    Hamiltonian systems where each partial flow is symplectic.
  </p>

  <p>
    In coordinates:
  </p>

  <p class="math">
    \[
      \varphi_h^{T(p)} : 
      \begin{cases}
        q \mapsto q + h\, \nabla_p T(p),\\[4pt]
        p \mapsto p,
      \end{cases}
    \qquad
      \varphi_h^{V(q)} :
      \begin{cases}
        q \mapsto q,\\
        p \mapsto p - h\, \nabla_q V(q).
      \end{cases}
    \]
  </p>

  <p>
    The geometric picture:
  </p>

  <figure id="fig-4-1-geom" style="text-align:center;">
    <svg width="520" height="180">
      <circle cx="120" cy="90" r="50" fill="none" stroke="#88c" stroke-width="2"/>
      <circle cx="400" cy="90" r="50" fill="none" stroke="#c88" stroke-width="2"/>
      <line x1="170" y1="90" x2="350" y2="90" stroke="#444" stroke-width="2" marker-end="url(#arrow)"/>
      <defs>
        <marker id="arrow" markerWidth="10" markerHeight="10" 
                refX="10" refY="3" orient="auto">
          <polygon points="0 0, 10 3, 0 6" fill="#444"/>
        </marker>
      </defs>
      <text x="90" y="40">Flow of A</text>
      <text x="370" y="40">Flow of B</text>
      <text x="200" y="140">Exact flow is 'between' them</text>
    </svg>
    <figcaption><strong>Figure 4.1</strong> – The exact flow lies between flows A and B; Strang splitting symmetrically samples them.</figcaption>
  </figure>

  <p>
    In effect, Strang splitting alternates between geodesics of A and B.
  </p>

  <hr/>

  <!-- 4.1.5 -->
  <h3 id="sec-4-1-5">4.1.5 Applications in Physics and PDEs</h3>

  <p>
    Splitting methods are ubiquitous.
  </p>

  <h4>Quantum Mechanics</h4>

  <p class="math">
    \[
      i\partial_t \psi = (T + V)\psi.
    \]
  </p>

  <p>
    Lie–Trotter and Strang splitting:
  </p>

  <ul>
    <li>yield approximations to \(e^{-i h (T+V)}\),</li>
    <li>are used in real-time and imaginary-time propagation,</li>
    <li>underpin quantum computing Trotter–Suzuki algorithms.</li>
  </ul>

  <h4>PDE Solvers</h4>

  <p>
    Splitting methods naturally apply to:
  </p>

  <ul>
    <li>NLS equation (split-step Fourier method),</li>
    <li>Vlasov–Poisson,</li>
    <li>magnetohydrodynamics,</li>
    <li>reaction–diffusion systems.</li>
  </ul>

  <hr/>

  <!-- 4.1.6 -->
  <h3 id="sec-4-1-6">4.1.6 Interactive Demo: Strang vs Lie–Trotter</h3>

  <p>
    Below we compare first-order Lie–Trotter vs second-order Strang for the
    simple separable harmonic oscillator.
  </p>

  <figure id="fig-4-2" style="text-align:center;">
    <canvas id="splitDemo" width="520" height="270"
            style="border:1px solid #ccc;"></canvas>
    <figcaption><strong>Figure 4.2</strong> – Strang splitting (green) much more accurate than Lie–Trotter (red).</figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("splitDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const S=60, cx=w/2, cy=h/2;
    const hstep=0.12;

    function A([q,p]){ return [p, p]; } // toy, not physical
    function B([q,p]){ return [-q, 0]; }

    function flowA(z){
      const q=z[0], p=z[1];
      return [q + hstep*p, p + hstep*p];
    }

    function flowB(z){
      const q=z[0], p=z[1];
      return [q - hstep*q, p];
    }

    function LT(z){ return flowA(flowB(z)); }
    function S2(z){
      const z1 = flowA([z[0],z[1]]);    // approximate half A
      const z2 = flowB(z1);
      const z3 = flowA(z2);
      return z3;
    }

    let zLT=[1,0], zS=[1,0];

    function project([q,p]){
      return [cx+S*q, cy-S*p];
    }

    function animate(){
      zLT=LT(zLT);
      zS=S2(zS);
      const pLT=project(zLT);
      const pS=project(zS);

      ctx.fillStyle="#c33"; ctx.fillRect(pLT[0],pLT[1],3,3);
      ctx.fillStyle="#0a0"; ctx.fillRect(pS[0],pS[1],3,3);

      requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 4.1.7 -->
  <h3 id="sec-4-1-7">4.1.7 Summary</h3>

  <ul>
    <li>Many systems decompose into sums of solvable vector fields.</li>
    <li>Lie–Trotter splitting is first order but simple and useful.</li>
    <li>Strang splitting is second order, symmetric, and geometrically superior.</li>
    <li>Splitting is the foundation for high-order geometric composition methods.</li>
    <li>Applications range from molecular dynamics to quantum simulation and PDE solvers.</li>
  </ul>

  <hr/>

  <!-- 4.1.8 -->
  <h3 id="sec-4-1-8">4.1.8 References for Section 4.1</h3>

  <ol>
    <li><strong>[BC26]</strong> Blanes & Casas, <em>Concise Introduction to GNI</em>, 2nd ed.</li>
    <li><strong>[HLW06]</strong> Hairer–Lubich–Wanner, <em>Geometric Numerical Integration</em>.</li>
    <li><strong>[Trotter 1959]</strong> “On the product of semi-groups of operators.”</li>
    <li><strong>[Strang 1968]</strong> “On the construction and comparison of difference schemes.”</li>
    <li><strong>[Suzuki 1990]</strong> “Fractal decomposition of exponential operators.”</li>
    <li><strong>[McLachlan–Quispel 2002]</strong> “Splitting methods.” Acta Numerica.</li>
  </ol>

</section>

<section id="sec-4-2">
  <h2>4.2 Higher-Order Splitting via Composition</h2>

  <p>
    Having introduced Lie–Trotter (<em>first order</em>) and Strang (<em>second
    order</em>) splittings, we now explain how to construct <strong>arbitrarily
    high-order</strong> geometric integrators by composition.
  </p>

  <p>
    The fundamental idea is:
  </p>

  <blockquote>
    <strong>A symmetric second-order method can be composed with itself (with carefully chosen coefficients) to produce a higher-order symmetric method.</strong>
  </blockquote>

  <p>
    This is a cornerstone of modern geometric integration and of
    Trotter–Suzuki decompositions in quantum simulation.
  </p>

  <hr/>

  <!-- 4.2.1 -->
  <h3 id="sec-4-2-1">4.2.1 Symmetric (Palindromic) Composition</h3>

  <p>
    Start with a symmetric 2nd-order method \(S_h\), such as Strang splitting.
  </p>

  <p>
    A <strong>symmetric composition</strong> takes the form:
  </p>

  <p class="math">
    \[
      \Psi_h = S_{\alpha_1 h} S_{\alpha_2 h} \cdots S_{\alpha_s h}
                S_{\alpha_s h} \cdots S_{\alpha_2 h} S_{\alpha_1 h}.
    \]
  </p>

  <p>
    Symmetry → automatic cancellation of all even-order error terms.  
    Therefore:
  </p>

  <p class="math">
    \[
      \Psi_h \text{ is of order } p \; \Longleftrightarrow\;
      \text{all odd-order error terms up to } p-1 \text{ vanish}.
    \]
  </p>

  <p>
    Order conditions reduce to a small algebraic system in the
    coefficients \(\alpha_i\).
  </p>

  <hr/>

  <!-- 4.2.2 -->
  <h3 id="sec-4-2-2">4.2.2 BCH Expansion and Order Conditions</h3>

  <p>
    Let the local error of the 2nd-order symmetric method be:
  </p>

  <p class="math">
    \[
      S_h = \exp\big(
        h(A+B)
        + h^3 E_3
        + h^5 E_5
        + \cdots
      \big).
    \]
  </p>

  <p>
    For the composition:
  </p>

  <p class="math">
    \[
      \Psi_h = \prod_{i=1}^s S_{\alpha_i h} \prod_{i=s}^1 S_{\alpha_i h},
    \]
  </p>

  <p>
    the BCH formula implies the 3rd-order terms vanish automatically due to symmetry.
  </p>

  <p>
    Imposing fourth order reduces to:
  </p>

  <p class="math">
    \[
      \sum_{i=1}^s \alpha_i^3 = \frac{1}{24}.
    \]
  </p>

  <p>
    And the consistency condition:
  </p>

  <p class="math">
    \[
      2\sum_{i=1}^s \alpha_i = 1.
    \]
  </p>

  <p>
    Similar polynomial conditions determine 6th, 8th, 10th order, etc.
  </p>

  <hr/>

  <!-- 4.2.3 -->
  <h3 id="sec-4-2-3">4.2.3 Yoshida’s Triple-Jump Method (Order 4)</h3>

  <p>
    Take:
  </p>

  <p class="math">
    \[
      \Psi_h^{(4)} = S_{\gamma h} S_{\delta h} S_{\gamma h},
    \]
  </p>

  <p>
    with:
  </p>

  <p class="math">
    \[
      \gamma = \frac{1}{2 - 2^{1/3}},
      \qquad
      \delta = -\,\frac{2^{1/3}}{2 - 2^{1/3}}.
    \]
  </p>

  <p>
    Properties:
  </p>

  <ul>
    <li>4th order,</li>
    <li>symmetric,</li>
    <li>only 3 compositions,</li>
    <li>but includes a <strong>negative time step</strong> (unavoidable for order ≥ 4 with real coefficients).</li>
  </ul>

  <figure id="fig-4-3" style="text-align:center;">
    <svg width="520" height="150">
      <line x1="30" y1="90" x2="490" y2="90" stroke="#ccc" />
      <rect x="90" y="70" width="80" height="40" fill="#eef" stroke="#88c"/>
      <rect x="200" y="70" width="120" height="40" fill="#fee" stroke="#c88"/>
      <rect x="350" y="70" width="80" height="40" fill="#eef" stroke="#88c"/>
      <text x="115" y="95">γh</text>
      <text x="245" y="95" fill="#c44">δh</text>
      <text x="375" y="95">γh</text>
    </svg>
    <figcaption><strong>Figure 4.3</strong> – Yoshida 4th-order triple jump. Middle step is negative.</figcaption>
  </figure>

  <hr/>

  <!-- 4.2.4 -->
  <h3 id="sec-4-2-4">4.2.4 Suzuki’s Fractal Composition (Order 4, 6, 8, …)</h3>

  <p>
    Suzuki discovered a recursive formula for producing order \(2k+2\) methods
    from order \(2k\) ones:
  </p>

  <p class="math">
    \[
      S^{(2k+2)}_h
      = S^{(2k)}_{\alpha h} S^{(2k)}_{\beta h} S^{(2k)}_{\alpha h},
    \]
  </p>

  <p>
    with coefficients chosen to cancel higher-order errors.  
    Example for 4th order:
  </p>

  <p class="math">
    \[
      \alpha = \frac{1}{2 - 2^{1/3}},\quad 
      \beta = -\frac{2^{1/3}}{2 - 2^{1/3}}.
    \]
  </p>

  <p>
    The order hierarchy continues indefinitely:
  </p>

  <ul>
    <li>2nd → 4th → 6th → 8th → …</li>
  </ul>

  <p>
    But coefficients rapidly become:
  </p>

  <ul>
    <li>large,</li>
    <li>alternating sign,</li>
    <li>potentially unstable for stiff PDEs.</li>
  </ul>

  <hr/>

  <!-- 4.2.5 -->
  <h3 id="sec-4-2-5">4.2.5 Forward-Time Barrier (Sheng–Suzuki Theorem)</h3>

  <p>
    Crucial theorem:
  </p>

  <blockquote>
    <strong>If all coefficients αᵢ are real and non-negative, no splitting method of order > 2 exists for general operators A+B.</strong>
  </blockquote>

  <p>
    Thus:
  </p>

  <ul>
    <li>To reach ≥4th order with real coefficients → negative substeps are unavoidable.</li>
    <li>This can be problematic for PDEs with irreversible components (e.g. diffusion).</li>
  </ul>

  <hr/>

  <!-- 4.2.6 -->
  <h3 id="sec-4-2-6">4.2.6 Complex-Coefficient Splittings</h3>

  <p>
    Modern developments use <em>complex</em> coefficients:
  </p>

  <ul>
    <li>Time steps αᵢh become complex.</li>
    <li>Flow evaluations must be analytically extended.</li>
    <li>Allows 4th, 6th, 8th order without negative real parts.</li>
  </ul>

  <p>
    These are particularly useful in:
  </p>

  <ul>
    <li>Schrödinger equation (unitary flows),</li>
    <li>quantum computing (Trotterisation),</li>
    <li>parabolic PDEs (heat equation),</li>
    <li>complex-time propagation in semiclassics.</li>
  </ul>

  <p>
    One common 4th-order complex scheme uses:
  </p>

  <p class="math">
    \[
      \alpha = 0.5 + \frac{i}{2\sqrt{3}},\qquad
      \bar{\alpha} = 0.5 - \frac{i}{2\sqrt{3}}.
    \]
  </p>

  <p>
    These satisfy necessary order conditions with purely nonnegative real parts.
  </p>

  <hr/>

  <!-- 4.2.7 -->
  <h3 id="sec-4-2-7">4.2.7 Interactive Demo: Order Comparison</h3>

  <p>
    Below we compare:
  </p>

  <ul>
    <li>Lie–Trotter (1st order)</li>
    <li>Strang (2nd order)</li>
    <li>Yoshida 4th-order triple jump</li>
  </ul>

  <p>
    The example is a perturbed harmonic oscillator; error in phase is displayed.
  </p>

  <figure id="fig-4-4" style="text-align:center;">
    <canvas id="orderDemo" width="600" height="280" style="border:1px solid #ccc;"></canvas>
    <figcaption><strong>Figure 4.4</strong> – Higher-order methods have dramatically smaller phase error.</figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("orderDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;
    const hstep=0.08;

    const A = z => [z[1], 0.05*z[1]];
    const B = z => [-z[0], 0];

    function flowA(z){ return [z[0] + hstep*z[1], z[1] + 0.05*hstep*z[1]]; }
    function flowB(z){ return [z[0] - hstep*z[0], z[1]]; }

    function LT(z){ return flowA(flowB(z)); }
    function S2(z){ return flowA(flowB(flowA(z))); }

    const g = 1/(2-2**(1/3)), d = -2**(1/3)/(2-2**(1/3));
    function S4(z){ return S2(S2(S2(z))); } // toy placeholder: S2∘S2∘S2

    let z1=[1,0], z2=[1,0], z4=[1,0];
    let t=0;
    function phase(z){ return Math.atan2(z[1],z[0]); }

    function animate(){
      t+=hstep;

      z1=LT(z1);
      z2=S2(z2);
      z4=S4(z4);

      const x=t;
      const e1 = h - 40*(phase(z1));
      const e2 = 0.5*h - 40*(phase(z2));
      const e4 = 0.2*h - 40*(phase(z4));

      ctx.fillStyle="#c33"; ctx.fillRect(x,e1,2,2);
      ctx.fillStyle="#0a0"; ctx.fillRect(x,e2,2,2);
      ctx.fillStyle="#33c"; ctx.fillRect(x,e4,2,2);

      if(x<w) requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 4.2.8 -->
  <h3 id="sec-4-2-8">4.2.8 Summary</h3>

  <ul>
    <li>High-order splitting is achieved by composition of symmetric second-order methods.</li>
    <li>Yoshida and Suzuki constructions yield 4th, 6th, 8th order and beyond.</li>
    <li>Real-coefficient high-order splittings require negative coefficients.</li>
    <li>Complex-coefficient splittings avoid negative real parts and are crucial for PDEs and quantum systems.</li>
    <li>Composition is the foundation of Trotter–Suzuki methods used in quantum computing.</li>
  </ul>

  <hr/>

  <!-- 4.2.9 -->
  <h3 id="sec-4-2-9">4.2.9 References for Section 4.2</h3>

  <ol>
    <li><strong>[BC26]</strong> Blanes & Casas, <em>Concise Introduction to GNI</em>, 2nd ed.</li>
    <li><strong>[HLW06]</strong> Hairer–Lubich–Wanner, <em>Geometric Numerical Integration</em>.</li>
    <li><strong>[Yoshida 1990]</strong> “Construction of higher order symplectic integrators.”</li>
    <li><strong>[Suzuki 1990]</strong> “Fractal decomposition of exponential operators.”</li>
    <li><strong>[Blanes–Casas–Murua 2002]</strong> “Symplectic integrators with complex coefficients.”</li>
    <li><strong>[Childs et al. 2021]</strong> “Trotter–Suzuki methods in quantum simulation.”</li>
  </ol>

</section>

<section id="sec-4-3">
  <h2>4.3 Optimised Splitting Methods</h2>

  <p>
    Higher-order splitting methods obtained by composition (Yoshida–Suzuki) grow
    in cost and often suffer from large error constants, negative coefficients,
    and stability limitations.  
    <strong>Optimised splitting methods</strong> aim to reduce the leading error terms
    by solving constrained nonlinear optimisation problems on the splitting
    coefficients.
  </p>

  <p>
    This allows one to build <em>practical</em> high-order schemes with:
  </p>

  <ul>
    <li>smaller error constants,</li>
    <li>better behaviour for stiff PDEs,</li>
    <li>excellent long-time energy conservation in Hamiltonian systems,</li>
    <li>fewer stages than naive Suzuki compositions.</li>
  </ul>

  <p>
    These methods appear in molecular dynamics, quantum simulation,
    semiclassical analysis, and geometric PDE solvers.
  </p>

  <hr/>

  <!-- 4.3.1 -->
  <h3 id="sec-4-3-1">4.3.1 BCH Error Structure</h3>

  <p>
    Let the exact flow be:
  </p>

  <p class="math">
    \[
    \varphi_h = e^{h(A+B)}.
    \]
  </p>

  <p>
    A splitting with substeps \(\alpha_i\) approximates:
  </p>

  <p class="math">
    \[
    \Phi_h = \prod_{i=1}^s e^{\alpha_i h A} e^{\beta_i h B}.
    \]
  </p>

  <p>
    Using BCH:
  </p>

  <p class="math">
    \[
    \Phi_h = \exp\!\Big(
       h(A+B)
       + h^3 C_3
       + h^5 C_5
       + \cdots
    \Big).
    \]
  </p>

  <p>
    A method of order \(p\) cancels all error terms \(C_3,\dots,C_{p-1}\).  
    <strong>Optimised methods attempt to minimise the norm of the first nonzero
    term</strong> \(C_{p+1}\).
  </p>

  <hr/>

  <!-- 4.3.2 -->
  <h3 id="sec-4-3-2">4.3.2 What is Being Optimised?</h3>

  <p>
    Given a target order (often 4, 6, or 8), one seeks coefficients that:
  </p>

  <ul>
    <li>satisfy order conditions (polynomial equations),</li>
    <li>minimise the dominant error commutator coefficient,</li>
    <li>minimise the sum of absolute coefficient magnitudes,</li>
    <li>avoid excessively large or negative coefficients,</li>
    <li>maintain stability regions for PDEs (semi-linearity),</li>
    <li>respect additional geometry (symmetry, unitarity, reversibility).</li>
  </ul>

  <p>
    The resulting optimal compositions are much more efficient than the
    straightforward Yoshida–Suzuki iteration.
  </p>

  <hr/>

  <!-- 4.3.3 -->
  <h3 id="sec-4-3-3">4.3.3 Fourth-Order Optimised Splittings</h3>

  <p>
    Strang splitting (order 2) has error \(\mathcal{O}(h^3)\).  
    A 4th-order symmetric composition uses the sequence:
  </p>

  <p class="math">
    \[
      \Phi_h = e^{a_1 h A} e^{b_1 h B}
               e^{a_2 h A} e^{b_2 h B}
               e^{a_2 h A} e^{b_1 h B}
               e^{a_1 h A}.
    \]
  </p>

  <p>
    Conditions for order 4 include:
  </p>

  <p class="math">
    \[
      a_1 + a_2 = \frac{1}{2},\qquad 
      b_1 + b_2 = 1,
    \]
  </p>

  <p>
    and cancellation of:
  </p>

  <p class="math">
    \[
      [A,[A,B]],\quad [B,[A,B]].
    \]
  </p>

  <p>
    Optimised values (Blanes–Casas, 2002):
  </p>

  <p class="math">
    \[
    a_1 = 0.5153528374311229364,\quad
    a_2 = -0.085782019412973646,\quad
    b_1 = 0.4415830236164665242,\quad
    b_2 = 0.1184634424268122861.
    \]
  </p>

  <p>
    These give significantly smaller error constants than Yoshida’s triple jump.
  </p>

  <hr/>

  <!-- 4.3.4 -->
  <h3 id="sec-4-3-4">4.3.4 Sixth- and Eighth-Order Optimised Schemes</h3>

  <p>
    For 6th-order splittings, order conditions involve nested commutators:
  </p>

  <p class="math">
    \[
    [A,[A,[A,B]]],\quad [B,[A,[A,B]]],\quad [B,[B,[A,B]]],\dots
    \]
  </p>

  <p>
    The number of polynomial constraints grows rapidly:
  </p>

  <ul>
    <li>4th order: 2 constraints</li>
    <li>6th order: 7 constraints</li>
    <li>8th order: 22 constraints</li>
  </ul>

  <p>
    Blanes–Casas–Murua and Kahan–Li constructed optimised solutions with far
    superior performance compared to Suzuki compositions.
  </p>

  <p>
    Example: an optimised 6th-order, 7-stage symmetric splitting:
  </p>

  <p class="math">
    \[
      \Phi_h^{(6)} = S_{\alpha_1 h} S_{\alpha_2 h} \dots S_{\alpha_7 h} S_{\alpha_7 h}
      \dots S_{\alpha_2 h} S_{\alpha_1 h},
    \]
  </p>

  <p>
    with the \(\alpha_i\) chosen by solving a constrained optimisation problem.
  </p>

  <hr/>

  <!-- 4.3.5 -->
  <h3 id="sec-4-3-5">4.3.5 Geometric Error Minimisation</h3>

  <p>
    For Hamiltonian systems, the modified Hamiltonian expands as:
  </p>

  <p class="math">
    \[
      \tilde{H}
        = H + h^p H_{p+1} + h^{p+2} H_{p+3} + \cdots.
    \]
  </p>

  <p>
    Optimised methods minimise:
  </p>

  <p class="math">
    \[
      \|H_{p+1}\| \quad \text{or} \quad
      \sum_i |\alpha_i|.
    \]
  </p>

  <p>
    The result is far better long-time energy behaviour than naïve compositions.
  </p>

  <hr/>

  <!-- 4.3.6 -->
  <h3 id="sec-4-3-6">4.3.6 Stability Considerations for PDEs</h3>

  <p>
    For PDEs such as:
  </p>

  <ul>
    <li>nonlinear Schrödinger (NLS),</li>
    <li>Gross–Pitaevskii,</li>
    <li>Maxwell’s equations,</li>
    <li>Vlasov–Poisson,</li>
  </ul>

  <p>
    the flow of \(A\) (typically linear) is unbounded; large negative coefficients
    make compositions highly unstable.
  </p>

  <p>
    Thus optimised schemes seek:
  </p>

  <ul>
    <li>small negative components,</li>
    <li>bounded coefficient magnitudes,</li>
    <li>sometimes complex coefficients with positive real part only.</li>
  </ul>

  <hr/>

  <!-- 4.3.7 -->
  <h3 id="sec-4-3-7">4.3.7 Structure-Adaptive Optimisation</h3>

  <p>
    Special splittings exploit system-specific structure:
  </p>

  <ul>
    <li>magnetic fields: Boris–like structure,</li>
    <li>semiclassical Schrödinger: minimise commutators with small parameters,</li>
    <li>stiff slow-fast systems: minimise coupling between scales.</li>
  </ul>

  <p>
    In these cases “optimal” means minimising error relative to a
    <em>problem-specific asymptotic regime</em>.
  </p>

  <hr/>

  <!-- 4.3.8 -->
  <h3 id="sec-4-3-8">4.3.8 Interactive Demo: Optimised vs Unoptimised 4th Order</h3>

  <p>
    Below is a visual comparison of:
  </p>

  <ul>
    <li>Yoshida 4th order (unoptimised),</li>
    <li>Optimised 4th order (Blanes–Casas).</li>
  </ul>

  <p>
    We display energy error for the harmonic oscillator.
  </p>

  <figure id="fig-4-5" style="text-align:center;">
    <canvas id="optSplitDemo" width="600" height="280"
            style="border:1px solid #ccc;"></canvas>
    <figcaption><strong>Figure 4.5</strong> – Optimised coefficients greatly reduce energy error.</figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("optSplitDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep=0.12;

    function fA([q,p]){ return [p, 0]; }
    function fB([q,p]){ return [0, -q]; }

    function flowA([q,p],c){ return [q + c*hstep*p, p]; }
    function flowB([q,p],c){ return [q, p - c*hstep*q]; }

    // Yoshida coefficients (unoptimised)
    const g = 1/(2-2**(1/3)), d = -2**(1/3)/(2-2**(1/3));

    function Yoshida(z){
      let z1=flowA(z,g);   z1=flowB(z1,g);
      let z2=flowA(z1,d);  z2=flowB(z2,d);
      let z3=flowA(z2,g);  z3=flowB(z3,g);
      return z3;
    }

    // Simplified "optimised" surrogate
    const ao1=0.5153528374, ao2=-0.08578201941;
    const bo1=0.4415830236, bo2=0.1184634424;

    function Opt(z){
      let z1=flowA(z,ao1); z1=flowB(z1,bo1);
      let z2=flowA(z1,ao2); z2=flowB(z2,bo2);
      let z3=flowA(z2,ao2); z3=flowB(z3,bo1);
      let z4=flowA(z3,ao1);
      return z4;
    }

    let zU=[1,0], zO=[1,0];
    let t=0;
    function H(z){ return 0.5*(z[0]*z[0]+z[1]*z[1]); }

    function animate(){
      t+=hstep;
      zU=Yoshida(zU);
      zO=Opt(zO);

      const x=t;
      const yU = h - 40*(H(zU)-0.5);
      const yO = h*0.5 - 40*(H(zO)-0.5);

      ctx.fillStyle="#c33"; ctx.fillRect(x,yU,2,2);
      ctx.fillStyle="#0a0"; ctx.fillRect(x,yO,2,2);

      if(x<w) requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 4.3.9 -->
  <h3 id="sec-4-3-9">4.3.9 Summary</h3>

  <ul>
    <li>Optimised splitting methods minimise dominant commutator errors.</li>
    <li>They dramatically outperform naïve compositions at equal computational cost.</li>
    <li>Real-coefficient optimisation is constrained by the forward-time barrier.</li>
    <li>Complex coefficients are viable for PDE and quantum flows.</li>
    <li>Structure-adapted optimisation is essential for stiff, oscillatory, or multiscale systems.</li>
  </ul>

  <hr/>

  <!-- 4.3.10 -->
  <h3 id="sec-4-3-10">4.3.10 References for Section 4.3</h3>

  <ol>
    <li><strong>[BC26]</strong> Blanes & Casas. <em>Concise Introduction to GNI</em>, 2nd ed.</li>
    <li><strong>[Blanes–Casas–Murua 2002]</strong> “Optimized symplectic integrators.”</li>
    <li><strong>[HLW06]</strong> Hairer–Lubich–Wanner. <em>Geometric Numerical Integration</em>.</li>
    <li><strong>[Kahan–Li 1997]</strong> “Composition methods for dynamical systems.”</li>
    <li><strong>[Suzuki 1990]</strong> “Fractal decomposition of exponential operators.”</li>
    <li><strong>[Bader–Blanes–Casas 2014]</strong> “Optimized splitting methods for semi-linear PDEs.”</li>
  </ol>

</section>

<section id="sec-4-4">
  <h2>4.4 Splitting Methods for Time-Dependent and Non-Autonomous Systems</h2>

  <p>
    In many applications — quantum control, laser-driven Schrödinger systems,
    NMR, accelerator physics, molecular dynamics with thermostats, celestial
    mechanics with perturbations, and time-dependent PDEs — 
    the governing equation is <em>non-autonomous</em>:
  </p>

  <p class="math">
    \[
      \dot{u}(t) = \big(A(t) + B(t)\big)\,u(t),\qquad u(0)=u_0.
    \]
  </p>

  <p>
    The exact solution involves the <strong>time-ordered exponential</strong>:
  </p>

  <p class="math">
    \[
      u(t) = \mathcal{T}\exp\!\left(\int_0^t (A(\tau)+B(\tau))\,d\tau\right)u_0.
    \]
  </p>

  <p>
    Because <span class="math">\(A(t)\)</span> and <span class="math">\(B(t)\)</span> fail to commute at different times,
    standard autonomous splittings <em>do not apply directly</em>.
  </p>

  <p>
    This section establishes the modern theory of splitting for non-autonomous
    systems, combining:
  </p>

  <ul>
    <li>Magnus expansions,</li>
    <li>time-dependent symmetric splittings,</li>
    <li>commutator-free Magnus integrators (CFMIs),</li>
    <li>Magnus–splitting hybrids,</li>
    <li>structure-preserving non-autonomous symplectic integrators.</li>
  </ul>

  <hr/>

  <!-- 4.4.1 -->
  <h3 id="sec-4-4-1">4.4.1 The Time-Ordered Exponential and Magnus Expansion</h3>

  <p>
    The time-ordered exponential can be rewritten using the
    <strong>Magnus expansion</strong>:
  </p>

  <p class="math">
    \[
    u(t) = \exp\big(\Omega(t)\big)\,u(0),
    \]
  </p>

  <p>
    where:
  </p>

  <p class="math">
    \[
      \Omega(t)
      = \int_0^t A(\tau)\,d\tau
      + \tfrac{1}{2}\!\int_0^t\!\!\int_0^{\tau_1}[A(\tau_1),A(\tau_2)]\,d\tau_2\,d\tau_1
      + \cdots.
    \]
  </p>

  <p>
    This provides a <em>universal autonomous lifting</em> of non-autonomous systems:
    a time-dependent problem is equivalent to an autonomous flow generated by a
    (possibly infinite) Lie series.
  </p>

  <p>
    In practice, truncations provide high-order approximations preserving
    unitarity or symplecticity exactly.
  </p>

  <hr/>

  <!-- 4.4.2 -->
  <h3 id="sec-4-4-2">4.4.2 The Challenge of Non-Autonomous Splitting</h3>

  <p>
    For autonomous systems:
  </p>

  <p class="math">
    \[
    e^{h(A+B)} \approx e^{hA} e^{hB}.
    \]
  </p>

  <p>
    For non-autonomous systems:
  </p>

  <p class="math">
    \[
    e^{\int A(t)\,dt} e^{\int B(t)\,dt} \neq e^{\int (A+B)(t)\,dt}.
    \]
  </p>

  <p>
    Commutators like <span class="math">[A(t_1),A(t_2)]</span> and <span class="math">[A(t),B(s)]</span> prevent naive splitting.
  </p>

  <p>
    Modern solutions involve:
  </p>

  <ul>
    <li>evaluating subflows at quadrature nodes,</li>
    <li>embedding time as an extra canonical coordinate,</li>
    <li>using Magnus truncations inside splitting schemes,</li>
    <li>commutator-free exponential integrators.</li>
  </ul>

  <hr/>

  <!-- 4.4.3 -->
  <h3 id="sec-4-4-3">4.4.3 Symmetric Non-Autonomous Strang Splitting</h3>

  <p>
    Consider:
  </p>

  <p class="math">
    \[
    \dot{u} = A(t)u + B(t)u.
    \]
  </p>

  <p>
    A robust second-order method evaluates operators at midpoints:
  </p>

  <p class="math">
    \[
      \Phi_h^{(2)}
      = \exp\!\big(\tfrac{h}{2}A(t+\tfrac{h}{2})\big)
        \exp\!\big(h B(t+\tfrac{h}{2})\big)
        \exp\!\big(\tfrac{h}{2}A(t+\tfrac{h}{2})\big).
    \]
  </p>

  <p>
    This coincides with a truncated Magnus expansion and produces a
    <strong>time-reversible</strong> method for symmetric systems.
  </p>

  <hr/>

  <!-- 4.4.4 -->
  <h3 id="sec-4-4-4">4.4.4 Commutator-Free Magnus Integrators (CFMIs)</h3>

  <p>
    Standard Magnus methods require evaluating commutators.  
    <strong>CFMIs</strong> avoid this by expressing solutions as products of exponentials:
  </p>

  <p class="math">
    \[
      \Phi_h = \exp\!\big(a_1 h\, A(t_1)\big)\,
               \exp\!\big(a_2 h\, A(t_2)\big)\cdots
    \]
  </p>

  <p>
    The idea is to choose quadrature nodes \(t_i\) and coefficients \(a_i\) so
    that the method matches the Magnus expansion up to order \(p\) without computing commutators.
  </p>

  <p>
    These methods are central in quantum computing, laser physics, and time-dependent PDEs.
  </p>

  <hr/>

  <!-- 4.4.5 -->
  <h3 id="sec-4-4-5">4.4.5 Magnus–Splitting Hybrid Methods</h3>

  <p>
    For systems decomposing as:
  </p>

  <p class="math">
    \[
      \dot{u} = A(t)u + B(t)u,
    \]
  </p>

  <p>
    where each subflow is easily computable,
    <strong>hybrid methods</strong> combine Magnus approximations for time dependence
    with splitting for operator structure.
  </p>

  <p>
    Example (4th order):
  </p>

  <p class="math">
    \[
      \Phi_h^{(4)}
      = \exp\!\left( a_1 h A(t_1) \right)
        \exp\!\left( b_1 h B(t_1) \right)
        \exp\!\left( a_2 h A(t_2) \right)
        \exp\!\left( b_1 h B(t_1) \right)
        \exp\!\left( a_1 h A(t_1) \right),
    \]
  </p>

  <p>
    where the nodes <span class="math">\(t_1,t_2\)</span> approximate the Gauss–Legendre nodes.
  </p>

  <p>
    These methods:
  </p>

  <ul>
    <li>preserve geometric structure,</li>
    <li>handle non-autonomous Hamiltonians,</li>
    <li>are highly accurate for oscillatory systems,</li>
    <li>avoid commutators.</li>
  </ul>

  <hr/>

  <!-- 4.4.6 -->
  <h3 id="sec-4-4-6">4.4.6 Embedding Time as a Canonical Coordinate</h3>

  <p>
    A beautiful geometric trick introduces an extended phase-space:
  </p>

  <p class="math">
    \[
      (q,p,t,p_t),
    \]
  </p>

  <p>
    with extended Hamiltonian:
  </p>

  <p class="math">
    \[
      K(q,p,t,p_t) = H(q,p,t) + p_t.
    \]
  </p>

  <p>
    The resulting system is <em>autonomous</em>:
  </p>

  <p class="math">
    \[
      \dot{t} = 1,\qquad
      \dot{p_t} = -\frac{\partial H}{\partial t},\qquad
      \dot{q},\dot{p}\text{ as usual}.
    \]
  </p>

  <p>
    Any autonomous splitting method — symplectic, symmetric, or optimised —
    now applies.
  </p>

  <hr/>

  <!-- 4.4.7 -->
  <h3 id="sec-4-4-7">4.4.7 Application: Quantum Control / Quantum Computing</h3>

  <p>
    For the Schrödinger equation with time-dependent Hamiltonian:
  </p>

  <p class="math">
    \[
      i\frac{d\psi}{dt} = H(t)\psi,
    \]
  </p>

  <p>
    splitting + Magnus is the dominant method for:
  </p>

  <ul>
    <li>quantum control sequences,</li>
    <li>laser–matter interaction,</li>
    <li>dynamical decoupling in qubits,</li>
    <li>time-dependent gate synthesis.</li>
  </ul>

  <p>
    CFMIs give unitarity exactly, with no commutator cost.
  </p>

  <hr/>

  <!-- 4.4.8 -->
  <h3 id="sec-4-4-8">4.4.8 Application: Driven Hamiltonian Systems</h3>

  <p>
    Celestial mechanics and plasma physics contain Hamiltonians of type:
  </p>

  <p class="math">
    \[
      H(q,p,t) = T(p) + V(q) + \epsilon\,W(q,t),
    \]
  </p>

  <p>
    where <span class="math">\(W\)</span> is a periodic or quasiperiodic driving term.
    Magnus–splitting hybrids offer:
  </p>

  <ul>
    <li>excellent phase accuracy,</li>
    <li>adiabatic invariance preservation,</li>
    <li>exact symplecticity,</li>
    <li>long-time energy stability.</li>
  </ul>

  <hr/>

  <!-- 4.4.9 -->
  <h3 id="sec-4-4-9">4.4.9 Interactive Demo: Non-Autonomous Splitting for a Driven Oscillator</h3>

  <p>
    We solve:
  </p>

  <p class="math">
    \[
      \ddot{q} + q = 0.1\sin(3 t).
    \]
  </p>

  <p>
    In first-order form:
  </p>

  <p class="math">
    \[
      \dot{q}=p,\qquad
      \dot{p}=-q + 0.1\sin(3t).
    \]
  </p>

  <figure id="fig-4-7" style="text-align:center;">
    <canvas id="drivenOscillator" width="600" height="280"
            style="border:1px solid #ccc;"></canvas>
    <figcaption><strong>Figure 4.7</strong> – Non-autonomous Strang vs Euler.</figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("drivenOscillator");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep = 0.05;

    function A([q,p], t){
      return [p, 0];
    }
    function B([q,p], t){
      return [0, -q + 0.1*Math.sin(3*t)];
    }

    function flowA(z, t, c){
      return [z[0] + c*hstep*z[1], z[1]];
    }
    function flowB(z, t, c){
      return [z[0], z[1] + c*hstep*(-z[0] + 0.1*Math.sin(3*t))];
    }

    function Strang(z, t){
      let tm = t + hstep/2;
      let z1 = flowA(z, tm, 0.5);
      let z2 = flowB(z1, tm, 1.0);
      let z3 = flowA(z2, tm, 0.5);
      return z3;
    }

    function Euler(z, t){
      const fA=A(z,t), fB=B(z,t);
      return [z[0] + hstep*(fA[0]+fB[0]),
              z[1] + hstep*(fA[1]+fB[1])];
    }

    let zS=[1,0], zE=[1,0];
    let t=0;

    function animate(){
      t+=hstep;
      zS=Strang(zS,t);
      zE=Euler(zE,t);

      const x=t;
      const yS = h*0.3 - 40*zS[0];
      const yE = h*0.7 - 40*zE[0];

      ctx.fillStyle="#00A"; ctx.fillRect(x,yS,2,2);
      ctx.fillStyle="#A00"; ctx.fillRect(x,yE,2,2);

      if(x<w) requestAnimationFrame(animate);
    }

    ctx.clearRect(0,0,w,h);
    animate();
  })();
  </script>

  <hr/>

  <!-- 4.4.10 -->
  <h3 id="sec-4-4-10">4.4.10 Summary of State-of-the-Art</h3>

  <ul>
    <li>Non-autonomous systems require time-ordering; Magnus gives the foundation.</li>
    <li>Commutator-free Magnus integrators avoid costly commutators.</li>
    <li>Magnus–splitting hybrids combine geometric preservation with time dependence.</li>
    <li>Extended-phase-space embedding gives fully symplectic non-autonomous integrators.</li>
    <li>Applications include quantum control, Hamiltonian PDEs, semiclassical dynamics.</li>
    <li>Modern methods exploit optimised quadrature nodes and coefficient solving.</li>
  </ul>

  <hr/>

  <!-- 4.4.11 -->
  <h3 id="sec-4-4-11">4.4.11 References for Section 4.4</h3>

  <ol>
    <li>Blanes & Casas (2026). <em>Concise Introduction to GNI</em>.</li>
    <li>Blanes, Casas, Oteo, Ros (2009). “The Magnus expansion and its applications”.</li>
    <li>Iserles et al. (2000–2023). Multiple works on Magnus, commutator-free integrators.</li>
    <li>Hairer–Lubich–Wanner (2006). <em>Geometric Numerical Integration</em>.</li>
    <li>Alvermann–Fehske (2011). “High-order commutator-free Magnus integrators”.</li>
    <li>Casas–Murua–Nadinic (2016). “Efficient high-order splitting–Magnus schemes”.</li>
  </ol>

</section>

<section id="sec-4-5">
  <h2>4.5 High-Order Composition & Optimised Non-Autonomous Schemes</h2>

  <p>
    After establishing splitting methods (Sections 4.1–4.4), we now move to the frontier:
    designing <strong>high-order, low-error, structure-preserving integrators</strong> for
    <em>non-autonomous</em> systems.
  </p>

  <p>
    These schemes combine:
  </p>

  <ul>
    <li>Lie–Trotter / Strang splitting,</li>
    <li>Magnus expansions,</li>
    <li>commutator-free exponential integrators (CFMIs),</li>
    <li>Gauss–Legendre quadrature,</li>
    <li>high-order symmetric compositions,</li>
    <li>complex time coefficients,</li>
    <li>adaptive or problem-aware quadrature nodes.</li>
  </ul>

  <p>
    Their purpose: achieve high accuracy at minimal computational cost while preserving
    geometric structure (symplecticity, reversibility, unitarity, invariants).
  </p>

  <hr/>

  <!-- 4.5.1 -->
  <h3 id="sec-4-5-1">4.5.1 Non-Autonomous BCH and Generalised Order Conditions</h3>

  <p>
    In the non-autonomous setting, the Baker–Campbell–Hausdorff (BCH) expansion acquires
    <em>time-dependent commutators</em>.
    For operators <span class="math">A(t)</span>, <span class="math">B(t)</span>:
  </p>

  <p class="math">
    \[
      e^{h A(t_1)} e^{h B(t_2)}
      = \exp\!\Big( h(A(t_1)+B(t_2))
      + \tfrac{h^2}{2} [A(t_1),B(t_2)]
      + \cdots \Big).
    \]
  </p>

  <p>
    High-order accuracy requires matching not only the autonomous BCH conditions but the
    <strong>generalised non-autonomous Magnus expansion</strong>.
  </p>

  <p>
    This leads to <strong>order conditions expressed in terms of time-integrated commutators</strong>,
    e.g.:
  </p>

  <p class="math">
    \[
    \int_0^h \!\! \int_0^{\tau_1} [A(\tau_1), A(\tau_2)] d\tau_2 d\tau_1.
    \]
  </p>

  <p>
    Direct enforcement is intractable → hence the need for:
  </p>

  <ul>
    <li>Magnus truncations,</li>
    <li>commutator-free quadrature-based approximations,</li>
    <li>symmetric composition to cancel odd Magnus terms.</li>
  </ul>

  <hr/>

  <!-- 4.5.2 -->
  <h3 id="sec-4-5-2">4.5.2 Commutator-Free Quadrature Integrators (CFQI)</h3>

  <p>
    CFQI methods approximate the Magnus operator <span class="math">\(\Omega(h)\)</span> via a product of exponentials:
  </p>

  <p class="math">
    \[
      \Phi_h
      = \exp\!\left( h \sum_j a_{1j} A(t_j) \right)
        \exp\!\left( h \sum_j a_{2j} A(t_j) \right)
        \cdots
    \]
  </p>

  <p>
    with quadrature nodes <span class="math">t_j</span> chosen by Gauss–Legendre, Gauss–Lobatto,
    or optimised nodes.
  </p>

  <p>
    The advantages:
  </p>

  <ul>
    <li><strong>No commutators</strong> appear explicitly.</li>
    <li>Exponentials may be computed by FFTs (PDEs) or small matrix exponentials (quantum mechanics).</li>
    <li>Preserves unitarity/symplecticity exactly.</li>
    <li>High order (~8 or more) achievable efficiently.</li>
  </ul>

  <hr/>

  <!-- 4.5.3 -->
  <h3 id="sec-4-5-3">4.5.3 Gauss–Legendre Magnus Methods (GL-Magnus)</h3>

  <p>
    A GL-Magnus integrator uses Gauss–Legendre quadrature to approximate:
  </p>

  <p class="math">
    \[
      \Omega(h) \approx h \sum_j w_j A(t_j)
      + \frac{h^3}{2} \sum_{i<j} w_i w_j (t_j - t_i) [A(t_j), A(t_i)]
      + \cdots.
    \]
  </p>

  <p>
    In practice:
  </p>

  <ul>
    <li>2-node GL gives order 4,</li>
    <li>3-node GL gives order 6,</li>
    <li>4-node GL gives order 8.</li>
  </ul>

  <p>
    GL-Magnus methods provide excellent error-per-cost behaviour for:
  </p>

  <ul>
    <li>time-dependent Schrödinger equations,</li>
    <li>spin systems,</li>
    <li>high-frequency driven Hamiltonians.</li>
  </ul>

  <hr/>

  <!-- 4.5.4 -->
  <h3 id="sec-4-5-4">4.5.4 High-Order Non-Autonomous Splitting via Symmetric Composition</h3>

  <p>
    A non-autonomous symmetric composition:
  </p>

  <p class="math">
    \[
      \Phi_h^{(p)}
      = \prod_{i=1}^s
        \exp\!\left( a_i h A(t+c_i h) \right)
        \exp\!\left( b_i h B(t+c_i h) \right)
    \]
  </p>

  <p>
    satisfies:
  </p>

  <ul>
    <li>time symmetry (<strong>reversibility</strong>),</li>
    <li>cancellation of all odd Magnus terms,</li>
    <li>potential to reach all even orders.</li>
  </ul>

  <p>
    Yoshida’s method generalises by choosing <span class="math">c_i</span>, <span class="math">a_i</span>, <span class="math">b_i</span> to satisfy non-autonomous order conditions.
  </p>

  <p>
    Modern optimised values (Blanes–Casas–Murua 2022+) minimise:
  </p>

  <ul>
    <li>commutator error norms,</li>
    <li>absolute coefficient sum,</li>
    <li>maximum real part of complex coefficients.</li>
  </ul>

  <hr/>

  <!-- 4.5.5 -->
  <h3 id="sec-4-5-5">4.5.5 Complex Time Steps and Forward-Time Constraints</h3>

  <p>
    For stiff PDEs, negative real coefficients make schemes unstable.  
    A breakthrough: use <strong>complex coefficients with positive real part</strong>.
  </p>

  <p>
    Let:
  </p>

  <p class="math">
    \[
      a_i = \alpha_i + i\beta_i,\qquad
      \operatorname{Re}(a_i) > 0.
    \]
  </p>

  <p>
    Then each flow remains stable for operators like:
  </p>

  <ul>
    <li>Laplacians,</li>
    <li>dispersive Schrödinger operators,</li>
    <li>Fokker-Planck / diffusion-drift operators.</li>
  </ul>

  <p>
    These schemes maintain symmetry and reach orders 6–12 with <em>no negative coefficients at all</em>.
  </p>

  <hr/>

  <!-- 4.5.6 -->
  <h3 id="sec-4-5-6">4.5.6 Adaptive Quadrature Magnus–Splitting Hybrids</h3>

  <p>
    In highly oscillatory regimes (e.g. laser pulses, RF fields), time dependence can vary rapidly.  
    Adaptive schemes choose:
  </p>

  <p class="math">
    \[
      \{t_j\},\quad \{w_j\}
    \]
  </p>

  <p>
    dynamically based on:
  </p>

  <ul>
    <li>local variation of A(t), B(t),</li>
    <li>smoothness indicators,</li>
    <li>energy drift,</li>
    <li>local commutator growth.</li>
  </ul>

  <p>
    These are the current state of the art for quantum control and Hamiltonian microlocal analysis.
  </p>

  <hr/>

  <!-- 4.5.7 -->
  <h3 id="sec-4-5-7">4.5.7 Splitting with Spectral Deferred Correction (SDC)</h3>

  <p>
    Another modern improvement: perform a low-order splitting step, then use:
  </p>

  <p class="math">
    \[
      u^{(k+1)} = u^{(k)} + \text{SDC correction}
    \]
  </p>

  <p>
    using a spectrally accurate quadrature rule.

    This yields <strong>arbitrarily high order</strong> while preserving the preferred splittings
    in each correction stage.
  </p>

  <p>
    This is powerful for:
  </p>

  <ul>
    <li>fluid simulations (Vlasov–Poisson, incompressible Euler),</li>
    <li>quantum chemistry,</li>
    <li>semiclassical transport equations.</li>
  </ul>

  <hr/>

  <!-- 4.5.8 -->
  <h3 id="sec-4-5-8">4.5.8 Error Budget and Practical Optimisation</h3>

  <p>
    The main error sources:
  </p>

  <ul>
    <li><strong>Magnus truncation error</strong>,</li>
    <li><strong>splitting BCH error</strong>,</li>
    <li><strong>quadrature error</strong>,</li>
    <li><strong>non-commutativity error</strong> between subflows.</li>
  </ul>

  <p>
    Modern methods choose coefficients to minimise a weighted combination:
  </p>

  <p class="math">
    \[
      \varepsilon
      = \|C_{p+1}\| + \lambda \|Q_{\text{err}}\| + \mu \sum_i |a_i|.
    \]
  </p>

  <p>
    This produces exceptionally efficient non-autonomous integrators for large-scale simulations.
  </p>

  <hr/>

  <!-- 4.5.9 -->
  <h3 id="sec-4-5-9">4.5.9 Summary of the State of Practice</h3>

  <ul>
    <li>High-order non-autonomous integrators combine Magnus expansions and splitting.</li>
    <li>CFQI and GL-Magnus are preferred for high accuracy with no commutators.</li>
    <li>Complex coefficients remove the stability barrier for stiff PDEs.</li>
    <li>Adaptive quadratures and SDC corrections achieve uniform accuracy across regimes.</li>
    <li>Modern optimised methods minimise commutator structure, not just order conditions.</li>
  </ul>

  <hr/>

  <!-- 4.5.10 -->
  <h3 id="sec-4-5-10">4.5.10 References for Section 4.5</h3>

  <ol>
    <li>Blanes & Casas (2026). <em>Concise Introduction to Geometric Numerical Integration</em>.</li>
    <li>Blanes, Casas, Murua (2009–2023). Optimised splitting & Magnus research series.</li>
    <li>Iserles, Kropielnicka, Singh (2018–2024). Commutator-free Magnus expansions.</li>
    <li>Hochbruck & Ostermann (2010–2022). Exponential integrators for PDEs.</li>
    <li>Alvermann & Fehske (2011). High-order CF Magnus integrators for quantum dynamics.</li>
    <li>Minchev & Wright (2005–2020). High-order Magnus + SDC hybrid methods.</li>
  </ol>

</section>

<section id="sec-5-1">
  <h2>5.1 Symplectic Runge–Kutta Methods</h2>

  <p>
    Symplectic Runge–Kutta (SRK) methods form the second main family of geometric
    integrators after splitting methods.  
    They act directly on the system of ODEs instead of decomposing the vector field.
    Their key virtues:
  </p>

  <ul>
    <li><strong>symplecticity</strong> for Hamiltonian systems,</li>
    <li><strong>high order</strong> (order up to 2s for s stages),</li>
    <li><strong>excellent long-time energy behaviour</strong>,</li>
    <li><strong>strong stability</strong> for moderately stiff systems,</li>
    <li>compatibility with <strong>implicit variational structure</strong>.</li>
  </ul>

  <p>
    The classical example: the <strong>Gauss–Legendre collocation integrators</strong>,
    which are implicit, A-stable, symmetric, symplectic, and of order
    <span class="math">2s</span> for <span class="math">s</span> stages.
  </p>

  <hr/>

  <!-- 5.1.1 -->
  <h3 id="sec-5-1-1">5.1.1 Hamiltonian ODEs and Symplecticity Conditions</h3>

  <p>
    Consider an autonomous Hamiltonian system on <span class="math">\(\mathbb{R}^{2m}\)</span>:
  </p>

  <p class="math">
    \[
      \dot{y} = J^{-1} \nabla H(y), \qquad
      J = \begin{pmatrix} 0&-I\\ I&0 \end{pmatrix}.
    \]
  </p>

  <p>
    A Runge–Kutta method with Butcher tableau:
  </p>

  <figure id="fig-5-1" style="text-align:center; margin:1em;">
    <table style="margin:0 auto; border-collapse:collapse; font-size: 14px;">
      <tr><td style="border:1px solid #ccc; padding:4px;">c_i</td>
          <td style="border:1px solid #ccc; padding:4px;" colspan="3">a_{ij}</td></tr>
      <tr><td style="border:1px solid #ccc; padding:4px;">&nbsp;</td>
          <td style="border:1px solid #ccc; padding:4px;">b_1</td>
          <td style="border:1px solid #ccc; padding:4px;">b_2</td>
          <td style="border:1px solid #ccc; padding:4px;">b_3</td></tr>
    </table>
    <figcaption><strong>Figure 5.1</strong> – Generic Runge–Kutta tableau.</figcaption>
  </figure>

  <p>
    is <strong>symplectic</strong> if and only if:
  </p>

  <p class="math">
    \[
      b_i a_{ij} + b_j a_{ji} - b_i b_j = 0
      \qquad \text{for all } i,j.
    \tag{5.1.1}
    \]
  </p>

  <p>
    This set of bilinear conditions characterises exactly those RK methods that preserve
    the canonical two-form <span class="math">\(\omega = dq \wedge dp\)</span>.
  </p>

  <hr/>

  <!-- 5.1.2 -->
  <h3 id="sec-5-1-2">5.1.2 Gauss–Legendre Collocation Methods</h3>

  <p>
    The Gauss–Legendre nodes <span class="math">c_i</span> in <span class="math">[0,1]</span> are roots of:
  </p>

  <p class="math">
    \[
      P_s(2c-1)=0,
    \]
  </p>

  <p>
    where <span class="math">P_s</span> is the Legendre polynomial of degree <span class="math">s</span>.
  </p>

  <p>
    The associated collocation method has:
  </p>

  <ul>
    <li>order <strong>2s</strong>,</li>
    <li>symmetry (time reversibility),</li>
    <li>A-stability (excellent stiffness damping),</li>
    <li><strong>symplecticity</strong> (via condition (5.1.1)).</li>
  </ul>

  <p>
    The Butcher coefficients are:
  </p>

  <p class="math">
    \[
      a_{ij} = \int_0^{c_i} \ell_j(\tau)\, d\tau,\qquad
      b_j = \int_0^1 \ell_j(\tau)\, d\tau,
    \]
  </p>

  <p>
    where <span class="math">\(\ell_j\)</span> are the Lagrange basis polynomials at the Gauss nodes.
  </p>

  <p>
    These are the highest-order (per stage) RK methods known, and are optimal for many Hamiltonian problems.
  </p>

  <hr/>

  <!-- 5.1.3 -->
  <h3 id="sec-5-1-3">5.1.3 Variational Derivation of Symplectic RK Methods</h3>

  <p>
    SRK methods arise naturally from a <strong>discrete variational principle</strong>.
    For a Lagrangian <span class="math">L(q,\dot{q})</span>:
  </p>

  <p class="math">
    \[
      S[q] = \int_0^h L(q,\dot q)\,dt.
    \]
  </p>

  <p>
    Approximate the trajectory inside each timestep by a polynomial interpolant
    defined at stage points:
  </p>

  <p class="math">
    \[
      q(t) \approx \sum_{j=1}^s q_j \ell_j(t/h).
    \]
  </p>

  <p>
    Then extremise the discrete action:
  </p>

  <p class="math">
    \[
      S_h(q_1,\dots,q_s) = h \sum_{i=1}^s b_i\, L(q_i, \dot{q}_i).
    \]
  </p>

  <p>
    The resulting discrete Euler–Lagrange equations produce exactly the SRK update.
  </p>

  <p>
    This variational origin guarantees <strong>symplecticity, momentum conservation,
    and excellent energy behaviour</strong>.
  </p>

  <hr/>

  <!-- 5.1.4 -->
  <h3 id="sec-5-1-4">5.1.4 Example: Gauss–2 (Order 4) Symplectic Integrator</h3>

  <p>
    For <span class="math">s=2</span>, the Gauss nodes are:
  </p>

  <p class="math">
    \[
      c_{1,2} = \tfrac{1}{2} \mp \tfrac{\sqrt{3}}{6}.
    \]
  </p>

  <p>
    The resulting method has:
  </p>

  <ul>
    <li>order 4,</li>
    <li>symplectic,</li>
    <li>symmetric,</li>
    <li>A-stable.</li>
  </ul>

  <p>
    This is one of the best all-purpose geometric ODE solvers available.
  </p>

  <hr/>

  <!-- 5.1.5 -->
  <h3 id="sec-5-1-5">5.1.5 Phase Accuracy and Long-Time Behaviour</h3>

  <p>
    A hallmark of Gauss collocation methods: their <strong>superior phase accuracy</strong>
    for Hamiltonian oscillatory systems.  
    For a harmonic oscillator:
  </p>

  <p class="math">
    \[
      y' = J^{-1} \nabla \tfrac{1}{2}(q^2+p^2),
    \]
  </p>

  <p>
    the Gauss-2 method yields:
  </p>

  <ul>
    <li>near-exact frequency,</li>
    <li>near-conservation of quadratic invariants,</li>
    <li>bounded energy error for exponentially long times.</li>
  </ul>

  <hr/>

  <!-- 5.1.6 -->
  <h3 id="sec-5-1-6">5.1.6 Interactive Illustration: Gauss-2 vs Explicit RK4 for Harmonic Oscillator</h3>

  <p>
    Comparison of energy drift:
  </p>

  <figure id="fig-5-2" style="text-align:center;">
    <canvas id="gaussDemo" width="600" height="280"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 5.2</strong> – Gauss-2 (blue) shows bounded energy oscillations;
      explicit RK4 (red) accumulates drift.
    </figcaption>
  </figure>

  <script>
  (function(){
    const canvas=document.getElementById("gaussDemo");
    if(!canvas) return;
    const ctx=canvas.getContext("2d");
    const w=canvas.width, h=canvas.height;

    const hstep = 0.1;

    // Harmonic oscillator flow
    function f([q,p]){ return [p, -q]; }

    // Explicit RK4
    function RK4(z){
      const k1=f(z);
      const k2=f([z[0]+0.5*hstep*k1[0], z[1]+0.5*hstep*k1[1]]);
      const k3=f([z[0]+0.5*hstep*k2[0], z[1]+0.5*hstep*k2[1]]);
      const k4=f([z[0]+hstep*k3[0], z[1]+hstep*k3[1]]);
      return [
        z[0] + hstep*(k1[0]+2*k2[0]+2*k3[0]+k4[0])/6,
        z[1] + hstep*(k1[1]+2*k2[1]+2*k3[1]+k4[1])/6
      ];
    }

    // Gauss-2 (implicit) approximated by fixed-point iteration
    function Gauss2(z){
      const c1=0.5 - Math.sqrt(3)/6;
      const c2=0.5 + Math.sqrt(3)/6;
      const b1=b2=0.5;

      // stage initial guesses
      let Z1=[z[0],z[1]];
      let Z2=[z[0],z[1]];
      const iters=3;
      for(let k=0;k<iters;k++){
        const f1=f(Z1), f2=f(Z2);
        Z1=[z[0] + hstep*(a11*f1[0] + a12*f2[0]),
            z[1] + hstep*(a11*f1[1] + a12*f2[1])];
        Z2=[z[0] + hstep*(a21*f1[0] + a22*f2[0]),
            z[1] + hstep*(a21*f1[1] + a22*f2[1])];
      }
      const f1=f(Z1), f2=f(Z2);
      return [
        z[0] + hstep*0.5*(f1[0]+f2[0]),
        z[1] + hstep*0.5*(f1[1]+f2[1])
      ];
    }

    // Gauss a-coefficients
    const a11=0.25, a12=0.25-Math.sqrt(3)/6;
    const a21=0.25+Math.sqrt(3)/6, a22=0.25;

    let zG=[1,0], z4=[1,0];
    let t=0;

    function H(z){ return 0.5*(z[0]*z[0]+z[1]*z[1]); }

    function animate(){
      t+=hstep;
      z4=RK4(z4);
      zG=Gauss2(zG);

      const x=t;
      const y4 = h*0.7 - 40*(H(z4)-0.5);
      const yG = h*0.3 - 40*(H(zG)-0.5);

      ctx.fillStyle="#c00"; ctx.fillRect(x,y4,2,2);
      ctx.fillStyle="#00c"; ctx.fillRect(x,yG,2,2);

      if(x<w) requestAnimationFrame(animate);
    }
    animate();
  })();
  </script>

  <hr/>

  <!-- 5.1.7 -->
  <h3 id="sec-5-1-7">5.1.7 SRK Methods for Stiff and Semi-Stiff Hamiltonians</h3>

  <p>
    Gauss methods are algebraically stable and A-stable.
    Thus they handle:
  </p>

  <ul>
    <li>weakly stiff Hamiltonians,</li>
    <li>high-frequency oscillations,</li>
    <li>semi-linear PDEs (after spatial discretisation),</li>
    <li>celestial mechanics near resonances.</li>
  </ul>

  <p>
    They are often the preferred integrator when:
  </p>

  <ul>
    <li>splitting is impossible or inefficient,</li>
    <li>the Hamiltonian is non-separable,</li>
    <li>coupling is fully implicit.</li>
  </ul>

  <hr/>

  <!-- 5.1.8 -->
  <h3 id="sec-5-1-8">5.1.8 Summary</h3>

  <ul>
    <li>SRK methods preserve symplecticity exactly.</li>
    <li>Gauss–Legendre collocation gives order <strong>2s</strong>.</li>
    <li>Variational derivation provides strong geometric invariance.</li>
    <li>SRK methods excel in long-time accuracy and stiff Hamiltonian problems.</li>
    <li>They complement splitting methods; neither replaces the other.</li>
  </ul>

  <hr/>

  <!-- 5.1.9 -->
  <h3 id="sec-5-1-9">5.1.9 References for Section 5.1</h3>

  <ol>
    <li>Hairer–Lubich–Wanner (2006). <em>Geometric Numerical Integration</em>.</li>
    <li>Blanes & Casas (2026). <em>Concise Introduction to GNI</em>.</li>
    <li>Butcher (2003). <em>Numerical Methods for ODEs</em>.</li>
    <li>Sanz-Serna (1988). “Runge–Kutta schemes for Hamiltonian systems”.</li>
    <li>Suris (1990–2020). Foundations of variational integrators.</li>
  </ol>

</section>

<section id="sec-5-2">
  <h2>5.2 Algebraic Order Conditions and B-Series for Symplectic RK Methods</h2>

  <p>
    Runge–Kutta (RK) methods admit an algebraic representation of their action
    on differential equations through <strong>B-series</strong>.  
    These are formal expansions indexed by rooted trees, which encode precisely how an RK method approximates the Taylor expansion of the exact flow.
  </p>

  <p>
    This section introduces the B-series formalism, describes order conditions,
    and explains why <strong>symplectic Runge–Kutta methods naturally restrict to <em>symplectic B-series</em></strong>, leading to:
  </p>

  <ul>
    <li>automatic conservation of quadratic invariants,</li>
    <li>the special structure that gives Gauss methods order \(2s\),</li>
    <li>deep links to the Butcher group and pre-Lie algebra of rooted trees.</li>
  </ul>

  <hr/>

  <!-- 5.2.1 -->
  <h3 id="sec-5-2-1">5.2.1 Rooted Trees and Elementary Differentials</h3>

  <p>
    For an autonomous ODE <span class="math">\(\dot{y}=f(y)\)</span>, 
    the Taylor expansion of the exact flow can be written using <strong>rooted trees</strong>.
  </p>

  <p class="math">
    \[
      y(h) = y(0) + h f
      + \frac{h^2}{2} f'f
      + \frac{h^3}{6} \big(f''(f,f) + f'(f'f)\big)
      + \cdots.
    \]
  </p>

  <p>
    Each term corresponds to a <em>rooted tree</em>.  
    For example:
  </p>

  <figure id="fig-5-3" style="text-align:center;">
    <svg width="400" height="160">
      <!-- tree tau1: single node -->
      <circle cx="60" cy="40" r="6" fill="#333"/>
      <text x="60" y="70" text-anchor="middle">τ₁: order 1</text>

      <!-- tree tau2: one branch -->
      <circle cx="170" cy="40" r="6" fill="#333"/>
      <circle cx="170" cy="90" r="6" fill="#333"/>
      <line x1="170" y1="46" x2="170" y2="84" stroke="#333"/>
      <text x="170" y="120" text-anchor="middle">τ₂: order 2</text>

      <!-- tree tau3: two subtrees -->
      <circle cx="300" cy="40" r="6" fill="#333"/>
      <circle cx="280" cy="90" r="6" fill="#333"/>
      <circle cx="320" cy="90" r="6" fill="#333"/>
      <line x1="300" y1="46" x2="280" y2="84" stroke="#333"/>
      <line x1="300" y1="46" x2="320" y2="84" stroke="#333"/>
      <text x="300" y="120" text-anchor="middle">τ₃: order 3</text>
    </svg>
    <figcaption><strong>Figure 5.3</strong> – Typical rooted trees.</figcaption>
  </figure>

  <p>
    For a tree <span class="math">\(\tau\)</span>, the associated <strong>elementary differential</strong> is denoted
  </p>

  <p class="math">
    \[
      F(\tau)(y) \in \mathbb{R}^m.
    \]
  </p>

  <p>
    The exact flow has a B-series:
  </p>

  <p class="math">
    \[
      \phi_h(y) = y + \sum_{\tau\in\mathcal{T}} 
        \frac{h^{|\tau|}}{\sigma(\tau)} F(\tau)(y).
    \tag{5.2.1}
    \]
  </p>

  <hr/>

  <!-- 5.2.2 -->
  <h3 id="sec-5-2-2">5.2.2 B-Series of a Runge–Kutta Method</h3>

  <p>
    Any (consistent) RK method produces a B-series:
  </p>

  <p class="math">
    \[
      \Psi_h(y) = y + \sum_{\tau\in\mathcal{T}}
        h^{|\tau|}\alpha(\tau)F(\tau)(y),
    \tag{5.2.2}
    \]
  </p>

  <p>
    where <span class="math">\(\alpha(\tau)\)</span> are algebraic expressions in <span class="math">a_{ij},b_i,c_i</span>.
  </p>

  <p>
    The method has order <span class="math">p</span> if and only if:
  </p>

  <p class="math">
    \[
      \alpha(\tau) = \frac{1}{\sigma(\tau)}
      \qquad \text{for all } |\tau|\le p.
    \tag{5.2.3}
    \]
  </p>

  <hr/>

  <!-- 5.2.3 -->
  <h3 id="sec-5-2-3">5.2.3 The Butcher Group</h3>

  <p>
    B-series form a group under composition: the <strong>Butcher group</strong> \(G_B\).
  </p>

  <p>
    Key facts:
  </p>

  <ul>
    <li><strong>Exact flows</strong> form a subgroup.</li>
    <li>The <strong>inverse B-series</strong> corresponds to running a method backward in time.</li>
    <li>Symmetric RK methods correspond to <strong>group involutions</strong>.</li>
    <li>Composition of integrators corresponds to multiplication in \(G_B\).</li>
  </ul>

  <p>
    Gauss collocation methods correspond to <em>the exponential of the truncated pre-Lie product</em> associated with the vector field.
  </p>

  <hr/>

  <!-- 5.2.4 -->
  <h3 id="sec-5-2-4">5.2.4 Symplectic RK Methods and Symplectic B-Series</h3>

  <p>
    For Hamiltonian ODEs <span class="math">\(\dot{y}=J^{-1}\nabla H(y)\)</span>,  
    the exact B-series satisfies:
  </p>

  <p class="math">
    \[
      \phi_h^*(\omega) = \omega,
    \]
  </p>

  <p>
    where <span class="math">\(\omega\)</span> is the symplectic form.
  </p>

  <p>
    An RK B-series is symplectic if and only if the Butcher coefficients satisfy:
  </p>

  <p class="math">
    \[
      b_i a_{ij} + b_j a_{ji} - b_i b_j = 0,
    \tag{5.1.1 revisited}
    \]
  </p>

  <p>
    These constraints <strong>force the B-series coefficients into the Hamiltonian sub-group 
    of the Butcher group</strong>.
  </p>

  <p>
    Consequences:
  </p>

  <ul>
    <li>quadratic invariants are preserved exactly,</li>
    <li>energy is nearly conserved over exponentially long times,</li>
    <li>Hamiltonian structure is respected at the series level.</li>
  </ul>

  <hr/>

  <!-- 5.2.5 -->
  <h3 id="sec-5-2-5">5.2.5 Why Gauss–Legendre RK Has Order 2s</h3>

  <p>
    A Gauss–Legendre collocation method with <span class="math">s</span> stages satisfies all order
    conditions up to order <strong>2s</strong>.  
    This follows because:
  </p>

  <ol>
    <li>
      Collocation enforces the differential equation exactly on the space of
      <em>interpolating polynomials</em> of degree <span class="math">2s-1</span>.
    </li>
    <li>
      Quadrature is exact for polynomials up to degree <span class="math">2s-1</span>.
    </li>
    <li>
      The trees correspond to compositions of derivatives of degree up to <span class="math">2s</span>.
    </li>
  </ol>

  <p>
    This gives the celebrated <strong>order-barrier optimality result</strong>:
  </p>

  <p class="math" style="font-size: 120%; font-weight: bold;">
    \[
      \text{For any s-stage RK method: } \quad p \le 2s.
    \]
  </p>

  <p>
    Gauss methods achieve this bound with equality.
  </p>

  <hr/>

  <!-- 5.2.6 -->
  <h3 id="sec-5-2-6">5.2.6 Interpretation via Pre-Lie Algebra of Rooted Trees</h3>

  <p>
    Rooted trees form a <strong>pre-Lie algebra</strong>:
  </p>

  <p class="math">
    \[
      \tau_1 \triangleright \tau_2 = \text{sum over graftings of the root of } \tau_1 \text{ onto each node of } \tau_2.
    \]
  </p>

  <p>
    The exact solution is the <em>Lie exponential</em> of the vector field in this algebra:
  </p>

  <p class="math">
    \[
      \phi_h = \exp_{\triangleright}(h f).
    \]
  </p>

  <p>
    Gauss methods are the <strong>truncated exponential</strong> of this pre-Lie product,
    preserving symplecticity by restriction to the Hamiltonian subalgebra.
  </p>

  <p>
    This provides the deepest algebraic explanation for their optimal order,
    symmetry, and geometric behaviour.
  </p>

  <hr/>

  <!-- 5.2.7 -->
  <h3 id="sec-5-2-7">5.2.7 Summary</h3>

  <ul>
    <li>B-series provide a universal algebraic description of RK methods.</li>
    <li>Order conditions correspond to matching exact B-series coefficients.</li>
    <li>Symplectic RK methods satisfy special bilinear constraints → Hamiltonian B-series subgroup.</li>
    <li>Gauss–Legendre collocation achieves the maximal possible order \(2s\).</li>
    <li>Underlying structure: pre-Lie algebra of rooted trees + Butcher group.</li>
  </ul>

  <hr/>

  <!-- 5.2.8 -->
  <h3 id="sec-5-2-8">5.2.8 References for Section 5.2</h3>

  <ol>
    <li>Hairer–Lubich–Wanner (2006). <em>Geometric Numerical Integration</em>.</li>
    <li>Butcher (1972–2003). <em>Tree theory and B-series</em>.</li>
    <li>Munthe-Kaas & Wright (2008–2020). <em>Pre-Lie algebra and Lie–Butcher series</em>.</li>
    <li>Chartier, Hairer, Vilmart (2010–2023). <em>Symplectic B-series integrators</em>.</li>
    <li>Iserles, Quispel, Nørsett (1999). “Lie-group methods and B-series”.</li>
  </ol>

</section>

<section id="sec-5-3">
  <h2>5.3 Symmetric, Symplectic, and Energy-Preserving RK Methods</h2>

  <p>
    Symmetry (time reversibility), symplecticity, and energy conservation are 
    three of the most important geometric properties for numerical integrators
    of Hamiltonian systems.  
    While no Runge–Kutta method can preserve <em>all</em> invariants exactly, 
    certain RK families preserve the <strong>symplectic form</strong>, 
    <strong>quadratic invariants</strong>, and/or 
    <strong>time-reversal symmetry</strong>, 
    which in turn guarantees excellent long-time behaviour.
  </p>

  <p>
    This section develops:
  </p>

  <ul>
    <li>time symmetry (self-adjoint RK integrators),</li>
    <li>symplectic and symmetric RK (SSRK) families,</li>
    <li>energy-preserving RK: discrete gradient & AVF methods,</li>
    <li>modified Hamiltonian structure from backward error analysis,</li>
    <li>connections between symmetry and even order.</li>
  </ul>

  <hr/>

  <!-- 5.3.1 -->
  <h3 id="sec-5-3-1">5.3.1 Time Symmetry (Self-Adjoint RK Methods)</h3>

  <p>
    A one-step method <span class="math">\(\Phi_h\)</span> is <strong>symmetric</strong> (or 
    <strong>time reversible</strong>) if:
  </p>

  <p class="math">
    \[
      \Phi_{-h} \circ \Phi_h = \mathrm{id}.
    \tag{5.3.1}
    \]
  </p>

  <p>
    For RK methods with tableau <span class="math">\((A,b,c)\)</span>, symmetry requires:
  </p>

  <p class="math">
    \[
      c_i = 1 - c_{s+1-i}, \qquad
      b_i = b_{s+1-i}, \qquad
      a_{ij} = b_{j} - a_{s+1-i,s+1-j}.
    \tag{5.3.2}
    \]
  </p>

  <p>
    Examples:
  </p>

  <ul>
    <li>All <strong>Gauss–Legendre</strong> collocation methods are symmetric.</li>
    <li>The implicit midpoint method is symmetric.</li>
    <li>Explicit RK methods cannot be symmetric, except trivial ones.</li>
  </ul>

  <p>
    Key fact:
  </p>

  <p class="math" style="font-weight:bold;">
    A symmetric method automatically has <em>even order</em>.
  </p>

  <hr/>

  <!-- 5.3.2 -->
  <h3 id="sec-5-3-2">5.3.2 Symmetric + Symplectic → Excellent Long-Time Behaviour</h3>

  <p>
    When an RK method is both <strong>symplectic</strong> and <strong>symmetric</strong>:
  </p>

  <ul>
    <li>it preserves phase volume,</li>
    <li>backward error analysis yields a <strong>real, time-symmetric modified Hamiltonian</strong>,</li>
    <li>the numerical trajectory stays on a smooth deformation of true energy level sets.</li>
  </ul>

  <p>
    This is why <strong>Gauss methods</strong> are the gold standard:
  </p>

  <p class="math">
    \[
      \text{Gauss–Legendre RK} 
      \quad \text{= symmetric + symplectic + order } 2s.
    \]
  </p>

  <p>
    This combination yields qualitatively correct behaviour over <em>astronomical</em> time spans.
  </p>

  <hr/>

  <!-- 5.3.3 -->
  <h3 id="sec-5-3-3">5.3.3 Backward Error Analysis: Modified Hamiltonians</h3>

  <p>
    A symplectic RK method applied to 
    <span class="math">\(\dot{y}=J^{-1}\nabla H(y)\)</span> 
    exactly solves a nearby Hamiltonian system:
  </p>

  <p class="math">
    \[
      \dot{y} = J^{-1}\nabla \tilde{H}(y),
    \]
  </p>

  <p>
    where the <strong>modified Hamiltonian</strong> has a formal expansion:
  </p>

  <p class="math">
    \[
      \tilde{H} = H 
      + h^p H_{p+1} 
      + h^{p+2} H_{p+3}
      + \cdots.
    \tag{5.3.3}
    \]
  </p>

  <p>
    Key consequences:
  </p>

  <ul>
    <li>Numerical energy error is nearly periodic (bounded) for exponentially long times.</li>
    <li>No drift accumulates: the numerical trajectory is near the exact level set of <span class="math">\(\tilde{H}\)</span>.</li>
    <li>Symmetry forces <span class="math">H_{p+2k+1}\equiv 0</span>, keeping the modified Hamiltonian <em>time-reversible</em>.</li>
  </ul>

  <figure id="fig-5-4" style="text-align:center;">
    <svg width="450" height="180">
      <!-- true level set -->
      <ellipse cx="120" cy="90" rx="70" ry="45" fill="none" stroke="#777" stroke-width="2"/>
      <text x="120" y="30" text-anchor="middle" font-size="12">H = constant</text>

      <!-- modified level set -->
      <ellipse cx="300" cy="90" rx="70" ry="45" fill="none" stroke="#0077cc" stroke-width="3"/>
      <text x="300" y="30" text-anchor="middle" font-size="12">ℍ̃ = constant</text>
    </svg>
    <figcaption><strong>Figure 5.4</strong> – Symplectic RK follows modified Hamiltonian level curves.</figcaption>
  </figure>

  <hr/>

  <!-- 5.3.4 -->
  <h3 id="sec-5-3-4">5.3.4 Energy-Preserving Runge–Kutta Methods</h3>

  <p>
    No ordinary RK method (explicit or implicit) can preserve a general Hamiltonian
    <strong>exactly</strong>.  
    But several specialized families achieve <strong>exact energy conservation</strong>
    by modifying the discretisation:
  </p>

  <h4>• The Average Vector Field (AVF) Method</h4>

  <p class="math">
    \[
      \frac{y_{n+1}-y_n}{h}
      = \int_0^1 f\big(\theta y_{n+1} + (1-\theta)y_n\big)\, d\theta.
    \]
  </p>

  <p>
    For Hamiltonian systems, AVF preserves energy exactly:
  </p>

  <p class="math">
    \[
      H(y_{n+1}) = H(y_n).
    \]
  </p>

  <h4>• Discrete Gradient Methods</h4>

  <p>
    Choose a discrete gradient 
    <span class="math">\(\bar{\nabla}H(y_{n+1},y_n)\)</span> satisfying:
  </p>

  <p class="math">
    \[
      H(y_{n+1}) - H(y_n)
      = \bar{\nabla}H(y_{n+1},y_n)^{\!\top} (y_{n+1}-y_n).
    \tag{5.3.4}
    \]
  </p>

  <p>
    Then define an update:
  </p>

  <p class="math">
    \[
      \frac{y_{n+1} - y_n}{h}
      = J^{-1} \bar{\nabla}H(y_{n+1},y_n).
    \]
  </p>

  <p>
    This preserves energy <em>exactly</em> for any Hamiltonian.
  </p>

  <h4>Energy-preserving ≠ Symplectic</h4>

  <p>
    There is a fundamental incompatibility:  
    <strong>an RK method cannot be both symplectic and energy-preserving unless the Hamiltonian is quadratic.</strong>
  </p>

  <p>
    Thus one chooses:
  </p>

  <ul>
    <li><strong>symplectic</strong> for general long-time Hamiltonian fidelity, or</li>
    <li><strong>energy-preserving</strong> when exact energy conservation is the priority.</li>
  </ul>

  <hr/>

  <!-- 5.3.5 -->
  <h3 id="sec-5-3-5">5.3.5 Comparison Chart: Symmetry, Symplecticity, Energy Preservation</h3>

  <figure id="tab-5-1" style="text-align:center;">
    <table style="margin:0 auto; border-collapse:collapse; width:90%; font-size:14px;">
      <tr style="background:#eef;">
        <th style="border:1px solid #ccc; padding:6px;">Method</th>
        <th style="border:1px solid #ccc; padding:6px;">Symplectic?</th>
        <th style="border:1px solid #ccc; padding:6px;">Symmetric?</th>
        <th style="border:1px solid #ccc; padding:6px;">Exact Energy?</th>
        <th style="border:1px solid #ccc; padding:6px;">Order</th>
      </tr>
      <tr>
        <td style="border:1px solid #ccc; padding:6px;">Gauss–s</td>
        <td style="border:1px solid #ccc; padding:6px;">Yes</td>
        <td style="border:1px solid #ccc; padding:6px;">Yes</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">2s</td>
      </tr>
      <tr>
        <td style="border:1px solid #ccc; padding:6px;">Radau IIA</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">2s-1</td>
      </tr>
      <tr>
        <td style="border:1px solid #ccc; padding:6px;">Implicit midpoint</td>
        <td style="border:1px solid #ccc; padding:6px;">Yes</td>
        <td style="border:1px solid #ccc; padding:6px;">Yes</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">2</td>
      </tr>
      <tr>
        <td style="border:1px solid #ccc; padding:6px;">AVF / DG Methods</td>
        <td style="border:1px solid #ccc; padding:6px;">No</td>
        <td style="border:1px solid #ccc; padding:6px;">Depends</td>
        <td style="border:1px solid #ccc; padding:6px;">Yes</td>
        <td style="border:1px solid #ccc; padding:6px;">2</td>
      </tr>
    </table>
    <figcaption><strong>Table 5.1</strong> – Comparison of geometric properties of key RK-type methods.</figcaption>
  </figure>

  <hr/>

  <!-- 5.3.6 -->
  <h3 id="sec-5-3-6">5.3.6 Summary</h3>

  <ul>
    <li><strong>Symmetry</strong> guarantees even order and prevents odd-order parasitic terms.</li>
    <li><strong>Symplecticity</strong> ensures faithful long-time Hamiltonian behaviour.</li>
    <li><strong>Energy-preserving discrete-gradient</strong> schemes preserve H exactly but generally lose symplecticity.</li>
    <li><strong>Gauss–Legendre RK</strong> sits at the intersection of symmetry + symplecticity + maximal order.</li>
  </ul>

  <hr/>

  <!-- 5.3.7 -->
  <h3 id="sec-5-3-7">5.3.7 References for Section 5.3</h3>

  <ol>
    <li>Hairer–Lubich–Wanner (2006). <em>Geometric Numerical Integration</em>.</li>
    <li>Blanes & Casas (2026). <em>Concise Introduction to GNI</em>.</li>
    <li>Sanz-Serna & Calvo (1994). <em>Numerical Hamiltonian Problems</em>.</li>
    <li>Quispel, Turner (2010–2021). Discrete gradient methods.</li>
    <li>Gonzalez (1996–2000). Average Vector Field method and variants.</li>
  </ol>

</section>

<section id="sec-5-4">
  <h2>5.4 Partitioned and Symplectic Partitioned Runge–Kutta Methods</h2>

  <p>
    Many important ODEs have a natural <strong>partitioned structure</strong>.
    Examples include:
  </p>

  <ul>
    <li>Hamiltonian systems with separable Hamiltonians: <span class="math">\(H(p,q)=T(p)+V(q)\)</span></li>
    <li>Mechanical systems: <span class="math">\(q' = M^{-1}p,\quad p' = -\nabla V(q)\)</span></li>
    <li>Charged particle dynamics in electromagnetic fields</li>
    <li>Canonical splitting for Lie–Poisson or multisymplectic PDE discretisations</li>
  </ul>

  <p>
    For such systems, <strong>Partitioned Runge–Kutta (PRK)</strong> methods assign 
    <em>different</em> RK tableaux to each component, while maintaining a coupled update.
  </p>

  <p>
    When the system is Hamiltonian, special algebraic conditions give rise to 
    <strong>Symplectic PRK (SPRK)</strong> methods.
  </p>

  <hr/>

  <!-- 5.4.1 -->
  <h3 id="sec-5-4-1">5.4.1 Partitioned ODEs and PRK Schemes</h3>

  <p>
    Consider a partitioned system:
  </p>

  <p class="math">
    \[
      \begin{aligned}
        q' &= f(q,p), \\
        p' &= g(q,p).
      \end{aligned}
    \tag{5.4.1}
    \]
  </p>

  <p>
    A <strong>partitioned Runge–Kutta method</strong> is defined by two tableaux:
  </p>

  <figure id="fig-5-5" style="text-align:center;">
    <table style="margin:auto; border-collapse:collapse;">
      <tr>
        <td style="padding-right:40px;">
          <table style="border-collapse:collapse;">
            <tr><td></td><td><em>A</em></td></tr>
            <tr><td><em>c</em></td><td></td></tr>
            <tr><td></td><td><em>b</em></td></tr>
          </table>
        </td>
        <td>
          <table style="border-collapse:collapse;">
            <tr><td></td><td><em>Ã</em></td></tr>
            <tr><td><em>c̃</em></td><td></td></tr>
            <tr><td></td><td><em>b̃</em></td></tr>
          </table>
        </td>
      </tr>
    </table>
    <figcaption><strong>Figure 5.5</strong> – A general Partitioned Runge–Kutta pair.</figcaption>
  </figure>

  <p>
    The stage values satisfy:
  </p>

  <p class="math">
    \[
      \begin{aligned}
        Q_i &= q_n + h\sum_{j=1}^s a_{ij}\,f(Q_j,P_j), \\
        P_i &= p_n + h\sum_{j=1}^s \tilde{a}_{ij}\,g(Q_j,P_j),
      \end{aligned}
    \tag{5.4.2}
    \]
  </p>

  <p>
    and the step update is:
  </p>

  <p class="math">
    \[
      \begin{aligned}
        q_{n+1} &= q_n + h\sum_{i=1}^s b_i\,f(Q_i,P_i), \\
        p_{n+1} &= p_n + h\sum_{i=1}^s \tilde{b}_i\,g(Q_i,P_i).
      \end{aligned}
    \tag{5.4.3}
    \]
  </p>

  <hr/>

  <!-- 5.4.2 -->
  <h3 id="sec-5-4-2">5.4.2 Hamiltonian Structure and SPRK Conditions</h3>

  <p>
    For a Hamiltonian system in canonical form:
  </p>

  <p class="math">
    \[
      q' = +\nabla_p H(p,q), \qquad
      p' = -\nabla_q H(p,q),
    \tag{5.4.4}
    \]
  </p>

  <p>
    the exact flow is symplectic:
  </p>

  <p class="math">
    \[
      \Phi_h^*(dq \wedge dp) = dq \wedge dp.
    \]
  </p>

  <p>
    A partitioned RK method is symplectic if and only if the coefficients satisfy:
  </p>

  <p class="math">
    \[
      b_i \tilde{a}_{ij} + \tilde{b}_j a_{ji} = b_i \tilde{b}_j,
      \qquad 1\le i,j\le s.
    \tag{5.4.5}
    \]
  </p>

  <p>
    This is the <strong>symplectic PRK condition</strong>.
  </p>

  <p>
    Special cases:
  </p>

  <ul>
    <li>
      If \(A=\tilde{A}\) and \(b=\tilde{b}\), we recover the classical RK symplecticity condition.
    </li>
    <li>
      If \(b=\tilde{b}\) and \(c=\tilde{c}\), then 
      <span class="math">\(\tilde{a}_{ij}=b_j-a_{ji}\)</span> ensures symplecticity.
    </li>
  </ul>

  <hr/>

  <!-- 5.4.3 -->
  <h3 id="sec-5-4-3">5.4.3 Separable Hamiltonians and the SPRK Midpoint Family</h3>

  <p>
    For separable systems:
  </p>

  <p class="math">
    \[
      H(p,q) = T(p) + V(q),
    \tag{5.4.6}
    \]
  </p>

  <p>
    the ODE is:
  </p>

  <p class="math">
    \[
      q' = +T_p(p), \qquad p' = -V_q(q).
    \tag{5.4.7}
    \]
  </p>

  <p>
    Since the two components depend only on one variable each, SPRK methods simplify dramatically.
  </p>

  <h4>• The Symplectic Euler A/B pair</h4>

  <p>
    Two 1-stage PRK methods:
  </p>

  <ul>
    <li>Euler A: implicit in \(p\)</li>
    <li>Euler B: implicit in \(q\)</li>
  </ul>

  Their compositions give:
  <ul>
    <li>the classical Stoermer–Verlet method</li>
    <li>kick–drift–kick and drift–kick–drift forms</li>
    <li>ubiquitous in molecular dynamics (velocity Verlet), astronomy (leapfrog), plasma physics, etc.</li>
  </ul>

  <p>
    Verlet is the most widely used SPRK of order 2.
  </p>

  <hr/>

  <!-- 5.4.4 -->
  <h3 id="sec-5-4-4">5.4.4 The Canonical Example: Stoermer–Verlet as a SPRK Method</h3>

  <p>
    Taking the tableaux:
  </p>

  <p class="math">
    \[
      A = \begin{pmatrix}0\end{pmatrix},\quad b=\begin{pmatrix}1\end{pmatrix},
      \qquad
      \tilde{A} = \begin{pmatrix}\frac12\end{pmatrix},\quad
      \tilde{b}=\begin{pmatrix}1\end{pmatrix},
    \tag{5.4.8}
    \]
  </p>

  <p>
    yields the scheme:
  </p>

  <p class="math">
    \[
      \begin{aligned}
        p_{n+\frac12} &= p_n - \tfrac{h}{2} \nabla V(q_n),\\
        q_{n+1} &= q_n + h\, \nabla_p T(p_{n+\frac12}),\\
        p_{n+1} &= p_{n+\frac12} - \tfrac{h}{2} \nabla V(q_{n+1}).
      \end{aligned}
    \tag{5.4.9}
    \]
  </p>

  <p>
    This is exactly the Stoermer–Verlet integrator, which is:
  </p>

  <ul>
    <li>second order,</li>
    <li>time symmetric,</li>
    <li>symplectic,</li>
    <li>computationally cheap (no solves for separable T),</li>
    <li>the world’s workhorse Hamiltonian integrator.</li>
  </ul>

  <hr/>

  <!-- 5.4.5 -->
  <h3 id="sec-5-4-5">5.4.5 Block Structure, Trees, and Order Conditions</h3>

  <p>
    PRK order conditions are described by <strong>two-coloured rooted trees</strong>:
  </p>

  <figure style="text-align:center;" id="fig-5-6">
    <svg width="420" height="150">
      <!-- simple two coloured tree -->
      <circle cx="210" cy="30" r="6" fill="#e00"/> <!-- red = p-tree -->
      <circle cx="180" cy="80" r="6" fill="#00e"/> <!-- blue = q-tree -->
      <circle cx="240" cy="80" r="6" fill="#00e"/>
      <line x1="210" y1="36" x2="180" y2="74" stroke="#333"/>
      <line x1="210" y1="36" x2="240" y2="74" stroke="#333"/>
      <text x="210" y="120" text-anchor="middle">Two-coloured rooted tree</text>
    </svg>
    <figcaption><strong>Figure 5.6</strong> – A typical order-3 PRK rooted tree.</figcaption>
  </figure>

  <p>
    Exactly as in the classical B-series case:
  </p>

  <p class="math">
    \[
      \Psi_h = y + \sum_{\tau\in \mathcal{T}_{2}} h^{|\tau|}\,\alpha(\tau)\,F(\tau),
    \tag{5.4.10}
    \]
  </p>

  <p>
    where <span class="math">\(\mathcal{T}_{2}\)</span> is the set of two-coloured rooted trees.
  </p>

  <p>
    Using coloured trees splits the order conditions into <strong>mixed</strong> and <strong>diagonal</strong> classes, allowing high-order symmetric & symplectic PRK methods to be constructed systematically.
  </p>

  <hr/>

  <!-- 5.4.6 -->
  <h3 id="sec-5-4-6">5.4.6 Higher-Order SPRK Methods</h3>

  <p>
    Examples include:
  </p>

  <ul>
    <li>
      <strong>Yoshida-type compositions</strong> of Verlet  
      → arbitrary even order
    </li>
    <li>
      <strong>SABA/SBAB families</strong> (Laskar–Robutel)  
      → highly optimised for celestial mechanics
    </li>
    <li>
      <strong>P-series</strong> and <strong>Q-series</strong> SPRK methods  
      → systematically derived from coloured-tree order conditions
    </li>
  </ul>

  <p>
    A typical high-order symmetric composition:
  </p>

  <p class="math">
    \[
      \Psi_h^{(4)} = \Phi_{\gamma_1 h}\circ
                     \Phi_{\gamma_2 h}\circ
                     \Phi_{\gamma_1 h},
    \tag{5.4.11}
    \]
  </p>

  <p>
    with 
    <span class="math">\(\gamma_1 = 1/(2-2^{1/3})\)</span>,
    <span class="math">\(\gamma_2 = -2^{1/3}\gamma_1\)</span>.
  </p>

  <p>
    Such compositions retain symplecticity and symmetry by construction.
  </p>

  <hr/>

  <!-- 5.4.7 -->
  <h3 id="sec-5-4-7">5.4.7 Summary</h3>

  <ul>
    <li>PRK methods apply different RK tableaux to different components.</li>
    <li>SPRK methods preserve the canonical symplectic form exactly.</li>
    <li>SPRK methods arise naturally for separable Hamiltonians.</li>
    <li>Verlet = SPRK of order 2, symmetric, symplectic, cheap → universal workhorse.</li>
    <li>Coloured-tree theory gives systematic construction of high-order SPRK schemes.</li>
    <li>Compositions of symplectic/symmetric PRK methods yield arbitrarily high order.</li>
  </ul>

  <hr/>

  <!-- 5.4.8 -->
  <h3 id="sec-5-4-8">5.4.8 References for Section 5.4</h3>

  <ol>
    <li>Hairer–Lubich–Wanner (2006). <em>Geometric Numerical Integration</em>.</li>
    <li>Blanes & Casas (2026). <em>Concise Introduction to GNI</em>.</li>
    <li>Sanz-Serna & Calvo (1994). <em>Numerical Hamiltonian Problems</em>.</li>
    <li>McLachlan & Quispel (2002–2023). <em>Survey of symplectic splitting & SPRK methods</em>.</li>
    <li>Laskar & Robutel (2001). <em>SABA/SBAB integrators</em>.</li>
  </ol>

</section>

<section id="sec-5-5">
  <h2>5.5 Exponential Runge–Kutta (ERK), Lawson, and Integrating Factor Methods</h2>

  <p>
    Many evolution equations have the <em>semilinear</em> structure:
  </p>

  <p class="math">
    \[
      y' = Ly + N(y), \qquad y(0)=y_0
    \tag{5.5.1}
    \]
  </p>

  <p>
    where:
  </p>

  <ul>
    <li><strong>L</strong> is a (possibly stiff) linear operator</li>
    <li><strong>N(y)</strong> is nonlinear but nonstiff</li>
  </ul>

  <p>
    Typical examples include:
  </p>

  <ul>
    <li>reaction–diffusion PDEs after spatial discretisation</li>
    <li>Schrödinger and Gross–Pitaevskii equations</li>
    <li>viscoelasticity and Maxwell–Bloch equations</li>
    <li>semidiscrete wave/Klein–Gordon systems</li>
  </ul>

  <p>
    In such cases, classical RK methods suffer order reduction and stability problems.
    <strong>Exponential Runge–Kutta (ERK)</strong> and 
    <strong>integrating factor / Lawson methods</strong> resolve this by 
    treating <em>the stiff linear part exactly</em>.
  </p>

  <hr/>

  <!-- 5.5.1 -->
  <h3 id="sec-5-5-1">5.5.1 The Integrating Factor Transformation</h3>

  <p>
    The exact flow of the linear part is:
  </p>

  <p class="math">
    \[
      \phi_L^h(y) = e^{hL}y.
    \]
  </p>

  <p>
    Introduce the change of variables:
  </p>

  <p class="math">
    \[
      v(t) = e^{-tL} y(t).
    \tag{5.5.2}
    \]
  </p>

  <p>
    Then:
  </p>

  <p class="math">
    \[
      v' = e^{-tL}N\!\big(e^{tL}v\big),
    \tag{5.5.3}
    \]
  </p>

  <p>
    which is <strong>nonstiff</strong> if <span class="math">N</span> is nonstiff.  
    Ordinary RK applied to <span class="math">v'(t)</span> gives the classical 
    <strong>Lawson method</strong>.
  </p>

  <p>
    This is the foundation of all exponential integrators.
  </p>

  <hr/>

  <!-- 5.5.2 -->
  <h3 id="sec-5-5-2">5.5.2 Lawson Methods (Explicit Exponential RK)</h3>

  <p>
    Apply an s-stage RK method to (5.5.3):
  </p>

  <p class="math">
    \[
      v_{n+1} = v_n 
      + h\sum_{i=1}^s b_i\,e^{-c_i h L}
        N\!\big(e^{c_i h L} V_i\big),
    \tag{5.5.4}
    \]
  </p>

  <p>
    with stages:
  </p>

  <p class="math">
    \[
      V_i = v_n 
        + h\sum_{j=1}^s a_{ij}\,e^{-c_j h L}
           N\!\big(e^{c_j hL} V_j\big).
    \tag{5.5.5}
    \]
  </p>

  <p>
    Return to <span class="math">y</span> via:
  </p>

  <p class="math">
    \[
      y_{n+1} = e^{hL} v_{n+1}.
    \tag{5.5.6}
    \]
  </p>

  <p>
    Advantages:
  </p>

  <ul>
    <li>Explicit internal stages (if underlying RK is explicit)</li>
    <li>Linear part handled exactly → much larger stable steps</li>
    <li>Ideal for semilinear PDEs with stiff L</li>
  </ul>

  <hr/>

  <!-- 5.5.3 -->
  <h3 id="sec-5-5-3">5.5.3 Exponential Runge–Kutta (ERK): ϕ-Functions</h3>

  <p>
    ERK methods express the solution using the variation-of-constants formula:
  </p>

  <p class="math">
    \[
      y(t+h)=e^{hL}y(t)
      +\int_0^h e^{(h-\tau)L} N(y(t+\tau))\,d\tau.
    \tag{5.5.7}
    \]
  </p>

  <p>
    This integral naturally leads to the <strong>phi functions</strong>:
  </p>

  <p class="math">
    \[
      \varphi_0(z)=e^z,\qquad
      \varphi_1(z)=\frac{e^z-1}{z},\qquad
      \varphi_2(z)=\frac{e^z - z - 1}{z^2}, \dots
    \tag{5.5.8}
    \]
  </p>

  <p>
    Higher-order ERK methods are linear combinations of 
    <span class="math">\(\varphi_k(hL)\)</span> acting on nonlinear terms.
  </p>

  <h4>• General s-stage ERK Method</h4>

  <p class="math">
    \[
      Y_i = e^{c_i h L} y_n
            + h\sum_{j=1}^s a_{ij}(hL)\,N(Y_j),
    \tag{5.5.9}
    \]
  </p>

  <p>
    and
  </p>

  <p class="math">
    \[
      y_{n+1} = e^{hL}y_n + 
        h\sum_{i=1}^s b_i(hL)\,N(Y_i),
    \tag{5.5.10}
    \]
  </p>

  <p>
    where <strong>the coefficients are matrix functions</strong>:
  </p>

  <p class="math">
    \[
      a_{ij}(hL) = \int_0^{c_i}e^{(c_i-\tau)hL}\ell_j(\tau)\,d\tau,
    \tag{5.5.11}
    \]
  </p>

  <p>
    and similarly for <span class="math">b_i(hL)</span>.
  </p>

  <hr/>

  <!-- 5.5.4 -->
  <h3 id="sec-5-5-4">5.5.4 Geometric Structure of Exponential Integrators</h3>

  <p>
    If the linear part <span class="math">L</span> generates a symmetry group of the system,  
    exponential integrators <strong>inherit invariances automatically</strong>:
  </p>

  <h4>• L skew-symmetric → Norm/energy preservation</h4>

  <p class="math">
    \[
      L^T = -L \;\Longrightarrow\; \|e^{hL}y\|=\|y\|.
    \]
  </p>

  <h4>• L Hamiltonian → Symplecticity of e<sup>hL</sup></h4>

  <p>
    If <span class="math">L</span> is a Hamiltonian matrix:
  </p>

  <p class="math">
    \[
      e^{hL} \in \mathrm{Sp}(2n).
    \tag{5.5.12}
    \]
  </p>

  <p>
    Then exponential integrators preserve linear symplectic structure automatically.
  </p>

  <h4>• L representing a Lie algebra action → ERK respects group symmetry</h4>

  <p>
    Example: rotation, Schrödinger flow, Maxwell–Bloch dynamics.
  </p>

  <hr/>

  <!-- 5.5.5 -->
  <h3 id="sec-5-5-5">5.5.5 Stability: Why ERK Beats Classical RK</h3>

  <figure id="fig-5-7" style="text-align:center;">
    <svg width="480" height="220">
      <!-- axes -->
      <line x1="40" y1="180" x2="430" y2="180" stroke="#444"/>
      <line x1="40" y1="180" x2="40" y2="40" stroke="#444"/>

      <!-- RK stability -->
      <path d="M 40 180 Q 150 120 230 100 T 430 80"
            stroke="#dd0000" fill="none" stroke-width="3"/>
      <text x="260" y="130" fill="#d00">Classical RK stability</text>

      <!-- exponential stability -->
      <path d="M 40 140 Q 180 80 430 60" 
            stroke="#0088cc" fill="none" stroke-width="3"/>
      <text x="250" y="90" fill="#08c">ERK stability (nearly optimal)</text>
    </svg>
    <figcaption><strong>Figure 5.7</strong> – ERK inherits stability from exact linear flow.</figcaption>
  </figure>

  <p>
    Because ERK treats the stiff part exactly, its stability region includes  
    the entire left half-plane for linear test problems  
    <span class="math">y' = \lambda y</span> with stiff <span class="math">\(\lambda\)</span>.  
    This eliminates order reduction for parabolic PDEs.
  </p>

  <hr/>

  <!-- 5.5.6 -->
  <h3 id="sec-5-5-6">5.5.6 Relation to Magnus and Splitting Methods</h3>

  <p>
    ERK is closely linked with:
  </p>

  <ul>
    <li><strong>Magnus integrators</strong> (matrix exponentials of nested commutators)</li>
    <li><strong>Lie–Trotter & Strang splitting</strong></li>
    <li><strong>Lawson–Magnus hybrids</strong></li>
    <li><strong>Exponential time differencing (ETD)</strong> methods</li>
  </ul>

  <p>
    For stiff linear operators, ERK methods are effectively splitting methods with exact L-flow and approximated nonlinear flow.
  </p>

  <hr/>

  <!-- 5.5.7 -->
  <h3 id="sec-5-5-7">5.5.7 Summary</h3>

  <ul>
    <li>Integrating factor <em>decouples</em> stiff linear and nonlinear dynamics.</li>
    <li>Lawson methods → explicit exponential RK via change of variables.</li>
    <li>ERK methods use <var>φ</var>-functions to obtain high-order integrators.</li>
    <li>They inherit geometric structure if <span class="math">L</span> generates symmetries.</li>
    <li>Stability is vastly superior for semilinear PDEs.</li>
  </ul>

  <hr/>

  <!-- 5.5.8 -->
  <h3 id="sec-5-5-8">5.5.8 References for Section 5.5</h3>

  <ol>
    <li>Hochbruck & Ostermann (2010), <em>Exponential Integrators</em>.</li>
    <li>Blanes & Casas (2026), <em>Concise Intro to GNI</em>.</li>
    <li>Lawson (1967), original integrating factor RK formulation.</li>
    <li>Cox & Matthews (2002), ETD–RK methods.</li>
    <li>Iserles (2008–2015), Lawson–Magnus & geometric exponential methods.</li>
  </ol>

</section>

<section id="sec-5-6">
  <h2>5.6 Magnus–Runge–Kutta, Commutator-Free Magnus Methods, and Lie–Algebraic Exponential Integrators</h2>

  <p>
    For <strong>non-autonomous</strong> linear systems
  </p>

  <p class="math">
    \[
      y'(t) = A(t)\, y(t),
    \tag{5.6.1}
    \]
  </p>

  <p>
    the exact solution is given by a time-ordered exponential:
  </p>

  <p class="math">
    \[
      y(t+h) = \mathcal{T} \exp\!\left(\int_t^{t+h}A(\tau)\,d\tau\right)y(t),
    \tag{5.6.2}
    \]
  </p>

  <p>
    which lies in the <em>Lie group</em> generated by the Lie algebra containing <span class="math">A(t)</span>.  
    This structure must be preserved for:
  </p>

  <ul>
    <li>quantum evolution (<code>U(t) ∈ U(n)</code>)</li>
    <li>rigid-body dynamics (<code>R(t) ∈ SO(3)</code>)</li>
    <li>adjoint equations (<code>M(t) ∈ Sp(2n)</code>)</li>
    <li>control systems on manifolds</li>
  </ul>

  <p>
    This section develops three families of integrators that preserve the Lie-group geometry:
  </p>

  <ol>
    <li><strong>Magnus integrators</strong> — exact exponential of a series of commutators.</li>
    <li><strong>Commutator-free Magnus (CFM)</strong> methods — high-order but exponential-only.</li>
    <li><strong>Magnus–Runge–Kutta hybrids</strong> — nonlinear / semilinear geometric integrators.</li>
  </ol>

  <hr/>

  <!-- 5.6.1 -->
  <h3 id="sec-5-6-1">5.6.1 The Magnus Expansion</h3>

  <p>
    Magnus (1954) showed that the solution of (5.6.1) can be written exactly as:
  </p>

  <p class="math">
    \[
      y(t+h) = \exp\!\left(\Omega(t,h)\right)y(t),
    \tag{5.6.3}
    \]
  </p>

  <p>
    where
  </p>

  <p class="math">
    \[
      \Omega(t,h)=\int_t^{t+h}A(\tau)d\tau
       - \frac12 \int_t^{t+h}\!\!\int_t^{\tau_1}
          [A(\tau_1),A(\tau_2)]\,d\tau_2 d\tau_1 
       + \cdots.
    \tag{5.6.4}
    \]
  </p>

  <p>
    Properties:
  </p>

  <ul>
    <li><span class="math">\(\Omega(t,h)\)</span> lies in the same <strong>Lie algebra</strong>.</li>
    <li><span class="math">\(\exp(\Omega)\)</span> lies in the corresponding <strong>Lie group</strong>.</li>
    <li>Preserves geometric invariants: unitarity, symplecticity, orthogonality, etc.</li>
  </ul>

  <h4>Practical truncation:</h4>

  <p>
    The 2nd-order Magnus method:
  </p>

  <p class="math">
    \[
      \Omega^{[2]} = h\, A(t+\tfrac{h}{2}).
    \tag{5.6.5}
    \]
  </p>

  <p>
    The 4th-order Magnus method:
  </p>

  <p class="math">
    \[
      \Omega^{[4]} 
      = h\Big(\tfrac12(A_1+A_2)
      - \tfrac{\sqrt{3}}{12}h [A_2, A_1]\Big),
    \tag{5.6.6}
    \]
  </p>

  <p>
    where <span class="math">A_1, A_2</span> are samples at Gauss–Legendre nodes.
  </p>

  <hr/>

  <!-- 5.6.2 -->
  <h3 id="sec-5-6-2">5.6.2 Commutator-Free Magnus (CFM) Methods</h3>

  <p>
    Standard Magnus integrators require evaluating matrix commutators  
    <span class="math">[A_i, A_j]</span> and nested commutators, which can be expensive.
  </p>

  <p>
    <strong>CFM integrators</strong> avoid commutators entirely:  
    instead of <span class="math">\(\Omega\)</span> being a sum of Lie brackets, we use sums of exponentials:
  </p>

  <p class="math">
    \[
      y_{n+1}
      = 
      \exp\!\left(h\sum_k \alpha_k A(t_n + c_k h)\right)
      y_n,
    \tag{5.6.7}
    \]
  </p>

  <p>
    with coefficients chosen to match the Magnus expansion up to order <span class="math">p</span>.
  </p>

  <p>
    Advantages:
  </p>

  <ul>
    <li>No commutators → much cheaper for large matrices.</li>
    <li>No loss of geometric structure.</li>
    <li>Ideal for quantum dynamics/Schrödinger equations.</li>
  </ul>

  <h4>Example: 4th-order CFM</h4>

  <p class="math">
    \[
      y_{n+1}
      = 
      \exp\!\big(h(\tfrac12 A_1 + \tfrac12 A_2)\big)\;
      y_n,
    \tag{5.6.8}
    \]
  </p>

  <p>
    with <span class="math">A_1, A_2</span> chosen at Gauss nodes.  
    No commutators appear, yet the method is 4th order.
  </p>

  <hr/>

  <!-- 5.6.3 -->
  <h3 id="sec-5-6-3">5.6.3 Magnus–Runge–Kutta Methods for Nonlinear Systems</h3>

  <p>
    For semilinear systems:
  </p>

  <p class="math">
    \[
      y' = A(t) y + N(y,t),
    \tag{5.6.9}
    \]
  </p>

  <p>
    one can combine a Magnus integrator for the linear part  
    with a Runge–Kutta method for the nonlinear part:
  </p>

  <p class="math">
    \[
      y_{n+1}
      = \exp\!\left(\Omega(t_n,h)\right)
        \left( 
          y_n + h\sum_{i=1}^s b_i\, \tilde{N}_i
        \right),
    \tag{5.6.10}
    \]
  </p>

  <p>
    where <span class="math">\(\tilde{N}_i\)</span> are nonlinear stages evaluated in a transformed frame:
  </p>

  <p class="math">
    \[
      \tilde{N}_i = 
      N\Big(
         \exp(\Omega_i)\big(y_n + \cdots\big),\,
         t_n + c_i h
      \Big).
    \tag{5.6.11}
    \]
  </p>

  <p>
    These hybrid methods:
  </p>

  <ul>
    <li>are exponential integrators on Lie groups,</li>
    <li>preserve the geometric structure of the linear flow exactly,</li>
    <li>handle non-autonomous nonlinearities via RK.</li>
  </ul>

  <hr/>

  <!-- 5.6.4 -->
  <h3 id="sec-5-6-4">5.6.4 High-Order Commutator-Free Magnus–RK Methods</h3>

  <p>
    Blanes, Casas, Iserles, and others developed high-order methods combining:
  </p>

  <ul>
    <li>the efficiency of CFM integrators,</li>
    <li>the flexibility of explicit/implicit RK,</li>
    <li>structure preservation on Lie groups.</li>
  </ul>

  <p>
    A typical 6th-order CFM–RK method uses:
  </p>

  <p class="math">
    \[
      y_{n+1}
      = 
      \exp\!\left(
        h(\alpha_1 A_1 + \alpha_2 A_2 + \alpha_3 A_3)
      \right)
      \Big(
        y_n + h\sum b_i N(Y_i)
      \Big).
    \tag{5.6.12}
    \]
  </p>

  <p>
    All coefficients arise from matching the Magnus series through order 6, 
    but <strong>no commutators are used</strong>.
  </p>

  <hr/>

  <!-- 5.6.5 -->
  <h3 id="sec-5-6-5">5.6.5 Preservation of Lie-Group Structure</h3>

  <p>
    If the exact flow satisfies:
  </p>

  <p class="math">
    \[
      y(t) \in G, \qquad G = \exp(\mathfrak{g}),
    \]
  </p>

  <p>
    then Magnus and CFM–RK methods ensure:
  </p>

  <p class="math">
    \[
      y_{n+1} = \exp(\xi_n) y_n \in G,
    \tag{5.6.13}
    \]
  </p>

  <p>
    because <span class="math">\(\xi_n \in \mathfrak{g}\)</span> for all steps.
  </p>

  <p>
    Thus:
  </p>

  <ul>
    <li>unitarity preserved for Schrödinger problem,</li>
    <li>orthogonality preserved in rigid-body rotation,</li>
    <li>symplecticity preserved for linear Hamiltonian systems.</li>
  </ul>

  <hr/>

  <!-- 5.6.6 -->
  <h3 id="sec-5-6-6">5.6.6 Summary</h3>

  <ul>
    <li>The Magnus expansion expresses the exact flow as <em>one exponential</em> in the Lie algebra.</li>
    <li>Truncations yield high-order geometric integrators.</li>
    <li>Commutator-free Magnus (CFM) methods remove commutators → highly efficient.</li>
    <li>Magnus–RK hybrids solve nonlinear/non-autonomous systems geometrically.</li>
    <li>All methods preserve Lie-group structure: U(n), SO(3), Sp(2n), SU(2), …</li>
  </ul>

  <hr/>

  <!-- 5.6.7 -->
  <h3 id="sec-5-6-7">5.6.7 References for Section 5.6</h3>

  <ol>
    <li>Blanes, Casas, Oteo, & Ros (2009), <em>The Magnus Expansion</em>.</li>
    <li>Iserles (2008–2022), <em>Lie-group Methods and Magnus Integrators</em>.</li>
    <li>Blanes & Casas (2026), <em>Concise Intro to GNI</em>.</li>
    <li>Hochbruck–Ostermann (2010), <em>Exponential Integrators: Review</em>.</li>
    <li>Alvermann & Fehske (2011), Commutator-free Magnus methods for large quantum systems.</li>
  </ol>

</section>

<section id="sec-6-0">

  <h2>6.0 Overview: Why Splitting & Composition Methods?</h2>

  <p>
    In the previous chapters we developed geometric structure, symplecticity,
    Lie–algebraic flows, exponential integrators, and stability theory. We now
    introduce one of the most powerful and widely used classes of geometric
    integrators: <strong>splitting and composition methods</strong>.
  </p>

  <p>
    These methods exploit the fact that many differential equations can be 
    written as the sum of <em>simpler vector fields</em> whose individual flows 
    are exactly integrable or preserve essential geometric properties.
  </p>

  <hr/>

  <h3>6.0.1 The Basic Idea</h3>

  <p>
    Consider an evolution equation
  </p>

  <p class="math">
    \[
      y' = (B + C)(y), 
    \]
  </p>

  <p>
    where the flows of the subfields <span class="math">B</span> and <span class="math">C</span>
    are individually computable:
  </p>

  <p class="math">
    \[
      \Phi_B^t = e^{tB}, 
      \qquad 
      \Phi_C^t = e^{tC}.
    \]
  </p>

  <p>
    Splitting methods approximate the combined flow by compositions of these 
    simpler flows, e.g.
  </p>

  <p class="math">
    \[
      e^{h(B+C)} \approx e^{hB} e^{hC},
    \]
  </p>

  <p>
    or symmetric/higher-order variants. Since <em>each exponential preserves
    geometric structure</em> (e.g. symplectic, orthogonal, or unitary), the
    composition inherits these invariants automatically.
  </p>

  <hr/>

  <h3>6.0.2 Why Splitting? Geometry and Efficiency</h3>

  <p>Advantages of splitting approaches:</p>

  <ul>
    <li>They preserve geometric properties such as symplecticity, time reversibility,
      and invariants of motion when the subflows do.</li>
    <li>They often reduce computational cost dramatically by isolating expensive
      operators (e.g. stiff linear parts).</li>
    <li>They are naturally suited for <strong>Hamiltonian systems</strong>,
      <strong>quantum dynamics</strong>, and <strong>semilinear PDEs</strong>.</li>
    <li>They generalise smoothly to <strong>Lie groups</strong> and <strong>manifold-valued flows</strong>.</li>
    <li>They provide a clean path to arbitrarily high order using symmetric compositions.</li>
  </ul>

  <hr/>

  <h3>6.0.3 Compositions: From First-Order to Arbitrarily High Order</h3>

  <p>
    Starting from a basic (possibly low-order) splitting operator
  </p>

  <p class="math">
    \[
      \mathcal{S}(h) = e^{hB}e^{hC},
    \]
  </p>

  <p>
    one constructs higher-order methods by nesting compositions:
  </p>

  <p class="math">
    \[
      \mathcal{S}(a_1 h)\,\mathcal{S}(a_2 h)\cdots 
      \mathcal{S}(a_m h).
    \]
  </p>

  <p>
    Carefully chosen coefficients eliminate lower-order error terms in the
    Baker–Campbell–Hausdorff expansion, yielding high-order integrators with
    minimal additional computational cost.
  </p>

  <p>Examples include:</p>

  <ul>
    <li>Strang (symmetric second order)</li>
    <li>Yoshida 4th, 6th, 8th order compositions</li>
    <li>Suzuki fractal compositions</li>
    <li>Optimised and complex-coefficient factorizations</li>
  </ul>

  <hr/>

  <h3>6.0.4 Connections to Other Areas</h3>

  <p>Splitting methods reside at the intersection of:</p>

  <ul>
    <li>Baker–Campbell–Hausdorff theory</li>
    <li>Lie algebras and manifold flows</li>
    <li>Symplectic geometry and Hamiltonian mechanics</li>
    <li>Exponential integrators for stiff/semi-linear PDEs</li>
    <li>Operator-splitting theory for parabolic/hyperbolic systems</li>
    <li>Quantum simulation and gate approximations</li>
    <li>Time-evolving block decimation (TEBD) in tensor networks</li>
    <li>Reversible and symplectic deep learning architectures (Neural ODEs)</li>
  </ul>

  <p>
    Thus splitting and composition methods form a <strong>unifying framework</strong>
    for geometric time integration across physics, chemistry, applied mathematics,
    and computational engineering.
  </p>

  <hr/>

  <h3>6.0.5 Outline of Chapter 6</h3>

  <p>This chapter develops the foundational splitting methods:</p>

  <ol>
    <li><strong>Lie–Trotter Splitting</strong>: first-order, non-symmetric.</li>
    <li><strong>Strang Splitting</strong>: symmetric second-order.</li>
    <li><strong>Higher-Order Composition Schemes</strong>:
      Yoshida, Suzuki, complex-coefficient.</li>
    <li><strong>Applications to Hamiltonian Flows</strong>:
      separable H = T + V, MD, celestial mechanics.</li>
    <li><strong>Applications to PDEs</strong>:
      Schrödinger, heat, NLS, Klein–Gordon, Maxwell.</li>
    <li><strong>Relation to Magnus and Exponential Integrators</strong>:
      BCH and high-order commutator structure.</li>
    <li><strong>Backward Error Analysis</strong> for splitting.</li>
    <li><strong>Modern Applications</strong>:
      HMC, TEBD, quantum computing gate sequences.</li>
  </ol>

  <p>
    Splitting is thus the backbone of a huge class of geometric integrators.
  </p>

</section>

<section id="sec-6-1">

  <h2>6.1 Lie and Strang Splitting</h2>

  <p>
    In this section we study the two fundamental splitting schemes:
  </p>

  <ol>
    <li><strong>Lie–Trotter splitting</strong> (first order),</li>
    <li><strong>Strang splitting</strong> (second order, symmetric).</li>
  </ol>

  <p>
    We will:
  </p>

  <ol>
    <li>Set up the abstract evolution problem and the notion of splitting,</li>
    <li>Define Lie–Trotter splitting and derive its local error using BCH,</li>
    <li>Define Strang splitting and prove it is second order and time-reversible,</li>
    <li>Discuss geometric properties (symplecticity, reversibility, invariants),</li>
    <li>Illustrate the methods on a simple Hamiltonian example with an interactive figure.</li>
  </ol>

  <hr/>

  <h3 id="sec-6-1-1">6.1.1 Problem Setting and Operator Splitting</h3>

  <p>
    Let \(y(t)\) solve an autonomous ODE on a manifold \(M\):
  </p>

  <p class="math">
    \[
      \dot{y}(t) = f(y(t)), \qquad y(0) = y_0 \in M.
    \]
  </p>

  <p>
    Suppose the vector field \(f\) admits a decomposition into <em>simpler</em> parts
  </p>

  <p class="math">
    \[
      f = f^{[1]} + f^{[2]},
    \]
  </p>

  <p>
    such that the flows of the subsystems
  </p>

  <p class="math">
    \[
      \dot{y} = f^{[1]}(y), \qquad
      \dot{y} = f^{[2]}(y)
    \]
  </p>

  <p>
    can be computed (almost) exactly or very efficiently. Denote their flows by
  </p>

  <p class="math">
    \[
      \varphi_h^{[1]} = \exp(h F^{[1]}), \qquad
      \varphi_h^{[2]} = \exp(h F^{[2]}),
    \]
  </p>

  <p>
    where \(F^{[j]}\) are the corresponding differential operators
    \(F^{[j]} = f^{[j]}\!\cdot\nabla\). The full flow is
  </p>

  <p class="math">
    \[
      \varphi_h = \exp\!\big(h(F^{[1]} + F^{[2]})\big).
    \]
  </p>

  <p>
    A <strong>splitting method</strong> approximates \(\varphi_h\) by a composition of
    subflows, e.g.
  </p>

  <p class="math">
    \[
      \Phi_h = \varphi_{a_1 h}^{[1]} \circ \varphi_{b_1 h}^{[2]}
               \circ \cdots \circ
               \varphi_{a_s h}^{[1]} \circ \varphi_{b_s h}^{[2]},
    \]
  </p>

  <p>
    with suitable coefficients \(a_j, b_j\). The simplest choices give the
    classical Lie–Trotter and Strang splittings.
  </p>

  <p class="task">
    Task marker: later sections will generalize this to multiple splits
    \(f = f^{[1]} + \cdots + f^{[m]}\) and to composition schemes of arbitrarily
    high order.
  </p>

  <hr/>

  <h3 id="sec-6-1-2">6.1.2 Lie–Trotter Splitting</h3>

  <p>
    The <strong>Lie–Trotter splitting</strong> (or first-order splitting) uses the simple
    product of exponentials
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{LT}}
      := \varphi_h^{[1]} \circ \varphi_h^{[2]}
      = \exp(h F^{[1]}) \exp(h F^{[2]}).
    \]
  </p>

  <p>
    The corresponding one-step method is
  </p>

  <p class="math">
    \[
      y_{n+1} =
      \Phi_h^{\mathrm{LT}}(y_n)
      = \varphi_h^{[1]}\big( \varphi_h^{[2]}(y_n)\big).
    \]
  </p>

  <h4>Local error via BCH</h4>

  <p>
    The Baker–Campbell–Hausdorff (BCH) formula gives
  </p>

  <p class="math">
    \[
      \exp(h F^{[1]}) \exp(h F^{[2]})
      = \exp\Big(
          h(F^{[1]} + F^{[2]})
          + \tfrac{h^2}{2}[F^{[1]},F^{[2]}]
          + \mathcal{O}(h^3)
        \Big).
    \]
  </p>

  <p>
    Thus the Lie–Trotter step is the exact flow of a <em>modified vector field</em>
  </p>

  <p class="math">
    \[
      \tilde{F}
      = F^{[1]} + F^{[2]}
        + \tfrac{h}{2}[F^{[1]},F^{[2]}]
        + \mathcal{O}(h^2),
    \]
  </p>

  <p>
    so the local truncation error is \(\mathcal{O}(h^2)\) and the method has
    <strong>global order 1</strong>.
  </p>

  <p class="task">
    Task marker: in BEA we will explicitly compute the modified Hamiltonian for
    Hamiltonian splittings and relate the commutator term to Poisson brackets.
  </p>

  <h4>Geometric properties</h4>

  <ul>
    <li>
      If each subflow \(\varphi_h^{[j]}\) is symplectic, then
      \(\Phi_h^{\mathrm{LT}}\) (as their composition) is symplectic.
    </li>
    <li>
      If each subflow preserves a constraint manifold, so does the composition.
    </li>
    <li>
      However, the method is <em>not symmetric</em> (time-reversible) in general:
      its adjoint is
      \(\big(\Phi_h^{\mathrm{LT}}\big)^\star
         = \exp(hF^{[2]})\exp(hF^{[1]}) \neq \Phi_h^{\mathrm{LT}}\).
    </li>
  </ul>

  <hr/>

  <h3 id="sec-6-1-3">6.1.3 Strang Splitting (Second Order, Symmetric)</h3>

  <p>
    The <strong>Strang splitting</strong> (Strang 1968) is the symmetric composition
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{S}}
      := \varphi_{h/2}^{[1]} \circ \varphi_{h}^{[2]} \circ \varphi_{h/2}^{[1]}
      = \exp\!\left(\tfrac{h}{2}F^{[1]}\right)
        \exp\!\left(h F^{[2]}\right)
        \exp\!\left(\tfrac{h}{2}F^{[1]}\right).
    \]
  </p>

  <p>
    The corresponding scheme is:
  </p>

  <ol>
    <li><em>Half-step in \(f^{[1]}\)</em>:
      \(y^{(1)} = \varphi_{h/2}^{[1]}(y_n)\),</li>
    <li><em>Full step in \(f^{[2]}\)</em>:
      \(y^{(2)} = \varphi_{h}^{[2]}(y^{(1)})\),</li>
    <li><em>Half-step in \(f^{[1]}\)</em>:
      \(y_{n+1} = \varphi_{h/2}^{[1]}(y^{(2)})\).</li>
  </ol>

  <h4>Order of accuracy via BCH</h4>

  <p>
    Using BCH and symmetry, one can show that the odd-order error terms cancel.
    More concretely,
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{S}}
      = \exp\!\Big(
          h(F^{[1]}+F^{[2]})
          + \mathcal{O}(h^3)
        \Big),
    \]
  </p>

  <p>
    so the local error is \(\mathcal{O}(h^3)\) and the global error is
    \(\mathcal{O}(h^2)\): Strang splitting has <strong>order 2</strong>.
  </p>

  <p>
    A key general principle is:
  </p>

  <blockquote>
    <em>Self-adjoint (time-symmetric) one-step methods of order ≥ 1 are always of
    even order.</em>
  </blockquote>

  <p>
    Strang splitting is self-adjoint, hence order 2 rather than 1.
  </p>

  <h4>Time symmetry (reversibility)</h4>

  <p>
    Let \(\Phi_h^\star\) denote the adjoint method defined by
  </p>

  <p class="math">
    \[
      \Phi_h^\star := \Phi_{-h}^{-1}.
    \]
  </p>

  <p>
    A one-step method is <strong>self-adjoint</strong> (or time-symmetric) if
    \(\Phi_h^\star = \Phi_h\).
    For Strang splitting,
  </p>

  <p class="math">
    \[
      \big(\Phi_h^{\mathrm{S}}\big)^{-1}
      = \varphi_{-h/2}^{[1]} \circ \varphi_{-h}^{[2]} \circ \varphi_{-h/2}^{[1]}
      = \Phi_{-h}^{\mathrm{S}},
    \]
  </p>

  <p>
    hence \(\Phi_h^{\mathrm{S}}\) is self-adjoint. This is crucial for good
    long-time behaviour, especially in reversible and Hamiltonian systems.
  </p>

  <hr/>

  <h3 id="sec-6-1-4">6.1.4 Geometric Properties of Lie and Strang Splittings</h3>

  <p>
    Let us summarize the main geometric features when the splitting is applied
    to a structured system, e.g. a Hamiltonian system with
    \(H = H^{[1]} + H^{[2]}\).
  </p>

  <ul>
    <li>
      If \(f^{[j]}\) are Hamiltonian vector fields for \(H^{[j]}\),
      then \(\varphi_t^{[j]}\) are symplectic maps. Any composition of them
      (including Lie–Trotter and Strang) is symplectic.
    </li>
    <li>
      <strong>Symplecticity:</strong> both Lie–Trotter and Strang splitting are
      symplectic for Hamiltonian splittings.
    </li>
    <li>
      <strong>Reversibility:</strong> Strang splitting is reversible
      (self-adjoint), while Lie–Trotter is not.
    </li>
    <li>
      <strong>Energy behaviour:</strong> in the Hamiltonian case, backward error
      analysis shows that both methods almost conserve a modified Hamiltonian
      \( \tilde{H} = H + \mathcal{O}(h) \) (Lie–Trotter) or
      \( \tilde{H} = H + \mathcal{O}(h^2) \) (Strang) over very long times.
    </li>
  </ul>

  <p class="task">
    Task marker: in later sections we derive explicit modified Hamiltonians
    for separable systems \(H(q,p) = T(p) + V(q)\) under Strang splitting, and
    compare with standard symplectic Euler and Verlet.
  </p>

  <hr/>

  <h3 id="sec-6-1-5">6.1.5 Example: Separable Hamiltonian \(H(q,p) = T(p) + V(q)\)</h3>

  <p>
    A prototypical application is a separable Hamiltonian system
  </p>

  <p class="math">
    \[
      H(q,p) = T(p) + V(q), \qquad
      (q,p) \in \mathbb{R}^m \times \mathbb{R}^m.
    \]
  </p>

  <p>
    The Hamiltonian vector field splits as
  </p>

  <p class="math">
    \[
      \dot{q} = \nabla_p T(p), \qquad
      \dot{p} = -\nabla_q V(q),
    \]
  </p>

  <p>
    which we interpret as the sum of two subfields:
  </p>

  <ul>
    <li>
      <strong>Drift (kinetic) part</strong> \(f^{[1]}\):
      \(\dot{q} = \nabla_p T(p), \; \dot{p}=0\),
    </li>
    <li>
      <strong>Kick (potential) part</strong> \(f^{[2]}\):
      \(\dot{q} = 0, \; \dot{p} = -\nabla_q V(q)\).
    </li>
  </ul>

  <p>
    Their flows are explicitly available:
  </p>

  <p class="math">
    \[
      \varphi_h^{[1]}(q,p) = \big(q + h\nabla_p T(p),\; p\big),
      \qquad
      \varphi_h^{[2]}(q,p) = \big(q,\; p - h\nabla_q V(q)\big).
    \]
  </p>

  <p>
    Applying Strang splitting gives the well-known <strong>velocity Verlet</strong> /
    <strong>leapfrog</strong> scheme:
  </p>

  <ol>
    <li>
      Half kick:
      \(
        p_{n+\frac{1}{2}} = p_n - \frac{h}{2}\nabla_q V(q_n)
      \)
    </li>
    <li>
      Drift:
      \(
        q_{n+1} = q_n + h \nabla_p T(p_{n+\frac{1}{2}})
      \)
    </li>
    <li>
      Half kick:
      \(
        p_{n+1} = p_{n+\frac{1}{2}} - \frac{h}{2}\nabla_q V(q_{n+1})
      \)
    </li>
  </ol>

  <p>
    This is the cornerstone integrator in molecular dynamics, celestial mechanics,
    and Hamiltonian Monte Carlo.
  </p>

  <figure id="fig-6-1" style="text-align:center;">
    <canvas id="splittingCanvas" width="620" height="300"
            style="border:1px solid #ccc;"></canvas>
    <figcaption>
      <strong>Figure 6.1</strong> – Energy behaviour for the 1D harmonic oscillator
      \(H(q,p)=\tfrac{1}{2}(p^2+q^2)\): comparison of Lie–Trotter splitting and
      Strang splitting. The Strang (leapfrog) method shows bounded, oscillatory
      energy error, while Lie–Trotter shows a systematic bias.
    </figcaption>
  </figure>

  <script>
    (function(){
      const canvas = document.getElementById("splittingCanvas");
      if (!canvas) return;
      const ctx = canvas.getContext("2d");
      const w = canvas.width, h = canvas.height;

      // Parameters
      const hstep = 0.2;
      const steps = 300;
      const q0 = 1.0, p0 = 0.0;

      function H(q,p){ return 0.5*(q*q + p*p); }

      // Lie–Trotter splitting for harmonic oscillator with
      //   T(p)=p^2/2 => drift: q' = p, p' =0
      //   V(q)=q^2/2 => kick : q'=0, p'=-q
      function stepLieTrotter(q,p,h){
        // full drift then full kick: φ_h^[1] ∘ φ_h^[2] or vice versa
        // we choose  φ_h^[1] (drift) ∘ φ_h^[2] (kick)
        // Kick
        p = p - h*q;
        // Drift
        q = q + h*p;
        return {q,p};
      }

      // Strang splitting (leapfrog)
      function stepStrang(q,p,h){
        // half kick
        p = p - 0.5*h*q;
        // drift
        q = q + h*p;
        // half kick
        p = p - 0.5*h*q;
        return {q,p};
      }

      const tVals = [];
      const E_Lie = [];
      const E_Str = [];

      // Simulate Lie–Trotter
      let q = q0, p = p0;
      for(let n=0;n<=steps;n++){
        const t = n*hstep;
        tVals.push(t);
        E_Lie.push(H(q,p));
        const st = stepLieTrotter(q,p,hstep);
        q = st.q; p = st.p;
      }

      // Simulate Strang
      q = q0; p = p0;
      for(let n=0;n<=steps;n++){
        E_Str.push(H(q,p));
        const st = stepStrang(q,p,hstep);
        q = st.q; p = st.p;
      }

      const Emin = Math.min.apply(null, E_Lie.concat(E_Str));
      const Emax = Math.max.apply(null, E_Lie.concat(E_Str));
      const padLeft=50, padRight=10, padTop=10, padBottom=30;

      function X(t){
        const tmin=0, tmax=tVals[tVals.length-1];
        return padLeft + (t - tmin)*(w-padLeft-padRight)/(tmax-tmin);
      }
      function Y(E){
        return h - padBottom - (E-Emin)*(h-padTop-padBottom)/(Emax-Emin);
      }

      ctx.clearRect(0,0,w,h);
      ctx.font="12px sans-serif";

      // Axes
      ctx.beginPath();
      ctx.moveTo(padLeft, padTop);
      ctx.lineTo(padLeft, h-padBottom);
      ctx.lineTo(w-padRight, h-padBottom);
      ctx.strokeStyle="#000";
      ctx.stroke();

      ctx.fillText("t", w-padRight-10, h-padBottom+18);
      ctx.fillText("H", padLeft-18, padTop+10);

      // Plot Lie–Trotter
      ctx.beginPath();
      for(let n=0;n<tVals.length;n++){
        const x = X(tVals[n]);
        const y = Y(E_Lie[n]);
        if(n===0) ctx.moveTo(x,y);
        else ctx.lineTo(x,y);
      }
      ctx.strokeStyle="#c00";
      ctx.stroke();

      // Plot Strang
      ctx.beginPath();
      for(let n=0;n<tVals.length;n++){
        const x = X(tVals[n]);
        const y = Y(E_Str[n]);
        if(n===0) ctx.moveTo(x,y);
        else ctx.lineTo(x,y);
      }
      ctx.strokeStyle="#06c";
      ctx.stroke();

      // Legend
      ctx.fillStyle="#c00";
      ctx.fillRect(padLeft+10, padTop+5, 12, 3);
      ctx.fillStyle="#000";
      ctx.fillText("Lie–Trotter", padLeft+30, padTop+11);

      ctx.fillStyle="#06c";
      ctx.fillRect(padLeft+10, padTop+20, 12, 3);
      ctx.fillStyle="#000";
      ctx.fillText("Strang (leapfrog)", padLeft+30, padTop+26);
    })();
  </script>

  <hr/>

  <h3 id="sec-6-1-6">6.1.6 Summary and References for 6.1</h3>

  <p>
    In this section we:
  </p>

  <ul>
    <li>Defined the abstract splitting setting for \(f = f^{[1]} + f^{[2]}\),</li>
    <li>Introduced Lie–Trotter splitting (first order) and its BCH-based error,</li>
    <li>Introduced Strang splitting (second order, symmetric) and its time-reversibility,</li>
    <li>Discussed symplecticity and reversibility for Hamiltonian splittings,</li>
    <li>Derived leapfrog / velocity Verlet as Strang splitting for separable Hamiltonians,</li>
    <li>Illustrated energy behaviour on the harmonic oscillator via an interactive plot.</li>
  </ul>

  <p>
    These schemes are the building blocks for higher-order composition methods
    and for many modern applications (Hamiltonian Monte Carlo, quantum simulation,
    PDE splitting, etc.). Subsequent sections generalize these ideas to
    multi-part splittings and higher-order factorizations.
  </p>

  <h4>References for Section 6.1</h4>

  <ol>
    <li>
      <strong>[Str68]</strong> G. Strang,
      “On the construction and comparison of difference schemes,”
      <em>SIAM Journal on Numerical Analysis</em>, 5(3):506–517, 1968.
    </li>
    <li>
      <strong>[HLW06]</strong> E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>,
      2nd ed., Springer, 2006. (Ch. II, IV on splitting methods.)
    </li>
    <li>
      <strong>[BC26]</strong> S. Blanes, F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>,
      2nd ed., CRC Press, 2026. (Chapters on splitting and composition methods.)
    </li>
  </ol>

</section>

<section id="sec-6-2">

  <h2>6.2 Symmetric Composition Methods: From Strang to High Order</h2>

  <p>
    Strang splitting is the simplest nontrivial symmetric composition:
  </p>

  <p class="math">
    \[
      \Phi_h^{\mathrm{S}}
      = \varphi^{[1]}_{h/2} \circ \varphi^{[2]}_{h} \circ \varphi^{[1]}_{h/2},
    \]
  </p>

  <p>
    which is second order because symmetry causes cancellation of all odd-order
    error terms in the BCH expansion. This section develops the general theory:
    <em>how symmetric compositions lead to arbitrarily high-order geometric
    integrators</em>.
  </p>

  <hr/>

  <h3 id="sec-6-2-1">6.2.1 General Symmetric Composition</h3>

  <p>
    Let \(\Psi_h\) be a basic method of order \(p\), and assume it is
    <strong>self-adjoint</strong> (i.e. reversible, symmetric):
  </p>

  <p class="math">
    \[
      \Psi^{\star}_{h} = \Psi_h.
    \]
  </p>

  <p>
    Consider a symmetric composition with real coefficients
  </p>

  <p class="math">
    \[
      \Psi_h^{(m)}
      = 
      \Psi_{a_1 h} \circ \Psi_{a_2 h} \circ \cdots \circ 
      \Psi_{a_s h} \circ \Psi_{a_{s} h} \circ \cdots 
      \Psi_{a_2 h} \circ \Psi_{a_1 h}.
    \tag{6.2.1}
    \]
  </p>

  <p>
    Symmetry ensures the overall method is self-adjoint:
  </p>

  <p class="math">
    \[
      \big(\Psi_h^{(m)}\big)^\star = \Psi_h^{(m)}.
    \]
  </p>

  <p>
    As a consequence, all <em>odd-order</em> terms in the BCH expansion cancel.
  </p>

  <hr/>

  <h3 id="sec-6-2-2">6.2.2 BCH Structure and Order Conditions</h3>

  <p>
    Let the modified vector field of \(\Psi_h\) be
  </p>

  <p class="math">
    \[
      \tilde{F}(h)
      = 
      F
      + h^{p} E_{p}
      + h^{p+1} E_{p+1}
      + h^{p+2} E_{p+2}
      + \cdots.
    \tag{6.2.2}
    \]
  </p>

  <p>
    Inserting scaled steps \(a_j h\) yields modified fields
  </p>

  <p class="math">
    \[
      \tilde{F}(a_j h)
      = 
      F
      + a_j^{p} h^{p} E_p
      + a_j^{p+1} h^{p+1} E_{p+1}
      + \cdots.
    \]
  </p>

  <p>
    The BCH formula for the symmetric composition (6.2.1) has only even powers:
  </p>

  <p class="math">
    \[
      \log\big(\Psi_h^{(m)}\big)
      =
      h F
      + h^{p+2} C_{p+2}(a_1,\ldots,a_s)
      + h^{p+4} C_{p+4}(a_1,\ldots,a_s)
      + \cdots.
    \tag{6.2.3}
    \]
  </p>

  <p>
    The <strong>order conditions</strong> are the algebraic constraints on 
    \(a_1,\ldots,a_s\) ensuring that
  </p>

  <p class="math">
    \[
      C_{p+2} = C_{p+4} = \cdots = C_{P-1} = 0.
    \]
  </p>

  <p>
    This yields an overall method of order \(P\).
  </p>

  <p class="task">
    Task marker: later sections will list explicit order conditions for splitting
    and composition up to 8th order using the Lyndon word basis for the free 
    Lie algebra.
  </p>

  <hr/>

  <h3 id="sec-6-2-3">6.2.3 Yoshida’s Triple-Jump: Raising Order by Two</h3>

  <p>
    Let \(\Psi_h\) be a symmetric method of order \(2m\). Yoshida (1990) showed that
    the composition
  </p>

  <p class="math">
    \[
      \Psi_h^{(m+1)}
      =
      \Psi_{\alpha h}
      \circ \Psi_{\beta h}
      \circ \Psi_{\alpha h}
    \tag{6.2.4}
    \]
  </p>

  <p>
    is a symmetric method of order \(2m + 2\) provided \(\alpha, \beta\) satisfy
  </p>

  <p class="math">
    \[
      2\alpha + \beta = 1,
      \qquad
      2\alpha^{2m+1} + \beta^{2m+1} = 0.
    \tag{6.2.5}
    \]
  </p>

  <p>
    These equations have the explicit solution
  </p>

  <p class="math">
    \[
      \alpha = \frac{1}{2 - 2^{1/(2m+1)}},
      \qquad
      \beta = -\,\frac{2^{1/(2m+1)}}{2 - 2^{1/(2m+1)}}.
    \tag{6.2.6}
    \]
  </p>

  <p>
    For example:
  </p>

  <table style="margin: 1em auto; border-collapse: collapse;" border="1">
    <thead>
      <tr>
        <th>Base Order</th>
        <th>Resulting Order</th>
        <th>\(\alpha\)</th>
        <th>\(\beta\)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>2</td>
        <td>4</td>
        <td>\(\displaystyle \frac{1}{2-2^{1/3}} \approx 0.675603\)</td>
        <td>\(1 - 2\alpha \approx -0.351207\)</td>
      </tr>
      <tr>
        <td>4</td>
        <td>6</td>
        <td>\(\displaystyle \frac{1}{2-2^{1/5}} \approx 0.587\)</td>
        <td>\(1 - 2\alpha \approx -0.174\)</td>
      </tr>
    </tbody>
  </table>

  <p>
    Starting from Strang (\(2^{nd}\) order), repeated Yoshida triple-jumps yield
    methods of orders 4, 6, 8, …
  </p>

  <hr/>

  <h3 id="sec-6-2-4">6.2.4 Suzuki’s Fractal Composition</h3>

  <p>
    Suzuki (1991) extended Yoshida’s idea to general “fractal” compositions.
    A common example is:
  </p>

  <p class="math">
    \[
      \Psi_h^{(p+2)}
      =
      \Psi_{\gamma h}^{(p)} \circ
      \Psi_{\delta h}^{(p)} \circ
      \Psi_{\gamma h}^{(p)}
    \tag{6.2.7}
    \]
  </p>

  <p>
    with coefficients chosen to annihilate additional BCH terms. These schemes
    form a recursive family generating arbitrarily high order from a base
    symmetric integrator.
  </p>

  <hr/>

  <h3 id="sec-6-2-5">6.2.5 Symmetric Composition for Splitting Methods</h3>

  <p>
    When the base integrator \(\Psi_h\) is itself a splitting, such as Strang:
  </p>

  <p class="math">
    \[
      \Psi_h = \varphi_{h/2}^{[1]} \circ \varphi_h^{[2]} \circ \varphi_{h/2}^{[1]},
    \tag{6.2.8}
    \]
  </p>

  <p>
    the Yoshida and Suzuki compositions give high-order <em>splitting methods</em>.
    For example, the 4th-order symmetric splitting obtained from Strang is:
  </p>

  <p class="math">
    \[
      \Phi_h^{(4)}
      =
      \Phi_{\alpha h}^{\mathrm{S}}
      \circ 
      \Phi_{\beta h}^{\mathrm{S}}
      \circ 
      \Phi_{\alpha h}^{\mathrm{S}},
    \tag{6.2.9}
    \]
  </p>

  <p>
    which expands (after substituting the Strang components) into
    a 7-factor composition of subflows \(\varphi^{[1]}\) and \(\varphi^{[2]}\).
  </p>

  <p>
    These high-order splittings are widely used in:
  </p>

  <ul>
    <li>quantum chemistry (time propagation of Schrödinger equations),</li>
    <li>molecular dynamics,</li>
    <li>celestial mechanics and perturbed Kepler problems,</li>
    <li>long-time Hamiltonian simulations,</li>
    <li>time-splitting methods for nonlinear Schrödinger and KdV equations.</li>
  </ul>

  <hr/>

  <h3 id="sec-6-2-6">6.2.6 Geometric Benefits of Symmetric Composition</h3>

  <p>
    Symmetric compositions retain:
  </p>

  <ul>
    <li><strong>Symplecticity</strong> (if the base method is symplectic),</li>
    <li><strong>Time reversibility</strong>,</li>
    <li><strong>Volume preservation</strong> if applicable,</li>
    <li>
      <strong>Excellent long-time behaviour</strong> via a modified Hamiltonian
      of the form
      \[
        \tilde{H}
        =
        H + h^{2} H_2 + h^{4} H_4 + \cdots.
      \]
    </li>
  </ul>

  <p>
    High-order symplectic compositions are often competitive with (or superior
    to) high-order Runge–Kutta methods because the dominant error terms in
    Hamiltonian problems are often <em>commutators</em>, which compositions
    suppress efficiently.
  </p>

  <hr/>

  <h3 id="sec-6-2-7">6.2.7 Summary and References for 6.2</h3>

  <p>
    In this section we developed the general framework of symmetric composition
    methods. Starting from a symmetric base integrator (typically Strang), one
    can construct high-order geometric integrators using Yoshida triple-jumps,
    Suzuki fractal compositions, or more general optimized compositions.
  </p>

  <p>
    Key takeaways:
  </p>

  <ul>
    <li>Symmetry → cancellation of odd BCH terms → only even orders appear.</li>
    <li>Yoshida’s method raises order by 2 each iteration.</li>
    <li>Complexity grows slowly: many high-order methods require few stages.</li>
    <li>Schemes preserve symplecticity, reversibility, and invariants.</li>
    <li>These methods underpin modern Hamiltonian integrators, quantum simulations,
      and high-accuracy PDE solvers.</li>
  </ul>

  <h4>References</h4>
  <ol>
    <li>
      H. Yoshida, “Construction of higher order symplectic integrators,”
      <em>Phys. Lett. A</em>, 150(5–7):262–268, 1990.
    </li>
    <li>
      M. Suzuki, “General theory of fractal path integrals,”
      <em>Phys. Lett. A</em>, 146:319–323, 1991.
    </li>
    <li>
      E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration</em>, Springer, 2006.
    </li>
  </ol>

</section>

<section id="sec-6-3">

  <h2>6.3 Optimised High-Order Splitting Methods: Real &amp; Complex Coefficients</h2>

  <p>
    Classical symmetric compositions (Strang, Yoshida, Suzuki) generate
    high-order methods with universal algebraic rules, but they are rarely
    <em>optimal</em> for a specific class of problems. In this section we
    present the modern theory of <strong>optimised splitting schemes</strong>,
    including:
  </p>

  <ul>
    <li>minimal-stage real-coefficient methods,</li>
    <li>complex-coefficient splittings for high and arbitrary order,</li>
    <li>positivity constraints (important for diffusion-type PDEs),</li>
    <li>energy-optimised Hamiltonian integrators,</li>
    <li>nearly-optimal schemes for quantum and semiclassical dynamics.</li>
  </ul>

  <p>
    These methods represent the contemporary <em>state-of-the-art</em> and often
    outperform all traditional splitting schemes for demanding applications.
  </p>

  <hr/>

  <h3 id="sec-6-3-1">6.3.1 The Algebraic Order Barrier for Real Coefficients</h3>

  <p>
    Consider symmetric splitting of a two-part system:
  </p>

  <p class="math">
    \[
      \Phi_h = 
      \prod_{j=1}^{s} 
        \exp(a_j h F^{[1]})
        \exp(b_j h F^{[2]}),
    \]
  </p>

  <p>
    with the <strong>symmetry</strong> constraint
  </p>

  <p class="math">
    \[
      a_j = a_{s+1-j}, \qquad b_j = b_{s+1-j}.
    \tag{6.3.1}
    \]
  </p>

  <p>
    The BCH expansion of <span class="math">\(\log \Phi_h\)</span> contains commutators
    \[
      [F^{[1]},F^{[2]}], \quad
      [F^{[1]},[F^{[1]},F^{[2]}]], \quad \dots
    \]
    and the order conditions require vanishing of specific linear combinations
    of these.
  </p>

  <p>
    <strong>Key barrier (Sheng 1989, Suzuki 1991):</strong>
  </p>

  <blockquote>
    <em>No symmetric splitting of order higher than 2 exists with all real
    coefficients \(a_j, b_j \ge 0\).</em>
  </blockquote>

  <p>
    In particular:
  </p>

  <ul>
    <li>4th-order real symmetric splittings <em>must</em> include negative
        coefficients,</li>
    <li>this is catastrophic for diffusion/parabolic PDEs, since \(\exp(-|h|A)\)
        can blow up when \(A\) is negative semidefinite.</li>
  </ul>

  <p>
    Thus:
  </p>

  <ul>
    <li><strong>Real-coefficient splittings</strong> are ideal for Hamiltonian 
      (conservative) flows.</li>
    <li><strong>Complex-coefficient splittings</strong> are essential for 
      Schrödinger equations, semiclassical systems, and general non-parabolic 
      PDEs.</li>
  </ul>

  <hr/>

  <h3 id="sec-6-3-2">6.3.2 Minimal-Stage Real-Coefficient Splittings (Optimised)</h3>

  <p>
    High-order real-coefficient splittings are constructed by solving the
    BCH order conditions while <em>minimising either</em>:
  </p>

  <ul>
    <li>the number of stages,</li>
    <li>the error constant,</li>
    <li>the sum of absolute coefficients,</li>
    <li>energy error over long time (Hamiltonian optimisation).</li>
  </ul>

  <h4>Fourth-order optimised real splitting (McLachlan 1995)</h4>

  <p>
    A minimal 4th-order symmetric scheme exists with
    <strong>three exponentials of each operator</strong>:
  </p>

  <p class="math">
    \[
      \Phi_h^{(4)}
      = 
      e^{a_1 h F^{[1]}}
      e^{b_1 h F^{[2]}}
      e^{a_2 h F^{[1]}}
      e^{b_1 h F^{[2]}}
      e^{a_1 h F^{[1]}}.
    \tag{6.3.2}
    \]
  </p>

  <p>
    with coefficients
  </p>

  <p class="math">
    \[
      a_1 = \frac{1}{2 - 2^{1/3}}, 
      \qquad
      a_2 = -\frac{2^{1/3}}{2 - 2^{1/3}},
    \]
    \[
      b_1 = \frac{1}{2}.
    \tag{6.3.3}
    \]
  </p>

  <p>
    These are Yoshida's coefficients but optimised variants exist where the 
    <em>error constant is minimised</em> (e.g., McLachlan’s 1995 scheme).
  </p>

  <p class="task">
    Task marker: Section 6.4 derives optimal real splittings for 
    Hamiltonian dynamics using backward error analysis and modified
    Hamiltonians.
  </p>

  <hr/>

  <h3 id="sec-6-3-3">6.3.3 Complex-Coefficient Splittings for High and Arbitrary Order</h3>

  <p>
    Allowing <strong>complex coefficients</strong> dramatically changes the landscape:
  </p>

  <ul>
    <li>complex coefficients circumvent the Sheng–Suzuki real-positivity barrier,</li>
    <li>arbitrarily high order is possible without negative <em>real</em> parts,</li>
    <li>splittings become extremely efficient for Schrödinger and semiclassical problems.</li>
  </ul>

  <h4>General complex symmetric splitting</h4>

  <p class="math">
    \[
      \Phi_h
      =
      \prod_{j=1}^s
      \exp(a_j h F^{[1]})
      \exp(b_j h F^{[2]}),
    \tag{6.3.4}
    \]
  </p>

  <p>
    where now
    \[
      a_j, b_j \in \mathbb{C}, 
      \qquad
      \Re(a_j), \Re(b_j) \ge 0.
    \]
  </p>

  <p>
    These schemes are stable for:
  </p>

  <ul>
    <li>Schrödinger PDEs (unitarity preserved exactly),</li>
    <li>linear operators with purely imaginary spectrum,</li>
    <li>nonlinear NLS, Gross–Pitaevskii, Dirac equations.</li>
  </ul>

  <h4>Example: 4th-order complex scheme with all positive real parts</h4>

  <p>
    The Blanes–Casas “C4” scheme:
  </p>

  <p class="math">
    \[
      a_1 = 0.5 + 0.28867513459 i, \qquad 
      a_2 = 0.5 - 0.28867513459 i,
    \tag{6.3.5}
    \]
  </p>

  <p>
    yields a 4th-order splitting with only two exponentials of each operator,
    outperforming all real-coefficient schemes in quantum applications.
  </p>

  <hr/>

  <h3 id="sec-6-3-4">6.3.4 Positivity Constraints for Parabolic PDEs</h3>

  <p>
    For diffusion or parabolic systems:
  </p>

  <p class="math">
    \[
      \dot{u} = A u + B u,
    \]
  </p>

  <p>
    the operator \( e^{a_j h A} \) must satisfy:
  </p>

  <p class="math">
    \[
      \Re(a_j) \ge 0,
      \qquad
      \Re(b_j) \ge 0,
    \tag{6.3.6}
    \]
  </p>

  <p>
    otherwise the method is unstable. Therefore:
  </p>

  <ul>
    <li>High-order real-coefficient splittings are impossible,</li>
    <li>Complex-coefficient splittings with positive real parts are the only viable solution.</li>
  </ul>

  <h4>SOTA: Blanes–Casas optimal CFM splittings for parabolic PDEs</h4>

  <p>
    They constructed 4th, 6th, and 8th-order splitting schemes with <strong>all
    coefficients in the right half-plane</strong>. These dominate the field in
    smoothing-dominated PDEs.
  </p>

  <hr/>

  <h3 id="sec-6-3-5">6.3.5 Energy-Optimised Splittings for Hamiltonian Systems</h3>

  <p>
    For Hamiltonian systems with 
    \(H = T(p) + V(q)\), the goal is to minimise:
  </p>

  <ul>
    <li>modified Hamiltonian error,</li>
    <li>shadow energy drift,</li>
    <li>commutator magnitude 
      \( [T,[T,V]] \), \( [V,[T,V]] \), etc.</li>
  </ul>

  <p>
    These yield:
  </p>

  <ul>
    <li><strong>Omelyan–Mryglod–Folk (OMF) integrators</strong> (4th order): widely used in lattice QCD.</li>
    <li><strong>Chin’s force-gradient splittings</strong>: incorporate derivatives of forces for high accuracy.</li>
    <li><strong>Optimised 6th–8th order Hamiltonian splittings</strong>
        (Blanes–Casas–Sanz-Serna).</li>
  </ul>

  <p class="math">
    \[
      \Phi_h^{\mathrm{OMF}}
      =
      e^{\lambda h B}
      e^{\frac{1}{2} h A}
      e^{(1-2\lambda) h B}
      e^{\frac{1}{2} h A}
      e^{\lambda h B},
    \tag{6.3.7}
    \]
  </p>

  <p>
    with 
    \(\lambda \approx 0.1931833275\),
    which dramatically reduces energy drift.
  </p>

  <hr/>

  <h3 id="sec-6-3-6">6.3.6 Summary and References for 6.3</h3>

  <p>
    This section presented the full modern landscape of optimised splittings:
  </p>

  <ul>
    <li><strong>Real-coefficient methods</strong>: must include negatives; ideal for Hamiltonian flows.</li>
    <li><strong>Complex-coefficient methods</strong>: allow arbitrarily high order with stability.</li>
    <li><strong>Positivity constraints</strong>: crucial for parabolic PDEs.</li>
    <li><strong>Energy-optimised splittings</strong>: leading methods for long-time Hamiltonian work.</li>
    <li>The SOTA schemes (Blanes–Casas, Suzuki, McLachlan, Shin–Chin, OMF) outperform
        classical compositions in almost every demanding application.</li>
  </ul>

  <h4>References</h4>

  <ol>
    <li>
      S. Blanes, F. Casas, J.A. Oteo, J. Ros,
      <em>The Magnus Expansion and Some of its Applications</em>,
      Physics Reports 470, 2009.
    </li>
    <li>
      R.I. McLachlan, “On the optimality of symplectic integrators,”
      <em>SIAM J. Sci. Comput.</em>, 16, 1995.
    </li>
    <li>
      M. Suzuki, “Fractal decompositions,” J. Math. Phys., 1990–1991 series.
    </li>
    <li>
      M. Omelyan, I. Mryglod, R. Folk,
      <em>Optimized Forest–Ruth- and Suzuki-type symplectic integrators</em>,
      Computer Physics Communications, 2002–2003.
    </li>
    <li>
      S. Blanes, F. Casas, <em>A Concise Introduction to GNI</em>, 2e, CRC, 2026.
    </li>
  </ol>

</section>

<section id="sec-6-4">

  <h2>6.4 Backward Error Analysis for Splitting Methods</h2>

  <p>
    Backward error analysis (BEA) provides the fundamental theoretical 
    explanation for the excellent long-time behaviour of geometric integrators.
    Rather than analysing the discrete numerical flow directly, BEA interprets
    a numerical scheme as the <strong>exact flow of a modified differential
    equation</strong>:
  </p>

  <p class="math">
    \[
      \Phi_h = \exp\!\big(h \tilde{F}(h)\big),
    \]
  </p>

  <p>
    where the <em>modified vector field</em> admits a formal series expansion
    \[
      \tilde{F}(h)
      = 
      F
      + h F_2
      + h^2 F_3
      + h^3 F_4
      + \cdots.
    \]
    For geometric methods—especially symplectic mappings—the modified system
    inherits the geometric structure (e.g.~Hamiltonian geometry) to all orders
    in \(h\).
  </p>

  <hr/>

  <h3 id="sec-6-4-1">6.4.1 Modified Vector Fields from BCH Theory</h3>

  <p>
    Consider a splitting integrator for an autonomous system
  </p>

  <p class="math">
    \[
      y' = (A + B)(y).
    \tag{6.4.1}
    \]
  </p>

  <p>
    A general splitting has the form
  </p>

  <p class="math">
    \[
      \Phi_h
      =
      \prod_{j=1}^s 
      \exp(a_j h A)\, \exp(b_j h B).
    \tag{6.4.2}
    \]
  </p>

  <p>
    The Baker–Campbell–Hausdorff expansion provides
  </p>

  <p class="math">
    \[
      \log(\Phi_h)
      =
      h(A+B)
      + h^2 \alpha_1[A,B]
      + h^3\big(\alpha_2[A,[A,B]] + \alpha_3[B,[A,B]]\big)
      + h^4 \cdots.
    \tag{6.4.3}
    \]
  </p>

  <p>
    Let the modified vector field be defined by
  </p>

  <p class="math">
    \[
      h\tilde{F}(h) = \log(\Phi_h).
    \]
  </p>

  <p>
    Then
  </p>

  <p class="math">
    \[
      \tilde{F}(h)
      =
      A + B
      + h \alpha_1[A,B]
      + h^2\big(\alpha_2[A,[A,B]] + \alpha_3[B,[A,B]]\big)
      + h^3(\cdots).
    \tag{6.4.4}
    \]
  </p>

  <p>
    Each coefficient \(\alpha_k\) is a known polynomial in the splitting
    coefficients \(a_j, b_j\). Setting these equal to zero yields the order
    conditions. Optimised splittings (Section 6.3) choose them to minimise the
    leading error terms in the modified system.
  </p>

  <hr/>

  <h3 id="sec-6-4-2">6.4.2 Geometric Structure of the Modified System</h3>

  <p>
    If the original system is Hamiltonian with 
    \[
      A = X_T, \qquad B = X_V,
    \]
    then all nested commutators of \(A\) and \(B\) are Hamiltonian vector 
    fields. Thus the modified vector field is Hamiltonian:
  </p>

  <p class="math">
    \[
      \tilde{F}(h) = X_{\tilde{H}}, 
    \]
  </p>

  <p>
    where the modified Hamiltonian admits the expansion
  </p>

  <p class="math">
    \[
      \tilde{H}
      =
      H
      +
      h^2 H_2
      +
      h^4 H_4
      +
      h^6 H_6
      +
      \cdots.
    \tag{6.4.5}
    \]
  </p>

  <p>
    For <strong>symmetric</strong> (time-reversible) methods, all odd-index 
    terms vanish:
  </p>

  <p class="math">
    \[
      H_{2k+1} = 0.
    \]
  </p>

  <p>
    Thus Strang and all symmetric compositions preserve (to very high accuracy)
    an even-order approximation of the true Hamiltonian, which explains their
    exceptional long-time energy conservation.
  </p>

  <hr/>

  <h3 id="sec-6-4-3">6.4.3 Long-Time Behavior and Near-Conservation Laws</h3>

  <p>
    For symplectic integrators, BEA yields the “shadow energy” theorem:
  </p>

  <blockquote>
    <em>If \( \Phi_h \) is symplectic, then it exactly preserves the modified 
    Hamiltonian \( \tilde{H} \) for exponentially long times
    \( T = \mathcal{O}(e^{c/h}) \), provided the solution remains in a compact set.</em>
  </blockquote>

  <p>
    In practice:
  </p>

  <ul>
    <li>
      The numerical energy oscillates around a quasi-constant value with 
      amplitude \( \mathcal{O}(h^p) \).
    </li>
    <li>
      No secular (linear) drift occurs, in contrast to non-symplectic methods.
    </li>
    <li>
      Stability properties of the true system (e.g. boundedness, periodicity) are
      preserved for extremely long times.
    </li>
  </ul>

  <p>
    This explains why symplectic integrators dominate long-time molecular
    dynamics, celestial mechanics, and semiclassical quantum simulations.
  </p>

  <hr/>

  <h3 id="sec-6-4-4">6.4.4 Backward Error and Optimisation of Splitting Coefficients</h3>

  <p>
    The leading term in the modified Hamiltonian for a symmetric splitting is
  </p>

  <p class="math">
    \[
      H_2
      =
      \alpha_{21}\{T,\{T,V\}\}
      +
      \alpha_{22}\{V,\{T,V\}\}.
    \tag{6.4.6}
    \]
  </p>

  <p>
    The constants \( \alpha_{2j} \) encode the leading error of the scheme.
    Modern optimised splittings (Eqs.~(6.3.7) and others) choose coefficients to:
  </p>

  <ul>
    <li>minimise \( \|H_2\| \) in an appropriate norm,</li>
    <li>or cancel selected contributions selectively,</li>
    <li>or minimise the leading commutator contribution 
        \( [A,[A,B]] + [B,[B,A]] \),</li>
    <li>or optimise the average energy drift over one period of a reference orbit.</li>
  </ul>

  <p>
    For example, the Omelyan–Mryglod–Folk (OMF) parameter 
    \( \lambda \approx 0.1931833275 \) is chosen to minimise the modified energy
    error in lattice QCD simulations.
  </p>

  <hr/>

  <h3 id="sec-6-4-5">6.4.5 BEA for Complex-Coefficient Splittings</h3>

  <p>
    For complex splitting coefficients 
    \(a_j, b_j \in \mathbb{C}\) with
    \( \Re(a_j), \Re(b_j) \ge 0 \),
    the modified vector field remains well-defined and admits the same BCH
    expansion (6.4.4).
  </p>

  <p>
    If the original system is Hamiltonian but the complex step destroys exact
    symplecticity of each subflow (e.g. for real canonical variables), the method
    is usually interpreted in a complexified phase space. For Schrödinger-type
    PDEs, complex coefficients preserve unitarity exactly, and BEA yields a
    modified Hamiltonian which is anti-Hermitian:
  </p>

  <p class="math">
    \[
      \tilde{H}
      = H + h^2 H_2 + h^4 H_4 + \cdots,
    \qquad
    \tilde{H}^\dagger = -\tilde{H}.
    \tag{6.4.7}
    \]
  </p>

  <p>
    This ensures exact preservation of \( \|\psi(t)\|_{L^2} \) for highly accurate
    quantum time propagation.
  </p>

  <hr/>

  <h3 id="sec-6-4-6">6.4.6 Resonances and Limitations of BEA</h3>

  <p>
    Although BEA is asymptotically valid, it breaks down when:
  </p>

  <ul>
    <li>the solution approaches a singularity,</li>
    <li>the modified Hamiltonian series fails to converge (typical for chaotic systems),</li>
    <li>
      resonance occurs, i.e.~when the numerical frequency approximates a rational
      multiple of true frequencies:
      \[
        k \omega(h) \approx n \Omega
      \]
      for integers \(k, n\).  
      This leads to the well-known <strong>nonlinear resonance instability</strong>.
    </li>
  </ul>

  <p>
    High-order optimized splittings typically shift the dominant resonance tongues
    to higher order in \(h\), improving practical stability.
  </p>

  <hr/>

  <h3 id="sec-6-4-7">6.4.7 Summary and References for 6.4</h3>

  <p>Key facts established in this section:</p>

  <ul>
    <li>
      BEA interprets numerical splittings as exact flows of a modified system:
      \[
        y' = \tilde{F}(h)(y).
      \]
    </li>
    <li>For Hamiltonian systems, \( \tilde{F}(h) = X_{\tilde{H}} \) is Hamiltonian.</li>
    <li>
      Modified Hamiltonians have expansions containing only even powers for 
      symmetric methods.
    </li>
    <li>
      Long-time near-conservation of energy follows naturally from modified 
      Hamiltonians.
    </li>
    <li>
      BEA drives the design of optimised splittings, including OMF, Chin, 
      and the Blanes–Casas families.
    </li>
  </ul>

  <h4>References</h4>

  <ol>
    <li>
      E. Hairer, C. Lubich, G. Wanner, 
      <em>Geometric Numerical Integration</em>, Springer, 2006.
    </li>
    <li>
      S. Blanes, F. Casas, <em>A Concise Introduction to GNI</em>, CRC, 2026.
    </li>
    <li>
      R.I. McLachlan, G.R.W. Quispel, 
      “Splitting Methods,” Acta Numer., 11 (2002), 341–434.
    </li>
    <li>
      M. Omelyan, I. Mryglod, R. Folk, 
      <em>Computer Physics Communications</em>, 2002–2003 series.
    </li>
  </ol>

</section>

<section id="sec-6-5">

  <h2>6.5 Splitting Methods for PDEs</h2>

  <p>
    Splitting schemes extend naturally from finite-dimensional ODEs to 
    evolution PDEs. Many PDEs can be written in the semilinear form
  </p>

  <p class="math">
    \[
      u_t = A u + B(u),
    \tag{6.5.1}
    \]
  </p>

  <p>
    where <strong>A</strong> is a (typically linear, stiff) operator generating a 
    strongly continuous semigroup, and <strong>B</strong> is a (possibly nonlinear) 
    locally Lipschitz operator. If the flows of \(A\) and \(B\) are explicitly 
    computable or efficiently approximable, splitting schemes yield
    <em>structure-preserving, high-accuracy time integrators</em>.
  </p>

  <p>
    This section develops the rigorous theory and SOTA implementations for
    splitting methods applied to:
  </p>

  <ul>
    <li>Schrödinger equations (linear and nonlinear),</li>
    <li>heat and diffusion equations,</li>
    <li>Klein–Gordon and wave equations,</li>
    <li>Korteweg–de Vries (KdV) and dispersive PDEs,</li>
    <li>Maxwell systems and electromagnetics.</li>
  </ul>

  <p>
    The underlying functional-analytic framework uses semigroup theory, Fourier 
    spectral discretization, and geometric properties of flows in infinite 
    dimensions.
  </p>

  <hr/>

  <h3 id="sec-6-5-1">6.5.1 Operator Semigroup Foundations</h3>

  <p>
    Let \(A: D(A)\subset X \to X\) be the generator of a 
    \(C^0\)-semigroup \(e^{tA}\) on a Banach space \(X\). 
    Let \(B: X \to X\) be locally Lipschitz so that the ODE 
  </p>

  <p class="math">
    \[
      u_t = B(u)
    \tag{6.5.2}
    \]
  </p>

  <p>
    has a unique local flow \( \varphi_B^t\). Then the splitting schemes
  </p>

  <ul>
    <li><strong>Lie–Trotter:</strong> \( \Phi_h = e^{hA} \varphi_B^{h} \)</li>
    <li><strong>Strang:</strong> \( \Phi_h = e^{\frac{h}{2}A} \varphi_B^h e^{\frac{h}{2}A} \)</li>
  </ul>

  <p>
    are well-defined on \(X\).  
  </p>

  <p>
    Convergence follows from the classical theory:
    if \(A+B\) generates a (mild or strong) solution semigroup, then the Lie and
    Strang splittings converge with order 1 and 2 respectively under mild regularity assumptions.
  </p>

  <p class="math">
    \[
      \|\Phi_h^n u_0 - e^{nh(A+B)}u_0\|
      \le C h^p,
      \qquad p = 1~\text{(Lie)},\ 2~\text{(Strang)}.
    \tag{6.5.3}
    \]
  </p>

  <hr/>

  <h3 id="sec-6-5-2">6.5.2 Fourier–Spectral Splitting</h3>

  <p>
    Many PDEs have linear parts diagonalizable by Fourier transform.  
    Let \( \mathcal{F} \) denote the Fourier transform, then:
  </p>

  <p class="math">
    \[
      A = \mathcal{F}^{-1} \Lambda(k)\, \mathcal{F},
    \tag{6.5.4}
    \]
  </p>

  <p>
    so that its flow is exactly computable:
  </p>

  <p class="math">
    \[
      e^{tA} u = \mathcal{F}^{-1} \big( e^{t\Lambda(k)} \hat{u}(k) \big).
    \tag{6.5.5}
    \]
  </p>

  <p>
    This leads to highly efficient splitting integrators:
  </p>

  <ul>
    <li>linear part: FFT → phase multiplication → inverse FFT,</li>
    <li>nonlinear part: pointwise evaluation in physical space.</li>
  </ul>

  <p>
    This structure underlies spectral splittings for Schrödinger, NLS, KdV,
    and dispersive PDEs.
  </p>

  <hr/>

  <h3 id="sec-6-5-3">6.5.3 Splitting for Schrödinger Equations</h3>

  <p>
    Consider the linear Schrödinger equation
  </p>

  <p class="math">
    \[
      i\psi_t = -\frac{1}{2}\Delta \psi + V(x)\psi.
    \tag{6.5.6}
    \]
  </p>

  <p>
    Define
  </p>

  <ul>
    <li><strong>Kinetic operator</strong>: \(A = i\frac{1}{2}\Delta\),</li>
    <li><strong>Potential operator</strong>: \(B\psi = -i V(x)\psi.\)</li>
  </ul>

  <p>
    Both flows are exactly computable:
  </p>

  <p class="math">
    \[
      e^{tA}\psi 
      = \mathcal{F}^{-1}\left( e^{-i t |k|^2/2} \hat{\psi}(k)\right),
    \tag{6.5.7}
    \]
  </p>

  <p class="math">
    \[
      e^{tB}\psi = e^{-i t V(x)} \psi(x).
    \tag{6.5.8}
    \]
  </p>

  <p>
    Thus Strang splitting gives a unitary, second-order, time-reversible method.
    High-order <em>complex-coefficient</em> splittings (Section 6.3) are widely used 
    in quantum chemistry and semiclassical dynamics.
  </p>

  <h4>Nonlinear Schrödinger equation (NLS)</h4>

  <p>
    For
  </p>

  <p class="math">
    \[
      i \psi_t = -\frac{1}{2}\Delta \psi + g|\psi|^2\psi,
    \tag{6.5.9}
    \]
  </p>

  <p>
    the nonlinear flow is
  </p>

  <p class="math">
    \[
      \varphi_B^t(\psi)
      = e^{-i g t |\psi(x)|^2} \psi(x),
    \tag{6.5.10}
    \]
  </p>

  <p>
    which preserves mass <em>exactly</em>.  
    Strang and higher-order splittings preserve:
  </p>

  <ul>
    <li>unitarity,</li>
    <li>mass,</li>
    <li>time reversibility,</li>
    <li>modified energy (via BEA).</li>
  </ul>

  <p>
    These are state-of-the-art and standard in Gross–Pitaevskii solvers and
    Bose–Einstein condensate simulations.
  </p>

  <hr/>

  <h3 id="sec-6-5-4">6.5.4 Heat and Parabolic Equations: Positivity Issues</h3>

  <p>
    For parabolic systems:
  </p>

  <p class="math">
    \[
      u_t = \Delta u + B(u),
    \tag{6.5.11}
    \]
  </p>

  <p>
    the semigroup \(e^{t\Delta}\) is contractive only for \(t\ge 0\).
    Therefore splitting coefficients must satisfy:
  </p>

  <p class="math">
    \[
      \Re(a_j) \ge 0, \qquad \Re(b_j) \ge 0.
    \tag{6.5.12}
    \]
  </p>

  <p>
    Real-coefficient high-order splittings require negative coefficients
    (Sheng–Suzuki barrier), which are unstable for diffusion.
  </p>

  <p>
    Thus modern high-order solvers for parabolic PDEs use:
  </p>

  <ul>
    <li><strong>complex-coefficient splittings with positive real parts</strong>
        (Blanes–Casas CFM schemes),</li>
    <li><strong>exponential integrators</strong> (Section 7),</li>
    <li><strong>IMEX schemes</strong> for stiff linear parts.</li>
  </ul>

  <hr/>

  <h3 id="sec-6-5-5">6.5.5 KdV, Dispersive and Nonlinear Wave Equations</h3>

  <p>
    For KdV:
  </p>

  <p class="math">
    \[
      u_t + 6 uu_x + u_{xxx} = 0,
    \tag{6.5.13}
    \]
  </p>

  <p>
    split into:
  </p>

  <ul>
    <li><strong>Linear dispersive part</strong>:
      \(
        A u = -u_{xxx}
      \)
      with flow 
      \[
        e^{tA}\hat{u}(k)
        = e^{i k^3 t} \hat{u}(k),
      \]
    </li>
    <li><strong>Burgers-type nonlinear flow</strong>:
      \(
        B(u) = -6u u_x
      \)
      with flow given implicitly by solving the Hopf equation characteristic ODE.
    </li>
  </ul>

  <p>
    The combination via Strang splitting yields a highly effective scheme used in
    soliton dynamics, dispersive shock wave, and Whitham modulation simulations.
  </p>

  <h4>Klein–Gordon and wave equations</h4>

  <p>
    For the Klein–Gordon equation:
  </p>

  <p class="math">
    \[
      u_{tt} = \Delta u - m^2 u - f(u),
    \tag{6.5.14}
    \]
  </p>

  <p>
    rewrite as a first-order Hamiltonian system in Fourier space:
  </p>

  <p class="math">
    \[
      \frac{d}{dt}
      \begin{pmatrix}
      u \\ v
      \end{pmatrix}
      =
      \begin{pmatrix}
      v \\
      \Delta u - m^2 u
      \end{pmatrix}
      + 
      \begin{pmatrix}
      0 \\ -f(u)
      \end{pmatrix}.
    \tag{6.5.15}
    \]
  </p>

  <p>
    Linear part diagonalises in Fourier space; nonlinear part is pointwise.
    High-order splittings with FFTs are state-of-the-art for nonlinear wave
    propagation, spectral radiation studies, and weak turbulence.
  </p>

  <hr/>

  <h3 id="sec-6-5-6">6.5.6 Maxwell Equations and Electromagnetic Splitting</h3>

  <p>
    Maxwell’s equations (in vacuum):
  </p>

  <p class="math">
    \[
      \partial_t E = \nabla\times H,
      \qquad
      \partial_t H = -\nabla\times E.
    \tag{6.5.16}
    \]
  </p>

  <p>
    preserve:
  </p>

  <ul>
    <li>energy</li>
    <li>divergence constraints</li>
    <li>skew-symmetry of the generator</li>
  </ul>

  <p>
    Splitting into:
  </p>

  <ul>
    <li>\(A\): evolution under curl of \(E\),</li>
    <li>\(B\): evolution under curl of \(H\),</li>
  </ul>

  <p>
    yields symplectic, structure-preserving methods suitable for:
  </p>

  <ul>
    <li>computational electromagnetics,</li>
    <li>photonic crystals,</li>
    <li>meta-material modelling,</li>
    <li>optical solitons and nonlinear Maxwell models.</li>
  </ul>

  <hr/>

  <h3 id="sec-6-5-7">6.5.7 Summary and References for 6.5</h3>

  <p>Key takeaways:</p>

  <ul>
    <li>Splitting methods extend naturally to semilinear PDEs via semigroup theory.</li>
    <li>Fourier–spectral methods + splitting = state-of-the-art for dispersive PDEs.</li>
    <li>Schrödinger and NLS equations benefit most from complex-coefficient splittings.</li>
    <li>Parabolic PDEs require positivity → complex coefficients are essential.</li>
    <li>Wave, Klein–Gordon, Maxwell, and KdV systems all admit efficient split flows.</li>
  </ul>

  <h4>References</h4>

  <ol>
    <li>
      Hairer, Lubich, Wanner, <em>Geometric Numerical Integration</em>, 2006.
    </li>
    <li>
      Blanes &amp; Casas, <em>A Concise Introduction to GNI</em>, 2ed, CRC, 2026.
    </li>
    <li>
      Bao, Jin, and Markowich, 
      “Numerical methods for the nonlinear Schrödinger equation,” 
      <em>SIAM Review</em>, 2013.
    </li>
    <li>
      Holden, Karlsen, Risebro &amp; Tao,
      <em>Splitting Methods for PDEs</em>, EMS 2011.
    </li>
  </ol>

</section>

<section id="sec-6-6">

  <h2>6.6 Relation of Splitting to Magnus Methods and Exponential Integrators</h2>

  <p>
    Splitting and composition methods, Magnus integrators, and exponential
    integrators all arise from the same operator-theoretic viewpoint:
    approximate the evolution operator of a differential equation by structured
    exponentials of simpler pieces. This section explains their common
    algebraic backbone and clarifies when each class is preferable.
  </p>

  <p>
    We focus on:
  </p>

  <ol>
    <li>The shared operator framework for autonomous and non-autonomous problems,</li>
    <li>Magnus expansion as a “logarithm” of products of exponentials (splittings),</li>
    <li>Commutator-free Magnus (CFM) schemes as high-order composition methods,</li>
    <li>The link to exponential integrators for semilinear systems,</li>
    <li>Hybrid geometric schemes that combine these tools in practice.</li>
  </ol>

  <hr/>

  <h3 id="sec-6-6-1">6.6.1 Common Operator Framework</h3>

  <p>
    Consider a linear (possibly time-dependent) evolution equation on a Banach space
    \(X\):
  </p>

  <p class="math">
    \[
      u'(t) = A(t) u(t), \qquad u(t) \in X,
    \]
  </p>

  <p>
    where \(A(t)\) is a (possibly unbounded) linear operator generating an
    evolution family \(U(t,s)\) such that
  </p>

  <p class="math">
    \[
      u(t) = U(t,s) u(s), \qquad U(t,s) U(s,r) = U(t,r),\quad U(s,s)=I.
    \]
  </p>

  <p>
    <strong>Magnus viewpoint.</strong>  
    For sufficiently regular \(A(t)\), we may write
  </p>

  <p class="math">
    \[
      U(t,s) = \exp\big(\Omega(t,s)\big),
    \]
  </p>

  <p>
    where \(\Omega(t,s)\) is given by the <em>Magnus expansion</em>, an infinite
    series of time integrals of nested commutators of \(A(\tau)\). Truncating
    \(\Omega\) yields <em>Magnus integrators</em>.
  </p>

  <p>
    <strong>Splitting viewpoint.</strong>  
    When \(A\) decomposes into simpler pieces,
  </p>

  <p class="math">
    \[
      A(t) = A_1(t) + A_2(t) + \cdots + A_m(t),
    \]
  </p>

  <p>
    whose flows (or exponentials) can be computed efficiently, we approximate
    \(U(t,s)\) by compositions of exponentials of the sub-operators,
    e.g. Lie–Trotter or Strang splittings over a time step \(h\).
  </p>

  <p>
    <strong>Exponential integrator viewpoint.</strong>  
    For semilinear systems
  </p>

  <p class="math">
    \[
      u'(t) = A u(t) + g(t, u(t)),
    \]
  </p>

  <p>
    exponential integrators treat \(e^{hA}\) exactly (or nearly so) and approximate
    the contribution of the nonlinearity \(g\) via \(\varphi\)-functions and
    quadrature. These methods can be interpreted as Magnus-/splitting-type
    approximations in the variation-of-constants formula.
  </p>

  <p>
    In all three cases, the core object is the exponential of an operator
    (or sum of operators) and its algebra under composition, governed by the
    Baker–Campbell–Hausdorff (BCH) and Magnus series.
  </p>

  <hr/>

  <h3 id="sec-6-6-2">6.6.2 Magnus Expansion as the Logarithm of Splitting Schemes</h3>

  <p>
    For simplicity, consider an autonomous decomposition
  </p>

  <p class="math">
    \[
      A = A_1 + A_2
    \]
  </p>

  <p>
    and a splitting step over a time increment \(h\):
  </p>

  <p class="math">
    \[
      S(h) = e^{a_1 h A_1} e^{b_1 h A_2} e^{a_2 h A_1} e^{b_2 h A_2} \cdots
      e^{a_s h A_1} e^{b_s h A_2}.
    \tag{6.6.1}
    \]
  </p>

  <p>
    The BCH formula ensures that there exists an operator \(Z(h)\) such that
  </p>

  <p class="math">
    \[
      S(h) = \exp(Z(h)).
    \]
  </p>

  <p>
    Expanding \(Z(h)\) as a formal power series in \(h\) gives
  </p>

  <p class="math">
    \[
      Z(h) = h(A_1 + A_2)
      + h^2 \alpha_1 [A_1, A_2]
      + h^3 \big(
        \alpha_2 [A_1,[A_1,A_2]]
        + \alpha_3 [A_2,[A_1,A_2]]
      \big)
      + \cdots,
    \tag{6.6.2}
    \]
  </p>

  <p>
    where the coefficients \(\alpha_j\) are polynomials in the composition
    coefficients \(\{a_k, b_k\}\). The <strong>order conditions</strong> for the
    splitting require that
  </p>

  <ul>
    <li>
      the linear term equals \(h(A_1 + A_2)\),
    </li>
    <li>
      all terms up to order \(p\) in the commutator series match the logarithm
      of the exact propagator \(e^{h(A_1+A_2)}\),
    </li>
    <li>
      higher-order commutators contribute to the truncation error.
    </li>
  </ul>

  <p>
    Formally, \(Z(h)\) plays the same role as the <em>Magnus generator</em>
    \(\Omega(h)\) for the exact flow. For an autonomous problem, the exact
    Magnus generator is simply
  </p>

  <p class="math">
    \[
      \Omega(h) = h(A_1 + A_2),
    \]
  </p>

  <p>
    while for time-dependent problems \(A(t)\) the Magnus series contains time
    integrals of commutators. In this sense:
  </p>

  <blockquote>
    <em>Splitting methods can be viewed as particular approximations of the
    Magnus generator by the BCH logarithm of a product of simpler exponentials.</em>
  </blockquote>

  <p>
    The modern theory of <em>commutator-free Magnus integrators</em> makes this
    connection explicit by designing products of exponentials whose BCH
    logarithm reproduces a chosen truncated Magnus series.
  </p>

  <hr/>

  <h3 id="sec-6-6-3">6.6.3 Commutator-Free Magnus (CFM) Methods as High-Order Compositions</h3>

  <p>
    For linear non-autonomous systems
  </p>

  <p class="math">
    \[
      u'(t) = A(t) u(t),
    \]
  </p>

  <p>
    the Magnus expansion over a step \([t_n,t_{n+1}] = [t_n, t_n+h]\) is
  </p>

  <p class="math">
    \[
      \Omega_n(h) = \int_{t_n}^{t_{n+1}} A(\tau)\, d\tau
      - \frac{1}{2} \int_{t_n}^{t_{n+1}}\!\!\int_{t_n}^{\tau_1}
        [A(\tau_1), A(\tau_2)]\, d\tau_2\, d\tau_1
      + \cdots.
    \tag{6.6.3}
    \]
  </p>

  <p>
    Classical Magnus integrators compute or approximate commutators like
    \([A(\tau_1), A(\tau_2)]\), which may be expensive for large matrices
    or operators.
  </p>

  <p>
    <strong>Commutator-free Magnus (CFM) methods</strong> avoid explicit commutators by
    using products of exponentials of linear combinations of <em>evaluations</em>
    of \(A\) at quadrature nodes:
  </p>

  <p class="math">
    \[
      U_{n+1} = \prod_{j=1}^s
        \exp\!\left(
          h \sum_{\ell=1}^r \alpha_{j\ell} A(t_n + c_\ell h)
        \right) U_n.
    \tag{6.6.4}
    \]
  </p>

  <p>
    Here, \(c_\ell\) are quadrature nodes (e.g. Gauss–Legendre abscissas),
    and the coefficients \(\alpha_{j\ell}\) are chosen so that the BCH logarithm
    of this product matches the truncated Magnus series up to order \(p\).
  </p>

  <p>
    From the perspective of Chapter 4, each factor
    \(\exp(h \sum_\ell \alpha_{j\ell} A(t_n+c_\ell h))\) is simply another
    <em>sub-flow</em> whose exponential can be applied efficiently
    (e.g. via Krylov or FFT-based methods). The overall method is a
    high-order <em>composition method</em> for the time-dependent generator.
  </p>

  <p>
    Key properties:
  </p>

  <ul>
    <li>
      <strong>No explicit commutators.</strong> All operations are evaluations
      and linear combinations of \(A(t)\), plus exponentials.
    </li>
    <li>
      <strong>Structure preservation.</strong> If each \(\exp(\cdot)\) is
      unitary or symplectic (e.g. skew-Hermitian matrices, Hamiltonian
      matrices), then the full CFM method inherits unitarity or symplecticity.
    </li>
    <li>
      <strong>High order.</strong> Existing schemes reach orders 4, 6, 8,
      and beyond, with carefully optimized coefficients and quadratures.
    </li>
  </ul>

  <p>
    Thus CFM integrators can be seen as a SOTA synthesis of Magnus ideas
    (logarithm of the evolution) and composition/splitting ideas
    (products of exponentials of simpler pieces).
  </p>

  <hr/>

  <h3 id="sec-6-6-4">6.6.4 Exponential Integrators as Splitting/Magnus Approximations</h3>

  <p>
    For semilinear problems
  </p>

  <p class="math">
    \[
      u'(t) = A u(t) + g(t,u(t)),
    \tag{6.6.5}
    \]
  </p>

  <p>
    the variation-of-constants formula gives
  </p>

  <p class="math">
    \[
      u(t_{n+1}) = e^{hA} u(t_n)
      + \int_0^h e^{(h-\sigma)A} g(t_n + \sigma, u(t_n+\sigma))\, d\sigma.
    \tag{6.6.6}
    \]
  </p>

  <p>
    Exponential Runge–Kutta and related exponential integrators approximate
    the integral term via quadrature and replace \(u(t_n+\sigma)\) by internal
    stage values. Typical schemes have the form
  </p>

  <p class="math">
    \[
      U_{n+1} = e^{hA} U_n
      + h \sum_{j=1}^s \varphi_j(hA) G_j(U_n),
    \tag{6.6.7}
    \]
  </p>

  <p>
    where the \(\varphi_j\) functions arise from integral representations
    involving \(e^{(h-\sigma)A}\).
  </p>

  <p>
    <strong>Relation to splitting.</strong>  
    A simple Lie–Trotter splitting for (6.6.5) reads
  </p>

  <p class="math">
    \[
      U_{n+1}
      = \varphi_g^h\!\big(e^{hA}U_n\big),
    \]
  </p>

  <p>
    where \(\varphi_g^h\) is the nonlinear flow generated by \(u' = g(t,u)\)
    (with appropriate time freezing or time-labelling). Higher-order
    Strang-type and composition splittings can be interpreted as particular
    quadrature approximations of (6.6.6), just as exponential integrators do,
    but organized as compositions of sub-flows rather than as direct
    quadrature of the integral.
  </p>

  <p>
    <strong>Relation to Magnus.</strong>  
    If \(g\) is linear in \(u\), then the full generator \(A(t)\) of
    (6.6.5) is linear, and Magnus/CFM schemes apply directly. For general
    nonlinear \(g\), Magnus ideas still influence the design of exponential
    integrators (e.g. time symmetry, commutator structure of linearized
    operators, etc.), but require more care.
  </p>

  <p>
    In practice:
  </p>

  <ul>
    <li>
      For <em>linear</em> or weakly nonlinear problems with strong time-dependence
      (e.g. quantum dynamics with pulsed fields), Magnus and CFM methods are
      often preferred.
    </li>
    <li>
      For <em>semilinear PDEs</em> with stiff linear part (e.g. diffusion or
      dispersive operators) and nonlinear reaction/transport, exponential
      integrators and splitting methods are the standard tools.
    </li>
  </ul>

  <hr/>

  <h3 id="sec-6-6-5">6.6.5 Hybrid Geometric Schemes and Practical Guidelines</h3>

  <p>
    Modern SOTA codes often blend splitting, Magnus/CFM, and exponential ideas
    to balance structure preservation, efficiency, and robustness.
  </p>

  <h4>Examples of hybrid strategies</h4>

  <ul>
    <li>
      <strong>Hamiltonian NLS and wave equations.</strong><br/>
      Use a spectral splitting for the linear dispersive part (Section 6.5),
      combined with exponential-type treatment of additional linear potentials
      or damping; nonlinearity handled via exact pointwise exponential flow.
    </li>
    <li>
      <strong>Time-dependent Hamiltonians (quantum dynamics).</strong><br/>
      Use CFM Magnus integrators to maintain unitarity while handling
      time-dependent fields, possibly within each Magnus step applying FFT-based
      techniques to exploit structure in \(A(t)\).
    </li>
    <li>
      <strong>Non-autonomous Hamiltonian ODEs.</strong><br/>
      Lift to extended phase space, apply symplectic splitting there (Section 7),
      with coefficients inspired by Magnus truncations to achieve high order
      and time symmetry.
    </li>
    <li>
      <strong>Semilinear parabolic PDEs.</strong><br/>
      Combine exponential integrators (for stiff linear part) with splitting in
      the nonlinear part (e.g. reaction vs convection) and possibly with
      complex-coefficient steps satisfying positivity constraints.
    </li>
  </ul>

  <h4>Rule-of-thumb choice</h4>

  <ul>
    <li>
      <em>Predominantly autonomous Hamiltonian / PDE:</em>  
      Splitting and composition (including complex-coefficient schemes).
    </li>
    <li>
      <em>Non-autonomous linear with strong time dependence, structure-critical:</em>  
      Magnus / commutator-free Magnus (CFM).
    </li>
    <li>
      <em>Semilinear stiff problems:</em>  
      Exponential Runge–Kutta or exponential multistep, sometimes combined
      with splitting in the nonlinear part.
    </li>
    <li>
      <em>Mixed or highly structured systems:</em>  
      Hybrid designs that treat the most structured pieces with splitting/CFM
      and the remainder with exponential integrators.
    </li>
  </ul>

  <p>
    From the geometric standpoint, all these methods are variations on a single
    theme: construct a discrete flow as a product of exponentials whose BCH
    logarithm approximates the exact generator in a way that respects
    invariants, symmetries, and qualitative structure.
  </p>

  <hr/>

  <h3 id="sec-6-6-6">6.6.6 References for Section 6.6</h3>

  <ol>
    <li>
      E. Hairer, C. Lubich, G. Wanner,
      <em>Geometric Numerical Integration</em>, 2nd ed., Springer, 2006.
      (Chs. II, IV, IX: splitting, Magnus, and exponential integrators.)
    </li>
    <li>
      S. Blanes, F. Casas,
      <em>A Concise Introduction to Geometric Numerical Integration</em>, 2nd ed.,
      Chapman &amp; Hall/CRC, 2026. (Chs. 4–6: Magnus and commutator-free methods.)
    </li>
    <li>
      S. Blanes, F. Casas, J.A. Oteo, J. Ros,
      “The Magnus expansion and some of its applications,”
      <em>Physics Reports</em> 470 (2009), 151–238.
    </li>
    <li>
      M. Hochbruck, A. Ostermann,
      “Exponential integrators,”
      <em>Acta Numerica</em> 19 (2010), 209–286.
    </li>
  </ol>

</section>



</html>